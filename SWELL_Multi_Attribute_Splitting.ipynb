{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2048b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "   ---------------------------------------- 0.0/250.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/250.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/250.0 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 61.4/250.0 kB 656.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 204.8/250.0 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 250.0/250.0 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Μια υπάρχουσα σύνδεση διακόπηκε υποχρεωτικά από τον απομακρυσμένο υπολογιστή', None, 10054, None))': /simple/openpyxl/\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc8cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from os import listdir\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3bf008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(data, participants): \n",
    "    \n",
    "    cost = []\n",
    "    silhouette = []\n",
    "\n",
    "    for i in range(2, participants):\n",
    "        kmeans = KMeans(n_clusters = i, max_iter = 500, random_state = 0)\n",
    "        kmeans.fit_predict(data)\n",
    "        \n",
    "        # Calculate Silhoutte Score\n",
    "        score = silhouette_score(data, kmeans.labels_, metric='euclidean')\n",
    "        silhouette.append(score)\n",
    "    \n",
    "        # Calculates squared error for the clustered points\n",
    "        cost.append(kmeans.inertia_)    \n",
    "        \n",
    "    # Plot the cost against K values\n",
    "    plt.plot(range(2, participants), cost, color ='g', linewidth ='3')\n",
    "    plt.xlabel(\"Value of K\")\n",
    "    plt.ylabel(\"Squared Error (Cost)\")\n",
    "    plt.show() # clear the plot\n",
    "    \n",
    "    # Plot the Silhouette Score against K values\n",
    "    plt.plot(range(2, participants), silhouette, color ='b', linewidth ='3')\n",
    "    plt.xlabel(\"Value of K\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.show() # clear the plot\n",
    "    # the point of the elbow is the\n",
    "    # most optimal value for choosing k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28f4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette(data, clusters):\n",
    "    kmeans = KMeans(n_clusters = clusters, max_iter = 500, random_state = 0)\n",
    "    kmeans.fit_predict(data)\n",
    "    \n",
    "    #Create SilhouetteVisualizer instance with KMeans instance\n",
    "    visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')#ax[q-1][mod])#, ax = ax[x%3][y%2]\n",
    "    \n",
    "    #Fit the visualizer\n",
    "    visualizer.fit(data)\n",
    "    #fig, ax = plt.subplots(3,2, figsize = (10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af3d32",
   "metadata": {},
   "source": [
    "# SWELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bd718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "swell = pd.read_csv(\"Final_CSVs/swell_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f033646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swell_extra = pd.read_excel('Personality_Files/swell_person.xlsx')\n",
    "swell_extra = pd.read_excel('scored_surveys/swell_person.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4922fe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>SCL</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>119.071484</td>\n",
       "      <td>PP4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>138.735573</td>\n",
       "      <td>PP19</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>120.251942</td>\n",
       "      <td>PP3</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>561.332213</td>\n",
       "      <td>PP21</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>158.138912</td>\n",
       "      <td>PP24</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>93.893556</td>\n",
       "      <td>PP4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP23</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>77</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>495.018099</td>\n",
       "      <td>PP12</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3140 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR       RMSSD         SCL    id dataset  stress\n",
       "0      58    0.093757  119.071484   PP4   Train       0\n",
       "1     999  999.000000  138.735573  PP19   Train       0\n",
       "2     999  999.000000  999.000000  PP22   Train       1\n",
       "3     999  999.000000  120.251942   PP3   Train       1\n",
       "4      70    0.064568  561.332213  PP21   Train       0\n",
       "...   ...         ...         ...   ...     ...     ...\n",
       "3135  999  999.000000  158.138912  PP24    Test       1\n",
       "3136  999  999.000000  999.000000  PP22    Test       1\n",
       "3137  999  999.000000   93.893556   PP4    Test       0\n",
       "3138  999  999.000000  999.000000  PP23    Test       0\n",
       "3139   77    0.025147  495.018099  PP12    Test       1\n",
       "\n",
       "[3140 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b85f86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Dominant hand</th>\n",
       "      <th>Glasses</th>\n",
       "      <th>smoke</th>\n",
       "      <th>coffee</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>physical</th>\n",
       "      <th>stress</th>\n",
       "      <th>heart disease</th>\n",
       "      <th>medicine</th>\n",
       "      <th>Internal control index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP1</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP2</td>\n",
       "      <td>25</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP3</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP4</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP5</td>\n",
       "      <td>24</td>\n",
       "      <td>f</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PP6</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PP7</td>\n",
       "      <td>22</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PP8</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>MSc Electrical Engineering</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PP9</td>\n",
       "      <td>28</td>\n",
       "      <td>m</td>\n",
       "      <td>PhD informatics</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PP10</td>\n",
       "      <td>25</td>\n",
       "      <td>m</td>\n",
       "      <td>Information Science</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PP11</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PP12</td>\n",
       "      <td>24</td>\n",
       "      <td>f</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PP13</td>\n",
       "      <td>26</td>\n",
       "      <td>m</td>\n",
       "      <td>student (Phd?)</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PP14</td>\n",
       "      <td>26</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>left</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PP15</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PP16</td>\n",
       "      <td>27</td>\n",
       "      <td>f</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PP17</td>\n",
       "      <td>38</td>\n",
       "      <td>f</td>\n",
       "      <td>PhD candidate</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PP18</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>Master MKE</td>\n",
       "      <td>left</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PP19</td>\n",
       "      <td>23</td>\n",
       "      <td>f</td>\n",
       "      <td>Icelandic</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PP20</td>\n",
       "      <td>21</td>\n",
       "      <td>f</td>\n",
       "      <td>Technische bestuurskunde</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PP21</td>\n",
       "      <td>22</td>\n",
       "      <td>f</td>\n",
       "      <td>Photography</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PP22</td>\n",
       "      <td>26</td>\n",
       "      <td>m</td>\n",
       "      <td>Physics</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PP23</td>\n",
       "      <td>25</td>\n",
       "      <td>f</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PP24</td>\n",
       "      <td>22</td>\n",
       "      <td>m</td>\n",
       "      <td>MSc Electrical Engineering</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PP25</td>\n",
       "      <td>26</td>\n",
       "      <td>m</td>\n",
       "      <td>MSc Technische Informatica</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PP  Age Gender                  Occupation Dominant hand Glasses  smoke  \\\n",
       "0    PP1   27      m                     student         right      no      6   \n",
       "1    PP2   25      m                     student         right      no      6   \n",
       "2    PP3   24      m                     student         right      no      6   \n",
       "3    PP4   24      m                     student         right      no      6   \n",
       "4    PP5   24      f                     student         right      no      6   \n",
       "5    PP6   24      m                     student         right      no      6   \n",
       "6    PP7   22      m                     student         right      no      6   \n",
       "7    PP8   27      m  MSc Electrical Engineering         right     yes      6   \n",
       "8    PP9   28      m             PhD informatics         right      no      6   \n",
       "9   PP10   25      m         Information Science         right      no      6   \n",
       "10  PP11   21      m                     student         right     yes      6   \n",
       "11  PP12   24      f                     student         right      no      6   \n",
       "12  PP13   26      m              student (Phd?)         right      no      6   \n",
       "13  PP14   26      m                     student          left     yes      6   \n",
       "14  PP15   24      m                     student         right      no      6   \n",
       "15  PP16   27      f                     student         right     yes      6   \n",
       "16  PP17   38      f               PhD candidate         right     yes      6   \n",
       "17  PP18   24      m                  Master MKE          left      no      6   \n",
       "18  PP19   23      f                   Icelandic         right     yes      6   \n",
       "19  PP20   21      f    Technische bestuurskunde         right      no      6   \n",
       "20  PP21   22      f                 Photography         right     yes      4   \n",
       "21  PP22   26      m                     Physics         right      no      6   \n",
       "22  PP23   25      f        Computer Engineering         right      no      6   \n",
       "23  PP24   22      m  MSc Electrical Engineering         right      no      6   \n",
       "24  PP25   26      m  MSc Technische Informatica         right     yes      6   \n",
       "\n",
       "    coffee  alcohol  physical  stress heart disease medicine  \\\n",
       "0        6        6         6       6            no       no   \n",
       "1        6        6         4       5            no       no   \n",
       "2        6        6         6       6            no       no   \n",
       "3        6        6         2       6            no       no   \n",
       "4        6        6         6       6            no       no   \n",
       "5        6        6         6       6            no       no   \n",
       "6        6        6         6       6            no       no   \n",
       "7        6        6         3       6            no       no   \n",
       "8        6        6         2       6            no       no   \n",
       "9        6        6         6       6            no       no   \n",
       "10       6        6         6       6            no       no   \n",
       "11       6        6         6       6            no       no   \n",
       "12       6        6         6       6            no       no   \n",
       "13       6        6         2       6            no       no   \n",
       "14       6        6         1       6            no       no   \n",
       "15       6        6         2       1            no       no   \n",
       "16       6        6         6       4            no       no   \n",
       "17       6        6         6       6            no       no   \n",
       "18       6        6         6       6            no       no   \n",
       "19       6        6         6       6            no       no   \n",
       "20       5        5         5       4            no       no   \n",
       "21       6        6         6       6            no       no   \n",
       "22       6        6         2       4            no       no   \n",
       "23       6        6         2       2            no       no   \n",
       "24       6        6         2       6            no       no   \n",
       "\n",
       "    Internal control index  \n",
       "0                     2.93  \n",
       "1                     4.25  \n",
       "2                     3.61  \n",
       "3                     3.61  \n",
       "4                     3.71  \n",
       "5                     3.86  \n",
       "6                     3.64  \n",
       "7                     3.57  \n",
       "8                     3.25  \n",
       "9                     3.39  \n",
       "10                    3.71  \n",
       "11                    3.89  \n",
       "12                    4.21  \n",
       "13                    3.50  \n",
       "14                    4.25  \n",
       "15                    3.61  \n",
       "16                    3.46  \n",
       "17                    3.61  \n",
       "18                    3.61  \n",
       "19                    3.57  \n",
       "20                    3.39  \n",
       "21                    3.61  \n",
       "22                    3.89  \n",
       "23                    3.82  \n",
       "24                    3.79  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15833e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary features\n",
    "\n",
    "swell_extra.drop(['heart disease'], axis=1, inplace=True)\n",
    "swell_extra.drop(['medicine'], axis=1, inplace=True)\n",
    "swell_extra.drop(['Glasses'], axis=1, inplace=True)\n",
    "swell_extra.drop(['smoke'], axis=1, inplace=True)\n",
    "swell_extra.drop(['alcohol'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45fadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group all Master students in one category\n",
    "\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"MSc Electrical Engineering\",\"MSc\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Master MKE\", \"MSc\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"MSc Technische Informatica\", \"MSc\", swell_extra['Occupation'])\n",
    "\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Computer Engineering\", \"student\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Physics\", \"student\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Information Science\", \"student\", swell_extra['Occupation'])\n",
    "\n",
    "\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Icelandic\", \"other\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Photography\", \"other\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"Technische bestuurskunde\", \"other\", swell_extra['Occupation'])\n",
    "\n",
    "# Group all PhD students in one category\n",
    "\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"PhD informatics\", \"PhD\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"student (Phd?)\", \"PhD\", swell_extra['Occupation'])\n",
    "swell_extra['Occupation'] = np.where(swell_extra['Occupation']==\"PhD candidate\", \"PhD\", swell_extra['Occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c7e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding categorical features\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "swell_extra['Occupation'] = le.fit_transform(swell_extra['Occupation'])\n",
    "swell_extra['Dominant hand'] = le.fit_transform(swell_extra['Dominant hand'])\n",
    "swell_extra['Gender'] = le.fit_transform(swell_extra['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f26fcc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Dominant hand</th>\n",
       "      <th>coffee</th>\n",
       "      <th>physical</th>\n",
       "      <th>stress</th>\n",
       "      <th>Internal control index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PP6</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PP7</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PP8</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PP9</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PP10</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PP11</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PP12</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PP13</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PP14</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PP15</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PP16</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PP17</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PP18</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PP19</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PP20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PP21</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PP22</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PP23</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PP24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PP25</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PP  Age  Gender  Occupation  Dominant hand  coffee  physical  stress  \\\n",
       "0    PP1   27       1           3              1       6         6       6   \n",
       "1    PP2   25       1           3              1       6         4       5   \n",
       "2    PP3   24       1           3              1       6         6       6   \n",
       "3    PP4   24       1           3              1       6         2       6   \n",
       "4    PP5   24       0           3              1       6         6       6   \n",
       "5    PP6   24       1           3              1       6         6       6   \n",
       "6    PP7   22       1           3              1       6         6       6   \n",
       "7    PP8   27       1           0              1       6         3       6   \n",
       "8    PP9   28       1           1              1       6         2       6   \n",
       "9   PP10   25       1           3              1       6         6       6   \n",
       "10  PP11   21       1           3              1       6         6       6   \n",
       "11  PP12   24       0           3              1       6         6       6   \n",
       "12  PP13   26       1           1              1       6         6       6   \n",
       "13  PP14   26       1           3              0       6         2       6   \n",
       "14  PP15   24       1           3              1       6         1       6   \n",
       "15  PP16   27       0           3              1       6         2       1   \n",
       "16  PP17   38       0           1              1       6         6       4   \n",
       "17  PP18   24       1           0              0       6         6       6   \n",
       "18  PP19   23       0           2              1       6         6       6   \n",
       "19  PP20   21       0           2              1       6         6       6   \n",
       "20  PP21   22       0           2              1       5         5       4   \n",
       "21  PP22   26       1           3              1       6         6       6   \n",
       "22  PP23   25       0           3              1       6         2       4   \n",
       "23  PP24   22       1           0              1       6         2       2   \n",
       "24  PP25   26       1           0              1       6         2       6   \n",
       "\n",
       "    Internal control index  \n",
       "0                     2.93  \n",
       "1                     4.25  \n",
       "2                     3.61  \n",
       "3                     3.61  \n",
       "4                     3.71  \n",
       "5                     3.86  \n",
       "6                     3.64  \n",
       "7                     3.57  \n",
       "8                     3.25  \n",
       "9                     3.39  \n",
       "10                    3.71  \n",
       "11                    3.89  \n",
       "12                    4.21  \n",
       "13                    3.50  \n",
       "14                    4.25  \n",
       "15                    3.61  \n",
       "16                    3.46  \n",
       "17                    3.61  \n",
       "18                    3.61  \n",
       "19                    3.57  \n",
       "20                    3.39  \n",
       "21                    3.61  \n",
       "22                    3.89  \n",
       "23                    3.82  \n",
       "24                    3.79  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfee8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#swell_extra[['Age', 'Occupation', 'smoke', 'physical', 'stress', 'Internal control index']] = scaler.fit_transform(swell_extra[['Age', 'Occupation', 'smoke',  'physical', 'stress', 'Internal control index']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d740ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "swell_extra[[\"Age\", \"Gender\", \"Occupation\", \"Dominant hand\", \"coffee\", \"physical\", \"stress\", \"Internal control index\"]] = scaler.fit_transform(swell_extra[[\"Age\", \"Gender\", \"Occupation\", \"Dominant hand\", \"coffee\", \"physical\", \"stress\", \"Internal control index\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c3e57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Dominant hand</th>\n",
       "      <th>coffee</th>\n",
       "      <th>physical</th>\n",
       "      <th>stress</th>\n",
       "      <th>Internal control index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP1</td>\n",
       "      <td>0.615457</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-2.531632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-0.231695</td>\n",
       "      <td>-0.272103</td>\n",
       "      <td>1.986695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP3</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP4</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP5</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.138288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PP6</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.651734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PP7</td>\n",
       "      <td>-0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.101320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PP8</td>\n",
       "      <td>0.615457</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-0.758273</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.340928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PP9</td>\n",
       "      <td>0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-1.436280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PP10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.957064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PP11</td>\n",
       "      <td>-1.230915</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.138288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PP12</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.754424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PP13</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>1.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PP14</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>-3.391165</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.580537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PP15</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.811430</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>1.986695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PP16</td>\n",
       "      <td>0.615457</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-3.295474</td>\n",
       "      <td>-0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PP17</td>\n",
       "      <td>4.000473</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>-0.717456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PP18</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>-3.391165</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PP19</td>\n",
       "      <td>-0.615457</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PP20</td>\n",
       "      <td>-1.230915</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.340928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PP21</td>\n",
       "      <td>-0.923186</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>-4.898979</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>-0.957064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PP22</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PP23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>0.754424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PP24</td>\n",
       "      <td>-0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-2.539631</td>\n",
       "      <td>0.514815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PP25</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.412126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       Age    Gender  Occupation  Dominant hand    coffee  physical  \\\n",
       "0    PP1  0.615457  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "1    PP2  0.000000  0.685994    0.727171       0.294884  0.204124 -0.231695   \n",
       "2    PP3 -0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "3    PP4 -0.307729  0.685994    0.727171       0.294884  0.204124 -1.284851   \n",
       "4    PP5 -0.307729 -1.457738    0.727171       0.294884  0.204124  0.821462   \n",
       "5    PP6 -0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "6    PP7 -0.923186  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "7    PP8  0.615457  0.685994   -1.869867       0.294884  0.204124 -0.758273   \n",
       "8    PP9  0.923186  0.685994   -1.004188       0.294884  0.204124 -1.284851   \n",
       "9   PP10  0.000000  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "10  PP11 -1.230915  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "11  PP12 -0.307729 -1.457738    0.727171       0.294884  0.204124  0.821462   \n",
       "12  PP13  0.307729  0.685994   -1.004188       0.294884  0.204124  0.821462   \n",
       "13  PP14  0.307729  0.685994    0.727171      -3.391165  0.204124 -1.284851   \n",
       "14  PP15 -0.307729  0.685994    0.727171       0.294884  0.204124 -1.811430   \n",
       "15  PP16  0.615457 -1.457738    0.727171       0.294884  0.204124 -1.284851   \n",
       "16  PP17  4.000473 -1.457738   -1.004188       0.294884  0.204124  0.821462   \n",
       "17  PP18 -0.307729  0.685994   -1.869867      -3.391165  0.204124  0.821462   \n",
       "18  PP19 -0.615457 -1.457738   -0.138509       0.294884  0.204124  0.821462   \n",
       "19  PP20 -1.230915 -1.457738   -0.138509       0.294884  0.204124  0.821462   \n",
       "20  PP21 -0.923186 -1.457738   -0.138509       0.294884 -4.898979  0.294884   \n",
       "21  PP22  0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "22  PP23  0.000000 -1.457738    0.727171       0.294884  0.204124 -1.284851   \n",
       "23  PP24 -0.923186  0.685994   -1.869867       0.294884  0.204124 -1.284851   \n",
       "24  PP25  0.307729  0.685994   -1.869867       0.294884  0.204124 -1.284851   \n",
       "\n",
       "      stress  Internal control index  \n",
       "0   0.483739               -2.531632  \n",
       "1  -0.272103                1.986695  \n",
       "2   0.483739               -0.204009  \n",
       "3   0.483739               -0.204009  \n",
       "4   0.483739                0.138288  \n",
       "5   0.483739                0.651734  \n",
       "6   0.483739               -0.101320  \n",
       "7   0.483739               -0.340928  \n",
       "8   0.483739               -1.436280  \n",
       "9   0.483739               -0.957064  \n",
       "10  0.483739                0.138288  \n",
       "11  0.483739                0.754424  \n",
       "12  0.483739                1.849776  \n",
       "13  0.483739               -0.580537  \n",
       "14  0.483739                1.986695  \n",
       "15 -3.295474               -0.204009  \n",
       "16 -1.027946               -0.717456  \n",
       "17  0.483739               -0.204009  \n",
       "18  0.483739               -0.204009  \n",
       "19  0.483739               -0.340928  \n",
       "20 -1.027946               -0.957064  \n",
       "21  0.483739               -0.204009  \n",
       "22 -1.027946                0.754424  \n",
       "23 -2.539631                0.514815  \n",
       "24  0.483739                0.412126  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_extra = swell_extra.rename(columns={\"PP\":\"id\"})\n",
    "swell_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2ec6f",
   "metadata": {},
   "source": [
    "## Multi-Attribute-Splitting (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3d42d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>HR</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>SCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP4</td>\n",
       "      <td>58</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>119.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP19</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>138.735573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP22</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP3</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>120.251942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP21</td>\n",
       "      <td>70</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>561.332213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>PP24</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>158.138912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>PP22</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>PP4</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>93.893556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>PP23</td>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>PP12</td>\n",
       "      <td>77</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>495.018099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   HR       RMSSD         SCL\n",
       "0      PP4   58    0.093757  119.071484\n",
       "1     PP19  999  999.000000  138.735573\n",
       "2     PP22  999  999.000000  999.000000\n",
       "3      PP3  999  999.000000  120.251942\n",
       "4     PP21   70    0.064568  561.332213\n",
       "...    ...  ...         ...         ...\n",
       "3135  PP24  999  999.000000  158.138912\n",
       "3136  PP22  999  999.000000  999.000000\n",
       "3137   PP4  999  999.000000   93.893556\n",
       "3138  PP23  999  999.000000  999.000000\n",
       "3139  PP12   77    0.025147  495.018099\n",
       "\n",
       "[3140 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_all_features = swell[['id', 'HR', 'RMSSD', 'SCL']]\n",
    "swell_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720ea302",
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_mean = swell_all_features.groupby('id', as_index = False, group_keys = True).mean()\n",
    "swell_mean = swell_mean.rename(columns={\"HR\": \"HR_mean\", \"RMSSD\": \"RMSSD_mean\", \"SCL\": \"SCL_mean\"})\n",
    "\n",
    "swell_min = swell_all_features.groupby('id', as_index = False, group_keys = True).min()\n",
    "swell_min = swell_min.rename(columns={\"HR\": \"HR_min\", \"RMSSD\": \"RMSSD_min\", \"SCL\": \"SCL_min\"})\n",
    "\n",
    "swell_std = swell_all_features.groupby('id', as_index = False, group_keys = True).std()\n",
    "swell_std = swell_std.rename(columns={\"HR\": \"HR_std\", \"RMSSD\": \"RMSSD_std\", \"SCL\": \"SCL_std\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05261243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "swell_mean[['HR_mean', 'RMSSD_mean', 'SCL_mean']] = scaler.fit_transform(swell_mean[['HR_mean', 'RMSSD_mean', 'SCL_mean']])\n",
    "swell_min[['HR_min', 'RMSSD_min', 'SCL_min']] = scaler.fit_transform(swell_min[['HR_min', 'RMSSD_min', 'SCL_min']])\n",
    "swell_std[['HR_std', 'RMSSD_std', 'SCL_std']] = scaler.fit_transform(swell_std[['HR_std', 'RMSSD_std', 'SCL_std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19cba762",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Dominant hand</th>\n",
       "      <th>coffee</th>\n",
       "      <th>physical</th>\n",
       "      <th>stress</th>\n",
       "      <th>Internal control index</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>RMSSD_mean</th>\n",
       "      <th>SCL_mean</th>\n",
       "      <th>HR_min</th>\n",
       "      <th>RMSSD_min</th>\n",
       "      <th>SCL_min</th>\n",
       "      <th>HR_std</th>\n",
       "      <th>RMSSD_std</th>\n",
       "      <th>SCL_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP1</td>\n",
       "      <td>0.615457</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-2.531632</td>\n",
       "      <td>-0.900394</td>\n",
       "      <td>-0.876707</td>\n",
       "      <td>-1.222782</td>\n",
       "      <td>-0.319298</td>\n",
       "      <td>-0.294909</td>\n",
       "      <td>-1.004249</td>\n",
       "      <td>0.465365</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>-0.949413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-0.231695</td>\n",
       "      <td>-0.272103</td>\n",
       "      <td>1.986695</td>\n",
       "      <td>-1.646229</td>\n",
       "      <td>-1.646932</td>\n",
       "      <td>-1.230384</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>-0.294888</td>\n",
       "      <td>-0.971799</td>\n",
       "      <td>-1.217241</td>\n",
       "      <td>-1.219896</td>\n",
       "      <td>-1.822954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP3</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.884367</td>\n",
       "      <td>0.867364</td>\n",
       "      <td>-0.548374</td>\n",
       "      <td>-0.264111</td>\n",
       "      <td>-0.294924</td>\n",
       "      <td>-0.312573</td>\n",
       "      <td>0.186334</td>\n",
       "      <td>0.249442</td>\n",
       "      <td>0.335381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP4</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>1.243265</td>\n",
       "      <td>1.247300</td>\n",
       "      <td>0.375704</td>\n",
       "      <td>-0.319298</td>\n",
       "      <td>-0.294784</td>\n",
       "      <td>-0.823730</td>\n",
       "      <td>-0.424820</td>\n",
       "      <td>-0.457861</td>\n",
       "      <td>1.405055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP5</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.138288</td>\n",
       "      <td>0.122998</td>\n",
       "      <td>0.126018</td>\n",
       "      <td>-0.862919</td>\n",
       "      <td>-0.307472</td>\n",
       "      <td>-0.294853</td>\n",
       "      <td>-0.768211</td>\n",
       "      <td>0.820475</td>\n",
       "      <td>0.816977</td>\n",
       "      <td>0.149815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PP6</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.651734</td>\n",
       "      <td>-0.575141</td>\n",
       "      <td>-0.550986</td>\n",
       "      <td>-1.113142</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>-0.294865</td>\n",
       "      <td>-0.861158</td>\n",
       "      <td>0.741422</td>\n",
       "      <td>0.707874</td>\n",
       "      <td>-1.239744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PP7</td>\n",
       "      <td>-0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.101320</td>\n",
       "      <td>-1.023418</td>\n",
       "      <td>-1.017587</td>\n",
       "      <td>-0.207807</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>-0.294906</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.272457</td>\n",
       "      <td>0.269073</td>\n",
       "      <td>0.687546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PP8</td>\n",
       "      <td>0.615457</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-0.758273</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.340928</td>\n",
       "      <td>1.656421</td>\n",
       "      <td>1.654327</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>3.390077</td>\n",
       "      <td>3.391165</td>\n",
       "      <td>1.674636</td>\n",
       "      <td>-2.793593</td>\n",
       "      <td>-2.803529</td>\n",
       "      <td>1.016631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PP9</td>\n",
       "      <td>0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-1.436280</td>\n",
       "      <td>0.450904</td>\n",
       "      <td>0.458573</td>\n",
       "      <td>2.375174</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>-0.294842</td>\n",
       "      <td>3.584380</td>\n",
       "      <td>0.682556</td>\n",
       "      <td>0.662209</td>\n",
       "      <td>-0.046574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PP10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.957064</td>\n",
       "      <td>0.398311</td>\n",
       "      <td>0.406084</td>\n",
       "      <td>-0.785393</td>\n",
       "      <td>-0.315356</td>\n",
       "      <td>-0.294852</td>\n",
       "      <td>-0.630076</td>\n",
       "      <td>0.715259</td>\n",
       "      <td>0.695735</td>\n",
       "      <td>0.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PP11</td>\n",
       "      <td>-1.230915</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.138288</td>\n",
       "      <td>1.656421</td>\n",
       "      <td>1.654327</td>\n",
       "      <td>1.399914</td>\n",
       "      <td>3.390077</td>\n",
       "      <td>3.391165</td>\n",
       "      <td>-0.612576</td>\n",
       "      <td>-2.793593</td>\n",
       "      <td>-2.803529</td>\n",
       "      <td>1.630332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PP12</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.754424</td>\n",
       "      <td>-0.673160</td>\n",
       "      <td>-0.688286</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>-0.271995</td>\n",
       "      <td>-0.294909</td>\n",
       "      <td>0.019899</td>\n",
       "      <td>0.587485</td>\n",
       "      <td>0.613917</td>\n",
       "      <td>0.087347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PP13</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>1.849776</td>\n",
       "      <td>-0.015454</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.446554</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>-0.294896</td>\n",
       "      <td>-0.324033</td>\n",
       "      <td>0.869512</td>\n",
       "      <td>0.839041</td>\n",
       "      <td>0.197979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PP14</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>-3.391165</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.580537</td>\n",
       "      <td>-0.699088</td>\n",
       "      <td>-0.715220</td>\n",
       "      <td>-0.889533</td>\n",
       "      <td>-0.268053</td>\n",
       "      <td>-0.294906</td>\n",
       "      <td>-0.464343</td>\n",
       "      <td>0.564936</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>-0.989584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PP15</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.811430</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>1.986695</td>\n",
       "      <td>0.466006</td>\n",
       "      <td>0.477363</td>\n",
       "      <td>-0.097784</td>\n",
       "      <td>-0.319298</td>\n",
       "      <td>-0.294875</td>\n",
       "      <td>0.807973</td>\n",
       "      <td>0.680695</td>\n",
       "      <td>0.649216</td>\n",
       "      <td>-0.306543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PP16</td>\n",
       "      <td>0.615457</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-3.295474</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>-1.548942</td>\n",
       "      <td>-1.576753</td>\n",
       "      <td>-0.942372</td>\n",
       "      <td>-0.260169</td>\n",
       "      <td>-0.294857</td>\n",
       "      <td>-1.066454</td>\n",
       "      <td>-0.959707</td>\n",
       "      <td>-0.945663</td>\n",
       "      <td>-0.779952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PP17</td>\n",
       "      <td>4.000473</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>-0.717456</td>\n",
       "      <td>-1.312910</td>\n",
       "      <td>-1.307585</td>\n",
       "      <td>-0.372496</td>\n",
       "      <td>-0.315356</td>\n",
       "      <td>-0.294917</td>\n",
       "      <td>0.941927</td>\n",
       "      <td>-0.215431</td>\n",
       "      <td>-0.218956</td>\n",
       "      <td>-1.304895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PP18</td>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>-3.391165</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>-0.993383</td>\n",
       "      <td>-1.001877</td>\n",
       "      <td>-0.507674</td>\n",
       "      <td>-0.283820</td>\n",
       "      <td>-0.294917</td>\n",
       "      <td>0.570615</td>\n",
       "      <td>0.277847</td>\n",
       "      <td>0.291028</td>\n",
       "      <td>-1.347435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PP19</td>\n",
       "      <td>-0.615457</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.139741</td>\n",
       "      <td>0.131338</td>\n",
       "      <td>-0.586040</td>\n",
       "      <td>-0.268053</td>\n",
       "      <td>-0.294862</td>\n",
       "      <td>-0.619700</td>\n",
       "      <td>0.791563</td>\n",
       "      <td>0.815099</td>\n",
       "      <td>0.246811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PP20</td>\n",
       "      <td>-1.230915</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.340928</td>\n",
       "      <td>1.115547</td>\n",
       "      <td>1.115816</td>\n",
       "      <td>0.493612</td>\n",
       "      <td>-0.287762</td>\n",
       "      <td>-0.294851</td>\n",
       "      <td>0.227648</td>\n",
       "      <td>-0.156073</td>\n",
       "      <td>-0.163981</td>\n",
       "      <td>1.254304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PP21</td>\n",
       "      <td>-0.923186</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>-4.898979</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>-0.957064</td>\n",
       "      <td>-1.430428</td>\n",
       "      <td>-1.425883</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>-0.294842</td>\n",
       "      <td>0.436899</td>\n",
       "      <td>-0.487757</td>\n",
       "      <td>-0.490870</td>\n",
       "      <td>-1.322268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PP22</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.685103</td>\n",
       "      <td>0.689476</td>\n",
       "      <td>0.403560</td>\n",
       "      <td>-0.303530</td>\n",
       "      <td>-0.294899</td>\n",
       "      <td>0.372228</td>\n",
       "      <td>0.478256</td>\n",
       "      <td>0.463279</td>\n",
       "      <td>1.225381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PP23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>0.754424</td>\n",
       "      <td>0.231754</td>\n",
       "      <td>0.227235</td>\n",
       "      <td>2.526465</td>\n",
       "      <td>-0.287762</td>\n",
       "      <td>-0.294896</td>\n",
       "      <td>0.171827</td>\n",
       "      <td>0.769992</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>-0.511894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PP24</td>\n",
       "      <td>-0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-2.539631</td>\n",
       "      <td>0.514815</td>\n",
       "      <td>0.534514</td>\n",
       "      <td>0.532129</td>\n",
       "      <td>0.197014</td>\n",
       "      <td>-0.283820</td>\n",
       "      <td>-0.294931</td>\n",
       "      <td>0.218670</td>\n",
       "      <td>0.598568</td>\n",
       "      <td>0.606903</td>\n",
       "      <td>0.852896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PP25</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.412126</td>\n",
       "      <td>1.233195</td>\n",
       "      <td>1.220136</td>\n",
       "      <td>0.199072</td>\n",
       "      <td>-0.220749</td>\n",
       "      <td>-0.294947</td>\n",
       "      <td>-0.589581</td>\n",
       "      <td>-0.454509</td>\n",
       "      <td>-0.391519</td>\n",
       "      <td>1.344447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       Age    Gender  Occupation  Dominant hand    coffee  physical  \\\n",
       "0    PP1  0.615457  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "1    PP2  0.000000  0.685994    0.727171       0.294884  0.204124 -0.231695   \n",
       "2    PP3 -0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "3    PP4 -0.307729  0.685994    0.727171       0.294884  0.204124 -1.284851   \n",
       "4    PP5 -0.307729 -1.457738    0.727171       0.294884  0.204124  0.821462   \n",
       "5    PP6 -0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "6    PP7 -0.923186  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "7    PP8  0.615457  0.685994   -1.869867       0.294884  0.204124 -0.758273   \n",
       "8    PP9  0.923186  0.685994   -1.004188       0.294884  0.204124 -1.284851   \n",
       "9   PP10  0.000000  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "10  PP11 -1.230915  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "11  PP12 -0.307729 -1.457738    0.727171       0.294884  0.204124  0.821462   \n",
       "12  PP13  0.307729  0.685994   -1.004188       0.294884  0.204124  0.821462   \n",
       "13  PP14  0.307729  0.685994    0.727171      -3.391165  0.204124 -1.284851   \n",
       "14  PP15 -0.307729  0.685994    0.727171       0.294884  0.204124 -1.811430   \n",
       "15  PP16  0.615457 -1.457738    0.727171       0.294884  0.204124 -1.284851   \n",
       "16  PP17  4.000473 -1.457738   -1.004188       0.294884  0.204124  0.821462   \n",
       "17  PP18 -0.307729  0.685994   -1.869867      -3.391165  0.204124  0.821462   \n",
       "18  PP19 -0.615457 -1.457738   -0.138509       0.294884  0.204124  0.821462   \n",
       "19  PP20 -1.230915 -1.457738   -0.138509       0.294884  0.204124  0.821462   \n",
       "20  PP21 -0.923186 -1.457738   -0.138509       0.294884 -4.898979  0.294884   \n",
       "21  PP22  0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "22  PP23  0.000000 -1.457738    0.727171       0.294884  0.204124 -1.284851   \n",
       "23  PP24 -0.923186  0.685994   -1.869867       0.294884  0.204124 -1.284851   \n",
       "24  PP25  0.307729  0.685994   -1.869867       0.294884  0.204124 -1.284851   \n",
       "\n",
       "      stress  Internal control index   HR_mean  RMSSD_mean  SCL_mean  \\\n",
       "0   0.483739               -2.531632 -0.900394   -0.876707 -1.222782   \n",
       "1  -0.272103                1.986695 -1.646229   -1.646932 -1.230384   \n",
       "2   0.483739               -0.204009  0.884367    0.867364 -0.548374   \n",
       "3   0.483739               -0.204009  1.243265    1.247300  0.375704   \n",
       "4   0.483739                0.138288  0.122998    0.126018 -0.862919   \n",
       "5   0.483739                0.651734 -0.575141   -0.550986 -1.113142   \n",
       "6   0.483739               -0.101320 -1.023418   -1.017587 -0.207807   \n",
       "7   0.483739               -0.340928  1.656421    1.654327  1.227664   \n",
       "8   0.483739               -1.436280  0.450904    0.458573  2.375174   \n",
       "9   0.483739               -0.957064  0.398311    0.406084 -0.785393   \n",
       "10  0.483739                0.138288  1.656421    1.654327  1.399914   \n",
       "11  0.483739                0.754424 -0.673160   -0.688286  0.543763   \n",
       "12  0.483739                1.849776 -0.015454    0.000329 -0.446554   \n",
       "13  0.483739               -0.580537 -0.699088   -0.715220 -0.889533   \n",
       "14  0.483739                1.986695  0.466006    0.477363 -0.097784   \n",
       "15 -3.295474               -0.204009 -1.548942   -1.576753 -0.942372   \n",
       "16 -1.027946               -0.717456 -1.312910   -1.307585 -0.372496   \n",
       "17  0.483739               -0.204009 -0.993383   -1.001877 -0.507674   \n",
       "18  0.483739               -0.204009  0.139741    0.131338 -0.586040   \n",
       "19  0.483739               -0.340928  1.115547    1.115816  0.493612   \n",
       "20 -1.027946               -0.957064 -1.430428   -1.425883  0.071310   \n",
       "21  0.483739               -0.204009  0.685103    0.689476  0.403560   \n",
       "22 -1.027946                0.754424  0.231754    0.227235  2.526465   \n",
       "23 -2.539631                0.514815  0.534514    0.532129  0.197014   \n",
       "24  0.483739                0.412126  1.233195    1.220136  0.199072   \n",
       "\n",
       "      HR_min  RMSSD_min   SCL_min    HR_std  RMSSD_std   SCL_std  \n",
       "0  -0.319298  -0.294909 -1.004249  0.465365   0.439151 -0.949413  \n",
       "1  -0.295646  -0.294888 -0.971799 -1.217241  -1.219896 -1.822954  \n",
       "2  -0.264111  -0.294924 -0.312573  0.186334   0.249442  0.335381  \n",
       "3  -0.319298  -0.294784 -0.823730 -0.424820  -0.457861  1.405055  \n",
       "4  -0.307472  -0.294853 -0.768211  0.820475   0.816977  0.149815  \n",
       "5  -0.323240  -0.294865 -0.861158  0.741422   0.707874 -1.239744  \n",
       "6  -0.323240  -0.294906  0.021783  0.272457   0.269073  0.687546  \n",
       "7   3.390077   3.391165  1.674636 -2.793593  -2.803529  1.016631  \n",
       "8  -0.323240  -0.294842  3.584380  0.682556   0.662209 -0.046574  \n",
       "9  -0.315356  -0.294852 -0.630076  0.715259   0.695735  0.187333  \n",
       "10  3.390077   3.391165 -0.612576 -2.793593  -2.803529  1.630332  \n",
       "11 -0.271995  -0.294909  0.019899  0.587485   0.613917  0.087347  \n",
       "12 -0.323240  -0.294896 -0.324033  0.869512   0.839041  0.197979  \n",
       "13 -0.268053  -0.294906 -0.464343  0.564936   0.592349 -0.989584  \n",
       "14 -0.319298  -0.294875  0.807973  0.680695   0.649216 -0.306543  \n",
       "15 -0.260169  -0.294857 -1.066454 -0.959707  -0.945663 -0.779952  \n",
       "16 -0.315356  -0.294917  0.941927 -0.215431  -0.218956 -1.304895  \n",
       "17 -0.283820  -0.294917  0.570615  0.277847   0.291028 -1.347435  \n",
       "18 -0.268053  -0.294862 -0.619700  0.791563   0.815099  0.246811  \n",
       "19 -0.287762  -0.294851  0.227648 -0.156073  -0.163981  1.254304  \n",
       "20 -0.295646  -0.294842  0.436899 -0.487757  -0.490870 -1.322268  \n",
       "21 -0.303530  -0.294899  0.372228  0.478256   0.463279  1.225381  \n",
       "22 -0.287762  -0.294896  0.171827  0.769992   0.784510 -0.511894  \n",
       "23 -0.283820  -0.294931  0.218670  0.598568   0.606903  0.852896  \n",
       "24 -0.220749  -0.294947 -0.589581 -0.454509  -0.391519  1.344447  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_all_grouped = swell_extra.join(swell_mean.set_index('id'), on='id')\n",
    "swell_all_grouped = swell_all_grouped.join(swell_min.set_index('id'), on='id')\n",
    "swell_all_grouped = swell_all_grouped.join(swell_std.set_index('id'), on='id')\n",
    "swell_all_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a6c375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep user IDs in a separate datarame\n",
    "\n",
    "ids = swell_all_grouped['id']\n",
    "swell_all_grouped.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9237da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Dominant hand</th>\n",
       "      <th>coffee</th>\n",
       "      <th>physical</th>\n",
       "      <th>stress</th>\n",
       "      <th>Internal control index</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>RMSSD_mean</th>\n",
       "      <th>SCL_mean</th>\n",
       "      <th>HR_min</th>\n",
       "      <th>SCL_min</th>\n",
       "      <th>HR_std</th>\n",
       "      <th>RMSSD_std</th>\n",
       "      <th>SCL_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.615457</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-2.531632</td>\n",
       "      <td>-0.900394</td>\n",
       "      <td>-0.876707</td>\n",
       "      <td>-1.222782</td>\n",
       "      <td>-0.319298</td>\n",
       "      <td>-1.004249</td>\n",
       "      <td>0.465365</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>-0.949413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-0.231695</td>\n",
       "      <td>-0.272103</td>\n",
       "      <td>1.986695</td>\n",
       "      <td>-1.646229</td>\n",
       "      <td>-1.646932</td>\n",
       "      <td>-1.230384</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>-0.971799</td>\n",
       "      <td>-1.217241</td>\n",
       "      <td>-1.219896</td>\n",
       "      <td>-1.822954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.884367</td>\n",
       "      <td>0.867364</td>\n",
       "      <td>-0.548374</td>\n",
       "      <td>-0.264111</td>\n",
       "      <td>-0.312573</td>\n",
       "      <td>0.186334</td>\n",
       "      <td>0.249442</td>\n",
       "      <td>0.335381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>1.243265</td>\n",
       "      <td>1.247300</td>\n",
       "      <td>0.375704</td>\n",
       "      <td>-0.319298</td>\n",
       "      <td>-0.823730</td>\n",
       "      <td>-0.424820</td>\n",
       "      <td>-0.457861</td>\n",
       "      <td>1.405055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.138288</td>\n",
       "      <td>0.122998</td>\n",
       "      <td>0.126018</td>\n",
       "      <td>-0.862919</td>\n",
       "      <td>-0.307472</td>\n",
       "      <td>-0.768211</td>\n",
       "      <td>0.820475</td>\n",
       "      <td>0.816977</td>\n",
       "      <td>0.149815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.651734</td>\n",
       "      <td>-0.575141</td>\n",
       "      <td>-0.550986</td>\n",
       "      <td>-1.113142</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>-0.861158</td>\n",
       "      <td>0.741422</td>\n",
       "      <td>0.707874</td>\n",
       "      <td>-1.239744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.101320</td>\n",
       "      <td>-1.023418</td>\n",
       "      <td>-1.017587</td>\n",
       "      <td>-0.207807</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.272457</td>\n",
       "      <td>0.269073</td>\n",
       "      <td>0.687546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.615457</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-0.758273</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.340928</td>\n",
       "      <td>1.656421</td>\n",
       "      <td>1.654327</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>3.390077</td>\n",
       "      <td>1.674636</td>\n",
       "      <td>-2.793593</td>\n",
       "      <td>-2.803529</td>\n",
       "      <td>1.016631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-1.436280</td>\n",
       "      <td>0.450904</td>\n",
       "      <td>0.458573</td>\n",
       "      <td>2.375174</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>3.584380</td>\n",
       "      <td>0.682556</td>\n",
       "      <td>0.662209</td>\n",
       "      <td>-0.046574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.957064</td>\n",
       "      <td>0.398311</td>\n",
       "      <td>0.406084</td>\n",
       "      <td>-0.785393</td>\n",
       "      <td>-0.315356</td>\n",
       "      <td>-0.630076</td>\n",
       "      <td>0.715259</td>\n",
       "      <td>0.695735</td>\n",
       "      <td>0.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.230915</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.138288</td>\n",
       "      <td>1.656421</td>\n",
       "      <td>1.654327</td>\n",
       "      <td>1.399914</td>\n",
       "      <td>3.390077</td>\n",
       "      <td>-0.612576</td>\n",
       "      <td>-2.793593</td>\n",
       "      <td>-2.803529</td>\n",
       "      <td>1.630332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.754424</td>\n",
       "      <td>-0.673160</td>\n",
       "      <td>-0.688286</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>-0.271995</td>\n",
       "      <td>0.019899</td>\n",
       "      <td>0.587485</td>\n",
       "      <td>0.613917</td>\n",
       "      <td>0.087347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>1.849776</td>\n",
       "      <td>-0.015454</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.446554</td>\n",
       "      <td>-0.323240</td>\n",
       "      <td>-0.324033</td>\n",
       "      <td>0.869512</td>\n",
       "      <td>0.839041</td>\n",
       "      <td>0.197979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>-3.391165</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.580537</td>\n",
       "      <td>-0.699088</td>\n",
       "      <td>-0.715220</td>\n",
       "      <td>-0.889533</td>\n",
       "      <td>-0.268053</td>\n",
       "      <td>-0.464343</td>\n",
       "      <td>0.564936</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>-0.989584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.811430</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>1.986695</td>\n",
       "      <td>0.466006</td>\n",
       "      <td>0.477363</td>\n",
       "      <td>-0.097784</td>\n",
       "      <td>-0.319298</td>\n",
       "      <td>0.807973</td>\n",
       "      <td>0.680695</td>\n",
       "      <td>0.649216</td>\n",
       "      <td>-0.306543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.615457</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-3.295474</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>-1.548942</td>\n",
       "      <td>-1.576753</td>\n",
       "      <td>-0.942372</td>\n",
       "      <td>-0.260169</td>\n",
       "      <td>-1.066454</td>\n",
       "      <td>-0.959707</td>\n",
       "      <td>-0.945663</td>\n",
       "      <td>-0.779952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.000473</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-1.004188</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>-0.717456</td>\n",
       "      <td>-1.312910</td>\n",
       "      <td>-1.307585</td>\n",
       "      <td>-0.372496</td>\n",
       "      <td>-0.315356</td>\n",
       "      <td>0.941927</td>\n",
       "      <td>-0.215431</td>\n",
       "      <td>-0.218956</td>\n",
       "      <td>-1.304895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>-3.391165</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>-0.993383</td>\n",
       "      <td>-1.001877</td>\n",
       "      <td>-0.507674</td>\n",
       "      <td>-0.283820</td>\n",
       "      <td>0.570615</td>\n",
       "      <td>0.277847</td>\n",
       "      <td>0.291028</td>\n",
       "      <td>-1.347435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.615457</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.139741</td>\n",
       "      <td>0.131338</td>\n",
       "      <td>-0.586040</td>\n",
       "      <td>-0.268053</td>\n",
       "      <td>-0.619700</td>\n",
       "      <td>0.791563</td>\n",
       "      <td>0.815099</td>\n",
       "      <td>0.246811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.230915</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.340928</td>\n",
       "      <td>1.115547</td>\n",
       "      <td>1.115816</td>\n",
       "      <td>0.493612</td>\n",
       "      <td>-0.287762</td>\n",
       "      <td>0.227648</td>\n",
       "      <td>-0.156073</td>\n",
       "      <td>-0.163981</td>\n",
       "      <td>1.254304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.923186</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>-0.138509</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>-4.898979</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>-0.957064</td>\n",
       "      <td>-1.430428</td>\n",
       "      <td>-1.425883</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>0.436899</td>\n",
       "      <td>-0.487757</td>\n",
       "      <td>-0.490870</td>\n",
       "      <td>-1.322268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.685103</td>\n",
       "      <td>0.689476</td>\n",
       "      <td>0.403560</td>\n",
       "      <td>-0.303530</td>\n",
       "      <td>0.372228</td>\n",
       "      <td>0.478256</td>\n",
       "      <td>0.463279</td>\n",
       "      <td>1.225381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.457738</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-1.027946</td>\n",
       "      <td>0.754424</td>\n",
       "      <td>0.231754</td>\n",
       "      <td>0.227235</td>\n",
       "      <td>2.526465</td>\n",
       "      <td>-0.287762</td>\n",
       "      <td>0.171827</td>\n",
       "      <td>0.769992</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>-0.511894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.923186</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>-2.539631</td>\n",
       "      <td>0.514815</td>\n",
       "      <td>0.534514</td>\n",
       "      <td>0.532129</td>\n",
       "      <td>0.197014</td>\n",
       "      <td>-0.283820</td>\n",
       "      <td>0.218670</td>\n",
       "      <td>0.598568</td>\n",
       "      <td>0.606903</td>\n",
       "      <td>0.852896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>-1.869867</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>-1.284851</td>\n",
       "      <td>0.483739</td>\n",
       "      <td>0.412126</td>\n",
       "      <td>1.233195</td>\n",
       "      <td>1.220136</td>\n",
       "      <td>0.199072</td>\n",
       "      <td>-0.220749</td>\n",
       "      <td>-0.589581</td>\n",
       "      <td>-0.454509</td>\n",
       "      <td>-0.391519</td>\n",
       "      <td>1.344447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age    Gender  Occupation  Dominant hand    coffee  physical  \\\n",
       "0   0.615457  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "1   0.000000  0.685994    0.727171       0.294884  0.204124 -0.231695   \n",
       "2  -0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "3  -0.307729  0.685994    0.727171       0.294884  0.204124 -1.284851   \n",
       "4  -0.307729 -1.457738    0.727171       0.294884  0.204124  0.821462   \n",
       "5  -0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "6  -0.923186  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "7   0.615457  0.685994   -1.869867       0.294884  0.204124 -0.758273   \n",
       "8   0.923186  0.685994   -1.004188       0.294884  0.204124 -1.284851   \n",
       "9   0.000000  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "10 -1.230915  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "11 -0.307729 -1.457738    0.727171       0.294884  0.204124  0.821462   \n",
       "12  0.307729  0.685994   -1.004188       0.294884  0.204124  0.821462   \n",
       "13  0.307729  0.685994    0.727171      -3.391165  0.204124 -1.284851   \n",
       "14 -0.307729  0.685994    0.727171       0.294884  0.204124 -1.811430   \n",
       "15  0.615457 -1.457738    0.727171       0.294884  0.204124 -1.284851   \n",
       "16  4.000473 -1.457738   -1.004188       0.294884  0.204124  0.821462   \n",
       "17 -0.307729  0.685994   -1.869867      -3.391165  0.204124  0.821462   \n",
       "18 -0.615457 -1.457738   -0.138509       0.294884  0.204124  0.821462   \n",
       "19 -1.230915 -1.457738   -0.138509       0.294884  0.204124  0.821462   \n",
       "20 -0.923186 -1.457738   -0.138509       0.294884 -4.898979  0.294884   \n",
       "21  0.307729  0.685994    0.727171       0.294884  0.204124  0.821462   \n",
       "22  0.000000 -1.457738    0.727171       0.294884  0.204124 -1.284851   \n",
       "23 -0.923186  0.685994   -1.869867       0.294884  0.204124 -1.284851   \n",
       "24  0.307729  0.685994   -1.869867       0.294884  0.204124 -1.284851   \n",
       "\n",
       "      stress  Internal control index   HR_mean  RMSSD_mean  SCL_mean  \\\n",
       "0   0.483739               -2.531632 -0.900394   -0.876707 -1.222782   \n",
       "1  -0.272103                1.986695 -1.646229   -1.646932 -1.230384   \n",
       "2   0.483739               -0.204009  0.884367    0.867364 -0.548374   \n",
       "3   0.483739               -0.204009  1.243265    1.247300  0.375704   \n",
       "4   0.483739                0.138288  0.122998    0.126018 -0.862919   \n",
       "5   0.483739                0.651734 -0.575141   -0.550986 -1.113142   \n",
       "6   0.483739               -0.101320 -1.023418   -1.017587 -0.207807   \n",
       "7   0.483739               -0.340928  1.656421    1.654327  1.227664   \n",
       "8   0.483739               -1.436280  0.450904    0.458573  2.375174   \n",
       "9   0.483739               -0.957064  0.398311    0.406084 -0.785393   \n",
       "10  0.483739                0.138288  1.656421    1.654327  1.399914   \n",
       "11  0.483739                0.754424 -0.673160   -0.688286  0.543763   \n",
       "12  0.483739                1.849776 -0.015454    0.000329 -0.446554   \n",
       "13  0.483739               -0.580537 -0.699088   -0.715220 -0.889533   \n",
       "14  0.483739                1.986695  0.466006    0.477363 -0.097784   \n",
       "15 -3.295474               -0.204009 -1.548942   -1.576753 -0.942372   \n",
       "16 -1.027946               -0.717456 -1.312910   -1.307585 -0.372496   \n",
       "17  0.483739               -0.204009 -0.993383   -1.001877 -0.507674   \n",
       "18  0.483739               -0.204009  0.139741    0.131338 -0.586040   \n",
       "19  0.483739               -0.340928  1.115547    1.115816  0.493612   \n",
       "20 -1.027946               -0.957064 -1.430428   -1.425883  0.071310   \n",
       "21  0.483739               -0.204009  0.685103    0.689476  0.403560   \n",
       "22 -1.027946                0.754424  0.231754    0.227235  2.526465   \n",
       "23 -2.539631                0.514815  0.534514    0.532129  0.197014   \n",
       "24  0.483739                0.412126  1.233195    1.220136  0.199072   \n",
       "\n",
       "      HR_min   SCL_min    HR_std  RMSSD_std   SCL_std  \n",
       "0  -0.319298 -1.004249  0.465365   0.439151 -0.949413  \n",
       "1  -0.295646 -0.971799 -1.217241  -1.219896 -1.822954  \n",
       "2  -0.264111 -0.312573  0.186334   0.249442  0.335381  \n",
       "3  -0.319298 -0.823730 -0.424820  -0.457861  1.405055  \n",
       "4  -0.307472 -0.768211  0.820475   0.816977  0.149815  \n",
       "5  -0.323240 -0.861158  0.741422   0.707874 -1.239744  \n",
       "6  -0.323240  0.021783  0.272457   0.269073  0.687546  \n",
       "7   3.390077  1.674636 -2.793593  -2.803529  1.016631  \n",
       "8  -0.323240  3.584380  0.682556   0.662209 -0.046574  \n",
       "9  -0.315356 -0.630076  0.715259   0.695735  0.187333  \n",
       "10  3.390077 -0.612576 -2.793593  -2.803529  1.630332  \n",
       "11 -0.271995  0.019899  0.587485   0.613917  0.087347  \n",
       "12 -0.323240 -0.324033  0.869512   0.839041  0.197979  \n",
       "13 -0.268053 -0.464343  0.564936   0.592349 -0.989584  \n",
       "14 -0.319298  0.807973  0.680695   0.649216 -0.306543  \n",
       "15 -0.260169 -1.066454 -0.959707  -0.945663 -0.779952  \n",
       "16 -0.315356  0.941927 -0.215431  -0.218956 -1.304895  \n",
       "17 -0.283820  0.570615  0.277847   0.291028 -1.347435  \n",
       "18 -0.268053 -0.619700  0.791563   0.815099  0.246811  \n",
       "19 -0.287762  0.227648 -0.156073  -0.163981  1.254304  \n",
       "20 -0.295646  0.436899 -0.487757  -0.490870 -1.322268  \n",
       "21 -0.303530  0.372228  0.478256   0.463279  1.225381  \n",
       "22 -0.287762  0.171827  0.769992   0.784510 -0.511894  \n",
       "23 -0.283820  0.218670  0.598568   0.606903  0.852896  \n",
       "24 -0.220749 -0.589581 -0.454509  -0.391519  1.344447  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_all_grouped.drop(['RMSSD_min'], axis=1, inplace=True)\n",
    "swell_all_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0346528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAHmCAYAAAB3bpYLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABn7ElEQVR4nO3dd3hUZdoG8PvMZGYy6b030kNJITSliYJYUGmKfe1+q8juWhdR184qrh0UVlfdRdFVrCyIiAoi0oJJIIX0kN57JlPP9wcyMiRgJu1MZu7fdeXCed4zZ57xJeHm8M57BFEURRARERER2RGZ1A0QEREREQ01hlwiIiIisjsMuURERERkdxhyiYiIiMjuMOQSERERkd1hyCUiIiIiu8OQS0RERER2x0nqBqTyyy+/QBRFKBQKqVshIiIioj7o9XoIgoC0tDSrn+uwV3JFUQTvg2HbRFGETqfjPDkozr9j4/w7Ns6/Yzt1/geT1xz2Su7JK7gTJkyQuBM6k+7ubuTl5SE2NhYuLi5St0MjjPPv2Dj/jo3z79hOnf/i4uIBn8dhr+QSERERkf1iyCUiIiIiu8OQS0RERER2hyGXiIiIiOwOQy4RERER2R2GXCIiIiKyOwy5RERERGR3GHKJiIiIyO4w5BIRERGR3WHIJSIiIiK7w5BLRERERHaHIZeIiIiI7A5DLhERERHZHYZcIiIiIrI7DLlEREREZHecpG7AEbR01aG0IROeLgGI9k+BIPDvFkRERETDiSF3mHXr2rHtyJvQGTQAAI2uA+PDZkncFREREZF94yXFYdbSVWsOuABwtGo3TKJRwo6IiIiI7B9D7jBzd/axeNyj70RtW4lE3RARERE5BobcYeah9oOva6hFrbQhS6JuiIiIiBwDQ+4IGOOfYvG4vPEojCaDRN0QERER2T+G3BEQ5Zds8Vhn7EF1S4FE3RARERHZP4bcEeDm7IUAj0iLWmljtkTdEBEREdk/htwRMsbPcsnC8aZcGIw6ibohIiIism8MuSMkym8CBAjmxwaTDhXN+RJ2RERERGS/GHJHiFrpjiCvGItaaSN3WSAiIiIaDgy5I+j0JQuVzcegM/RI1A0RERGR/WLIHUGRfuMgE+TmxybRgONNORJ2RERERGSfGHJHkMrJBaHe8RY1LlkgIiIiGnoMuSPs9CUL1S1F6NF3SdQNERERkX1iyB1h4b5JkMsU5sciTChvPCphR0RERET2hyF3hCnkKoT7JFrUShoypWmGiIiIyE4x5Erg9CULde1l6NK2SdQNERERkf1hyJVAqE8CFHLVKRURZY1HJOuHiIiIyN4w5ErASaZAhO84ixp3WSAiIiIaOpKG3PLyctx6661IS0vDeeedh7feess8VlFRgZtuugmpqam45JJLsGfPHovn7t27FwsWLEBKSgpuvPFGVFRUjHT7g3L6koXGjgp09DRJ1A0RERGRfZEs5JpMJtxxxx3w9vbGZ599hieeeAJvvPEGvvrqK4iiiLvvvht+fn7YvHkzrrjiCixfvhzV1dUAgOrqatx9991YvHgxPvnkE/j4+OCuu+6CKIpSvR2rhXjFQuXkYlErbciWqBsiIiIi+yJZyG1sbERSUhIef/xxREVFYfbs2TjnnHOQkZGBffv2oaKiAk8++SRiYmJw5513IjU1FZs3bwYAfPzxxxg/fjxuueUWxMXFYfXq1aiqqsKBAwekejtWk8nkiPSbYFErbeCSBSIiIqKh4CTVCwcEBODll18GAIiiiMOHD+PgwYP429/+hqysLIwdOxYuLr9d6UxPT0dmZiYAICsrC5MmTTKPqdVqjBs3DpmZmZg6dWq/exBFEd3d3UPyfgYixD0BBbX7zY9bumtR01QOT7W/ZD3ZEo1GY/ErORbOv2Pj/Ds2zr9jO3X+RVGEIAgDOo9kIfdU559/PqqrqzFnzhzMnz8fzz77LAICAiyO8fX1RW1tLQCgoaHhrOP9pdfrkZeXN7jmB0EURTjBGQb0mGu/FP6AQMV4yXqyRWVlZVK3QBLi/Ds2zr9j4/w7tpPzr1QqB/R8mwi5r776KhobG/H4449j9erV0Gg0vd6QUqmETqcDgN8d7y+FQoHY2NjBNT9I2soKFNb/djW3W16HxMSlA/5biz3RaDQoKytDVFQU1Gq11O3QCOP8OzbOv2Pj/Du2U+e/qqpqwOexiZA7YcKJtalarRb3338/lixZ0uufKHQ6HZydnQEAKpWqV6DV6XTw8PCw6nUFQbBYEiGF+OB0i5DbqW1Gj9gKX9dQCbuyLWq1WvJ5Iulw/h0b59+xcf4dm1qtHtRFP0k/ePbtt99a1GJjY6HX6+Hv74/GxsZex59cohAYGNjnuL//6FvL6ucWDjeVt0WNH0AjIiIiGhzJQm5lZSWWL1+Ouro6c+3o0aPw8fFBeno6cnJy0NPz21rVjIwMpKSc2Fs2JSUFGRkZ5jGNRoPc3Fzz+GgiCALG+Fv2XdqYBVE0SdQRERER0egnWcidMGECxo0bh4cffhhFRUXYtWsX1qxZg//7v//DlClTEBwcjJUrV6KwsBAbNmxAdnY2li5dCgBYsmQJDh8+jA0bNqCwsBArV65EWFiYVTsr2JLTQ26Xtg31Hccl6oaIiIho9JMs5Mrlcqxbtw5qtRrLli3DqlWrcMMNN+DGG280jzU0NGDx4sX48ssvsXbtWoSEhAAAwsLC8Nprr2Hz5s1YunQpWltbsXbt2lH7YS1vlyB4qi13i+CSBSIiIqKBk/SDZ4GBgXj99df7HIuMjMTGjRvP+NzZs2dj9uzZw9XaiDqxZCEZmcd/W6Nc1ngEU6IXQCbIJeyMiIiIaHSS7EouWTp9yUKPvhO1bSUSdUNEREQ0ujHk2ghPtX+vbcO4ZIGIiIhoYBhybcgY/2SLx+WNR2E0GSTqhoiIiGj0Ysi1IVF+lksWdMYeVLcWStQNERER0ejFkGtD3Jy9EOARaVHjkgUiIiIi6zHk2pgxp13NPd6UC4NRd4ajiYiIiKgvDLk2JtJvAgT8tt+vwaRDZUu+hB0RERERjT4MuTbGRemOIM8YixqXLBARERFZhyHXBp2+Z25F8zHoDD0SdUNEREQ0+jDk2qBI33EWdzoziQYcb8qRsCMiIiKi0YUh1wapFC4I8YqzqJU2ZkvUDREREdHow5Bro05fslDdWogefZdE3RARERGNLgy5NirCdyzkMoX5sSiaUN54VMKOiIiIiEYPhlwbpZCrEO6TaFErbeQuC0RERET9wZBrw06/MURtWym6te0SdUNEREQ0ejDk2rBQ7wQo5KpTKiI/gEZERETUDwy5NsxJrkCE7ziLGpcsEBEREf0+hlwbd/qShcaOCnT0NEvUDREREdHowJBr40K8YqFycrGolTZwyQIRERHR2TDk2jiZTI5Iv/EWtdKGTGmaISIiIholGHJHgdOXLLR016K1u06iboiIiIhsH0PuKBDoOQZqpbtFjUsWiIiIiM6MIXcUkAkyRPklW9RKG7MgiqJEHRERERHZNobcUeL0JQvtmkY0d1VL1A0RERGRbWPIHSX83cPhpvK2qJU2cM9cIiIior4w5I4SgiBgjL/l1dzSxmyIokmijoiIiIhsF0PuKDLmtHW5XdpWNHRUSNQNERERke1iyB1FvF2D4an2t6iVcM9cIiIiol4YckeRvpYslDUegUk0StQRERERkW1iyB1lTt9loUffidq2Uom6ISIiIrJNDLmjjKeLP3xcQyxq3GWBiIiIyBJD7igUfdqShfKmozCaDBJ1Q0RERGR7GHJHodPvfqYzaFDdWihRN0RERES2hyF3FHJz9kaAe6RFjUsWiIiIiH7DkDtKjfG3vJp7vDkXBqNOom6IiIiIbAtD7igV6ZcMAYL5scGoQ2VLvoQdEREREdkOhtxRykXpjiDPGIsalywQERERncCQO4qdvmShovkYdIYeibohIiIish0MuaNYpO94yAS5+bFJNKCiOVfCjoiIiIhsA0PuKKZSuCDEK86iVsIlC0REREQMuaPdmNNuDFHdWogefZdE3RARERHZBobcUS7CZyzkMifzY1E0obzpqIQdEREREUmPIXeUUzipEOadZFHjLgtERETk6Bhy7UD0aUsWattK0aVtk6gbIiIiIukx5NqBUO8EKOSqUyoi9pd8CVEUJeuJiIiISEoMuXbASa5AlN8Ei9rxphwU1h2SqCMiIiIiaTHk2om0yAuhcnKxqB0o+QrtmkaJOiIiIiKSDkOunXBReuDcuCUWNYNJh93HPoLJZJSoKyIiIiJpSBpy6+rqsGLFCkyZMgUzZ87E6tWrodVqAQBPP/00EhISLL42btxofu6WLVswd+5cpKSk4O6770Zzc7NUb8NmRPqOQ3zgFItaY2cFMit2StQRERERkTQkC7miKGLFihXQaDR4//338dJLL+H777/Hyy+/DAAoLi7Gfffdhz179pi/liw5caUyOzsbq1atwvLly/HRRx+hvb0dK1eulOqt2JTJ0Qvg4exnUTtS8T3q2sqkaYiIiIhIApKF3JKSEmRmZmL16tWIi4vDpEmTsGLFCmzZsgXAiZA7duxY+Pv7m7/UajUAYOPGjbj44ouxcOFCJCYm4vnnn8euXbtQUVEh1duxGQq5ErMSlkEQfptaESJ+LPgIOkOPhJ0RERERjRzJQq6/vz/eeust+PlZXnXs7OxEZ2cn6urqEBUV1edzs7KyMGnSJPPj4OBghISEICuLN0EAAD/3cKRFzLOodWpbsL/4C4k6IiIiIhpZTr9/yPDw8PDAzJkzzY9NJhM2btyIadOmobi4GIIg4M0338Tu3bvh5eWFm2++GYsWLQIA1NfXIyAgwOJ8vr6+qK2ttaoHURTR3d09+Ddjg6J9JuN4Ux4aO4+ba8UNv8DfdQwifMZL2Fn/aTQai1/JsXD+HRvn37Fx/h3bqfMviiIEQRjQeSQLuadbs2YNcnNz8cknnyAnJweCICA6OhrXX389Dh48iEcffRRubm6YN28eenp6oFQqLZ6vVCqh0+msek29Xo+8vLyhfBs2xdc0Hs2ohgkGc+1A2VdoqdFCKXM5yzNtS1lZmdQtkIQ4/46N8+/YOP+O7eT8n575+ssmQu6aNWvw3nvv4aWXXkJ8fDzi4uIwZ84ceHl5AQASExNRVlaGTZs2Yd68eVCpVL0CrU6nM6/Z7S+FQoHY2Nihehs2yatZhf1ln5kfm6BHs+IoZsfdAJlg2zvIaTQalJWVISoqyuq5pdGP8+/YOP+OjfPv2E6d/6qqqgGfR/KQ+9RTT2HTpk1Ys2YN5s+fDwAQBMEccE+Kjo7Gvn37AACBgYFobLS8yUFjYyP8/f2tem1BEODiMnquaA5EkstUNHSVoqQh01xr6CxHacshTAg7T7K+rKFWq+1+nujMOP+OjfPv2Dj/jk2tVg94qQIg8T65r7/+Oj788EO8+OKLuPTSS831V155BTfddJPFsfn5+YiOjgYApKSkICMjwzxWU1ODmpoapKSkjEjfo83UmCvgqvKyqP1SvgONnZXSNEREREQ0zCQLucXFxVi3bh1uv/12pKeno6Ghwfw1Z84cHDx4EG+//TaOHz+ODz74AJ9//jluueUWAMA111yDL774Ah9//DHy8/Px4IMP4rzzzkN4eLhUb8emqZzUmBl/FYDf/jZkEo3YfewjGIzWrWMmIiIiGg0kW66wc+dOGI1GvPHGG3jjjTcsxo4dO4ZXXnkFr776Kl555RWEhobiH//4B9LS0gAAaWlpePLJJ/Hqq6+ira0N06dPx1NPPSXF2xg1gjyjMSFsNo5U/mCutWsacLD0fzgndpF0jRERERENA8lC7h133IE77rjjjONz587F3Llzzzi+ePFiLF68eDhas1upEXNR3VqEplOWKRyr3Y8w7wSE+46VsDMiIiKioWXbH6+nISWXOWFWwjI4yRQW9Z+KNkOj65CoKyIiIqKhx5DrYDzV/pgcvcCi1qPvwp7CTyCKokRdEREREQ0thlwHFB84BeE+lssTqlqOIb/mZ4k6IiIiIhpaDLkOSBAETI9bDLXC3aJ+qGwrWrvrJOqKiIiIaOgw5DooZ4UbZsRfaVEzmgzYdexDGE2GMzyLiIiIaHRgyHVgod7xSAo+16LW0lWDw+XfSNQRERER0dBgyHVw6VEXw8sl0KKWU7Ub1a1FEnVERERENHgMuQ7OSa7ArISrIRPkFvU9Bf+FVt8tUVdEREREg8OQS/BxDUZ61EUWtW5dO/YWfcZtxYiIiGhUYsglAMDYkOkI9oq1qJU3HUFRfYZEHRERERENHEMuAQAEQYaZcVdB5eRiUd9f8iXaNU0SdUVEREQ0MAy5ZOai8sC5sYstagajDj8WfASTaJSoKyIiIiLrMeSShUi/8YgLnGRRa+g4jqzj30nUEREREZH1GHKplynRl8Hd2deill3xHerbyyXqiIiIiMg6DLnUi0KuwqyEZRBO+e0hQsTuYx9BZ+iRsDMiIiKi/mHIpT75u0cgNeICi1qnthn7S76UqCMiIiKi/mPIpTOaED4HAR6RFrXi+sMoa8yWqCMiIiKi/mHIpTOSCTLMjF8GhVxlUd9b9Bm6tG0SdUVERET0+xhy6azcnX0wLeYKi5rOoMGegv9CFE0SdUVERER0dgy59Lui/dMwxi/FolbTVoycqh8l6oiIiIjo7Bhy6XcJgoBpsQvhqvK0qB8u/waNHRUSdUVERER0Zgy51C8qJzVmxi8DIJhrJtGIXcc2cVsxIiIisjkMudRvQZ7RSA47z6LW0dOMn4s+gyiK0jRFRERE1AeGXLJKasRcBLhbbitW2piForpDEnVERERE1BtDLllFJpNjVsLVUMqdLer7Sr5Ea3e9RF0RERERWWLIJau5OXtjetxSi5rRpMcP+e/DYNRL1BURERHRbxhyaUAi/cYjMXiaRa21uw4HS7dI1BERERHRbxhyacAmjbkU3i5BFrVjtftR1nhEoo6IiIiITmDIpQFzkikwO/FaOMkUFvWfCjejo6dZoq6IiIiIGHJpkLxcAjD1tNv+6o092H3sQ5hMRom6IiIiIkfHkEuDFhuQjmj/VItaQ8dx/HJ8hzQNERERkcNjyKVBEwQB02IWwt3Z16J+pPIHVLUUSNQVEREROTKGXBoSSidnzE64BjJBblH/seC/6NZ1SNQVEREROSqGXBoyfu5hSI+6yKLWo+/EnoL/QhRNEnVFREREjmhQIbelpQVtbW1D1QvZgbEhMxDmnWhRq24txNGq3RJ1RERERI7IyZqDOzs78d///hc7d+5EdnY2DAYDAECpVCI5ORkXXHABFi9eDA8Pj2FplmyfIAiYEb8UX/7yKrp17eb64bJvEOgxBgEekRJ2R0RERI6iXyHXZDLhn//8JzZs2ICQkBCcd955WLZsGXx8fGA0GtHc3IycnBxs3rwZa9euxc0334w777wTcrn8909OdsdZ4YaZ8cuw/ehbAEQAgAgTdh3bhMvT/gSVk1raBomIiMju9SvkLlu2DLGxsfjwww8RFxfX5zGLFi0CABw5cgTvvfcerrrqKmzevHnoOqVRJdgrBinh5yOrYqe51qVtxd7CzTgv8ToIgiBhd0RERGTv+hVyn3zySSQlJfXrhBMmTMALL7yA3NzcQTVGo19KxPmobStGXXuZuVbedBQFtQeQEDxVusaIiIjI7vXrg2enBtzPP/8cOp2u1zHd3d149913zY/Hjh07+O5oVJMJcsxKuBoqJxeL+oHSr9DSVStRV0REROQI+hVym5ubUV1djerqaqxcuRKFhYXmxye/9u7dixdffHG4+6VRxlXlhelxSy1qRpMBP+R/AL2x91+WiIiIiIZCv5Yr7N69G3/9618hCAJEUcTSpUt7HSOKImbPnj3kDdLoF+E7Fkkh05FX/ZO51qapx4GSrzA9bomEnREREZG96lfIXbhwIUJDQ2EymfCHP/wBr776Kjw9Pc3jgiDAxcUF8fHxw9YojW6Toi5GXVspmruqzbXCuoMI9opFtH+KhJ0RERGRPer3PrmTJ08GAPz73//GxIkT4eRk1Ra75ODkMiecl3gtvsx8FYZTlin8XPQp/N3D4O7sK2F3REREZG+svuPZlClTsG3bNtTWnvjg0Lp167BgwQI89thj0Gq1Q94g2Q8PtR/OiVlkUdMbtdiVvwlGk0GiroiIiMgeWR1y161bh1WrVqG6uhoZGRl49dVXkZaWhv379+OFF14Yjh7JjsQEpCEmYKJFrbGzEofLv5GoIyIiIrJHVofczZs347nnnsPEiROxfft2pKam4qmnnsIzzzyDr7/+ejh6JDszLeYKeKj9LGo5VbtR2XxMoo6IiIjI3lgdcuvr65GWlgYA2Lt3L2bMmAEACA4ORnt7+9B2R3ZJIVdhdsK1kAmWt33+seC/6Nby9xARERENntUhNygoCKWlpSgvL0dRURGmT58OADh06BCCgoKGvEGyT75uIZg85lKLmtbQhR8LPoJJNEnUFREREdkLq0Pu1VdfjT//+c+4/vrrkZCQgLS0NLz//vt47LHHcNVVV1l1rrq6OqxYsQJTpkzBzJkzsXr1avOH1yoqKnDTTTchNTUVl1xyCfbs2WPx3L1792LBggVISUnBjTfeiIqKCmvfCkksMfgchPtY3hmvpq0YRyp/kKYhIiIishtWh9xbb70Vq1evxm233Wa+ja+HhwceffRR3Hrrrf0+jyiKWLFiBTQaDd5//3289NJL+P777/Hyyy9DFEXcfffd8PPzw+bNm3HFFVdg+fLlqK4+scdqdXU17r77bixevBiffPIJfHx8cNddd0EURWvfDklIEATMiFsKV5WnRT2z/FvUtZVJ0xQRERHZhQFtdnv++ecDOHG73/b2dlx22WVWn6OkpASZmZn46aef4Od34kNIK1aswHPPPYdZs2ahoqICH374IVxcXBATE4Off/4Zmzdvxj333IOPP/4Y48ePxy233AIAWL16NaZPn44DBw5g6tSpA3lLJBGVwgWz4q/B10fWQ8SJv6SIMGF3wSbMTbhD4u6IiIhotLL6Si5w4oYQM2bMwPTp0zF16lTMnDnTfFW3v/z9/fHWW2+ZA+5JnZ2dyMrKwtixY+Hi4mKup6enIzMzEwCQlZWFSZMmmcfUajXGjRtnHqfRJdAzCqkRcy1qXdo2HCr/klfniYiIaECsvpL74YcfYs2aNbj22msxefJkiKKIgwcP4sUXX4SbmxuWLl3ar/N4eHhg5syZ5scmkwkbN27EtGnT0NDQgICAAIvjfX19zTeg+L3x/hJFEd3d3VY9h4ZHjO9UVDUXor6zzFyrajsGUeECjWaMdI2RZDQajcWv5Fg4/46N8+/YTp1/URQhCMKAzmN1yH333Xfx0EMP4frrrzfX5s2bh8jISLz33nv9DrmnW7NmDXJzc/HJJ5/g3XffhVKptBhXKpXQ6U7cDlaj0Zx1vL/0ej3y8vIG1C8NPR9xPJpQDSN+m8cafRbySvyglnlJ1xhJqqysTOoWSEKcf8fG+XdsJ+f/9MzXX1aH3OrqasyaNatXfebMmXjuuecG1MSaNWvw3nvv4aWXXkJ8fDxUKhVaW1stjtHpdHB2dgYAqFSqXoFWp9PBw8PDqtdVKBSIjY0dUM80PPzb3PFj8SbzYxEmNAjZmJd4O2TCgFbX0Cil0WhQVlaGqKgoqNVqqduhEcb5d2ycf8d26vxXVVUN+DxWh9yQkBAcPXoUERERFvUjR470Wl/bH0899RQ2bdqENWvWYP78+QCAwMBAFBUVWRzX2NhoXqIQGBiIxsbGXuNJSUlWvbYgCBbrfkl6MS4paO6pRE7Vj+ZaW08dSlsyMCFstoSdkVTUajW/Tx0Y59+xcf4dm1qtHvBSBWCA++Q+8cQT+OCDD5Cfn4/8/Hy8//77ePLJJ7FkyRKrzvX666/jww8/xIsvvohLL/3txgApKSnIyclBT0+PuZaRkYGUlBTzeEZGhnlMo9EgNzfXPE6j28TI+fBysVxznXl8B9o1jWd4BhEREZElq6/k3njjjaiqqsKzzz4Lo9EIURTh5OSEq6++Gn/84x/7fZ7i4mKsW7cOd9xxB9LT09HQ0GAemzJlCoKDg7Fy5Urcdddd+P7775GdnY3Vq1cDAJYsWYK3334bGzZswJw5c7B27VqEhYVx+zA7IZc54dzYJdia/Ya5ZjQZsLfoU8wff/ug/lZHREREjsHqkCuTybBq1Sr86U9/QklJCQAgOjoabm5uVp1n586dMBqNeOONN/DGG29YjB07dgzr1q3DqlWrsHjxYkRGRmLt2rUICQkBAISFheG1117Ds88+i7Vr1yItLQ1r165l+LEjAR6RiPOfgsKGA+ZabVsJCusOIj5oioSdERER0WhgVcjNyspCQkICnJ2d4ebmhuTkZHzzzTcwmUxITU216oXvuOMO3HHHmTf7j4yMxMaNG884Pnv2bMyezTWa9mx8yPkoazwKvfjbNm8HS7cizDsRLirrPmRIREREjqXfa3Iff/xxXH311b1uuPDxxx/jmmuuMS8lIBoqCrkSoYp0i5re2IN9JV9I1BERERGNFv0KuR9//DG++OILrF69GpMnT7YYW79+PZ599ll8+OGH+Pzzz4ejR3Jg7vIgRPokW9SON+WgrPGIRB0RERHRaNCvkLtp0yY8+OCDWLhwIeRyueUJZDIsWrQId911Fz744INhaZIcW2rYhVA5uVrU9hd/Ca2Bd6sjIiKivvUr5JaVlWH69OlnPWbu3LnmD6IRDSWVkwumxlxmUdPoO3CodKtEHREREZGt61fIVSqVFnvWnsnpV3mJhsoYvxSEeSda1ArrDqG6tegMzyAiIiJH1q+QO27cOPzwww9nPWbnzp2Ijo4eip6IehEEAefELoRCrrKo/1z0KQxG3RmeRURERI6qXyH32muvxRtvvIHvv/++z/HvvvsO69atw7Jly4a0OaJTuaq8kB51kUWto6cZvxzfIVFHREREZKv6tU/uBRdcYL6jWVJSEiZOnAgPDw+0trbi8OHDKCgowLJly7Bw4cJhbpccXULQVJQ0ZKG+vcxcy63agzF+yfBzD5euMSIiIrIp/d4n96GHHsL69esRGBiI7du346233sJ3332HMWPG4O2338bjjz8+jG0SnSAIMpwbuxgy4bf13yJE/FS4GSaTUcLOiIiIyJZYdccz3mWMbIGXSwBSIi7AL+XfmGst3bU4WrUbyeFzJOyMiIiIbEW/ruS+9957MBr7f5XMYDDgnXfeGXBTRL9nQuhseLsEWdQyj+9EW3eDRB0RERGRLelXyK2srMRll12GTZs2obm5+YzHtbS04J133sHFF1+MysrKIWuS6HQymRzT45ZAgGCumUQDfiraDFE0SdgZERER2YJ+LVdYtWoVMjIy8PLLL+Ppp5/GuHHjEB8fD19fXxiNRjQ3NyM3NxeFhYVITU3FM888gylTpgx37+Tg/NzDMTZkOnKq95hr9e1lOFZ7AInB0yTsjIiIiKTW7zW56enp+M9//oPs7Gzs3LkTWVlZyMzMhCAICAgIwJw5c/DMM89g3Lhxw9kvkYXUyAtR3pSLTu1v/8KQUbYN4T5JcFV5StgZERERScmqD54BQHJyMpKTk4ejFyKrKeRKnBu3CN8cfdtc0xu1+LnoM1ww9g8QBOEszyYiIiJ71e8txIhsVYhXHGID0i1qlS35KG3MlqgjIiIikhpDLtmFydGXwlnhZlE7UPIlevRdEnVEREREUmLIJbugcnLBtJgrLGo9+i4cLP2fRB0RERGRlKwOuV1dvDJGtinSdzwifMZa1IrrD6OqpUCijoiIiEgqVofchQsXIicnZzh6IRoUQRAwLWYhFHKVRX1v0afQG7USdUVERERSsDrkajQaqNXq4eiFaNBcVB6YNOYSi1qXthWHT7kFMBEREdk/q7cQu/HGG7F8+XJcd911iIiIgLOzs8X45MmTh6w5ooGID5yMkvpM1LWXmmt51Xsxxi8FAR4REnZGREREI8XqkPviiy8CAJ566qleY4IgIC8vb/BdEQ2CIMgwPW4JvvjlZRhNhl+rIvYWbcZlqfdALrP6tz0RERGNMlb/ab9z587h6INoSHmo/ZAaMRcZZV+ba63ddThS+QNSI+ZK2BkRERGNBKvX5IaGhiI0NBSenp5oampCe3s7PD09zXUiWzEudCZ8XEMsatkV36Olq06ijoiIiGikWB1yTSYTVq9ejXPOOQfLli3DokWLcO655+KZZ56BKIrD0SPRgMgEOabHLYFwym9zk2jE3qLNMIkmCTsjIiKi4Wb1coX169dj8+bNeOCBBzBlyhSYTCYcPHgQa9euRWBgIG677bbh6JNoQHzdQjEubCaOVu4y1xo6jiO/5meMDZkuYWdEREQ0nKwOuR9//DH+9re/4bLLLjPXxo4dCx8fH7z22msMuWRzUsPn4nhjDtp7Gs21w2XbEeEzFm7O3hJ2RkRERMPF6uUKTU1NSElJ6VVPSUlBTU3NkDRFNJSc5AqcG7fYomYw6fBz8WdcYkNERGSnrA65UVFR2Lt3b6/6Tz/9xA+ekc0K8oxGfNAUi1pVSwFKGjKlaYiIiIiGldXLFW6++WY89thjqKiowMSJEwEAGRkZeP/99/Hggw8OeYNEQyU96mJUNOdBo+sw1w6UfIVQ7zg4K9wk7IyIiIiGmtUhd+HChWhtbcVbb72Ft99+GwDg5+eHP//5z7juuuuGvEGioaJyUmNazEJ8n/cfc01r6Mb+kq8wO+EaCTsjIiKioWZ1yN2yZQsWLVqEm266Cc3NzRBFEb6+vsPRG9GQi/Qdh0jfCShvOmKulTZkIdo/DeE+iRJ2RkREREPJ6jW5Tz75JBoaGgAAPj4+DLg06kyNuRxKJ7VF7eeiz9Cj75KoIyIiIhpqA/rgWUFBwXD0QjQiXJTumDzmUotat64Nu499yJtEEBER2QmrlyskJibi/vvvx1tvvYWoqCioVCqL8dWrVw9Zc0TDJTYgHSUNmahpLTLXqlsL8Uv5N0iPukjCzoiIiGgoWB1yS0tLkZ6eDgDmZQtEo40gCJgZfxW+ynzNYreFI5U/wNctFFF+EyTsjoiIiAbL6pD7pz/9CcnJyVAqlcPRD9GIcVF6YE7i9fj6yAaYRKO5vqfwY3i5BMDLJVDC7oiIiGgwrF6Te88996CwsHA4eiEacQEekZgSvcCiZjDq8F3ef6Az9EjUFREREQ2W1SHXx8cHHR0dv38g0SiREDQNsQHpFrV2TSN+LPgvRH4QjYiIaFSyernCrFmzcOedd2L27NmIjIzs9cGz5cuXD1lzRCNBEARMi1mIlq5aNHVVmesVzbnIrvwBKeHnS9gdERERDYTVIXf79u3w9fXF0aNHcfToUYsxQRAYcmlUcpIrMCfpenyV+Rq0hm5z/ZfyHfB1DUWYT4KE3REREZG1rA6533333XD0QSQ5N2dvzE68BjuO/gsixF+rInYf24QFqffAQ80bnxAREY0W/VqT29ra+rvH6HQ6fPPNN4Pth0hSIV5xmHjaPrk6Yw++z/sPDEadRF0RERGRtfoVcs855xw0NTVZ1B566CGLWnt7O/70pz8NbXdEEhgfOguRvpb75LZ012Jv0acQRfEMzyIiIiJb0q+Q29cf7Dt27EB3d/fvHkc02giCgBlxS+HlEmBRL2nIRF71TxJ1RURERNaweguxk/oKtIIgDKoZIluhcFJhTtINUMgtdw85WLoVtW0lEnVFRERE/TXgkEtk7zzV/pgZv8yiJsKEH/I/QJe2TaKuiIiIqD8YconOIsJ3bK99cnv0nfg+fyOMJoNEXREREdHv6XfIHc6lCDqdDgsWLMD+/fvNtaeffhoJCQkWXxs3bjSPb9myBXPnzkVKSgruvvtuNDc3D1t/5NhSIuYi1Ntyn9zGjgrsL/lSoo6IiIjo9/R7n9ynn37a4u5mer0ea9asgaurKwBAq9UOqAGtVov77rsPhYWFFvXi4mLcd999WLRokbnm5uYGAMjOzsaqVavwxBNPIDExEc888wxWrlyJ9evXD6gHorORCTLMSliGLZmvo6Pnt79MFdQegJ9bGOKDpkjYHREREfWlXyF38uTJaGhosKilpaWhpaUFLS0t5tqkSZOsevGioiLcd999fX6Irbi4GLfeeiv8/f17jW3cuBEXX3wxFi5cCAB4/vnnMWfOHFRUVCA8PNyqHoj6Q+XkgjlJN2Br1joYTHpzfV/xF/B2DYa/O3/fERER2ZJ+hdz//Oc/w/LiBw4cwNSpU/GXv/wFqamp5npnZyfq6uoQFRXV5/OysrJw++23mx8HBwcjJCQEWVlZVoVcURR7bYNGtkOj0Vj8KjVnwROTIi7DvrJPzTWTaMR3uf/BvMTb4axwlbA7+2Nr808ji/Pv2Dj/ju3U+RdFccBLZq2+re9Quvbaa/usFxcXQxAEvPnmm9i9eze8vLxw8803m5cu1NfXIyDAcg9TX19f1NbWWvX6er0eeXl5A2ueRkxZWZnULZxCDl95HJqMvy2v0ejbsTPn3xijnAVB4Gc5h5ptzT+NNM6/Y+P8O7aT869UKgf0fElD7pmUlJRAEARER0fj+uuvx8GDB/Hoo4/Czc0N8+bNQ09PT683rFQqodNZd9tVhUKB2NjYoWydhpBGo0FZWRmioqKgVqulbscsQYzHrsKNaOgsN9e6TA3QeVQhNexCCTuzL7Y6/zQyOP+OjfPv2E6d/6qqqgGfxyZD7sKFCzFnzhx4eXkBABITE1FWVoZNmzZh3rx5UKlUvQKtTqez+htBEAS4uLgMVds0TNRqtc3N0/ljb8BXma+iW9durhXU70OQ9xhE+6dI2Jn9scX5p5HD+XdsnH/HplarB7W7l03+26ogCOaAe1J0dDTq6uoAAIGBgWhsbLQYb2xs7PNDakTDQa10w5yk6yET5Bb1vYWfoKXLumUzRERENPRsMuS+8soruOmmmyxq+fn5iI6OBgCkpKQgIyPDPFZTU4OamhqkpPAKGo0cf/cITIu5wqJmMOnxXd5/oDXwA41ERERS6tdyhZUrV/b7hKtXrx5wMyfNmTMHGzZswNtvv4158+Zhz549+Pzzz/Hvf/8bAHDNNdfghhtuQGpqKiZMmIBnnnkG5513HrcPoxEXHzQFjR2VKKg7YK519DThx2Mf4YKxf+AH0YiIiCTSr5BbWVlp/m9RFHHo0CH4+flh7NixcHJyQn5+Purq6nDBBRcMSVPJycl45ZVX8Oqrr+KVV15BaGgo/vGPfyAtLQ3AiT16n3zySbz66qtoa2vD9OnT8dRTTw3JaxNZa2rM5WjuqkFjZ4W5VtlyDJnHdyItcp6EnRERETkuq/fJfeGFFxAYGIjVq1ebdzgwGo147LHHBrU4+NixYxaP586di7lz557x+MWLF2Px4sUDfj2ioSKXOWFO0vX4KvNV9Oi7zPWsip3wcwtFuO9YCbsjIiJyTFb/W+pHH32Eu+66y2ILL7lcjltvvRVbt24d0uaIRgtXlSdmJ1wL4bRvqd0FH6Fd03iGZxEREdFwsTrkKhQKVFdX96oXFxdzmw9yaMFeMZg05mKLmt6oxXd5/4HeqJWoKyIiIsdkdchdsGABVq1ahU8//RQFBQXIz8/HBx98gMceewzLli0bjh6JRo2xITMw5rR9clu76/BT4WaIoihRV0RERI7H6ptB3H///ejp6cHf/vY3GAwGiKIIlUqF66+/HsuXLx+OHolGDUEQcG7sErR21aGl+7f9cssas+HnFobxYbMk7I6IiMhxWB1ylUolnnzySTz00EMoLS2FIAgYM2YMlyoQ/UohV2JO0g3YkvkadMYecz2jbBu8XAIR5pMgYXdERESOYUCbePb09GDHjh3Yvn07QkNDcfToUbS0tAx1b0SjlofaF7MSrgHw244jIkTszHsPxfW/SNcYERGRg7A65DY2NuLSSy/F448/jrfffhsdHR3417/+hcsuuwzFxcXD0SPRqBTmk4C0CMtt8ETRhB8LPsKRyl1co0tERDSMrA65f//73xEXF4eff/4ZKpUKAPDcc88hLi4Oa9asGfIGiUaz5PA5iPZP7VXPKNuGAyVfwSSaRr4pIiIiB2B1yN23bx9WrFgBtVptrnl6euKhhx7C4cOHh7Q5otFOEGSYGX8VkkKm9xrLq9mLXfmbYDDpJeiMiIjIvlkdcru6us74ITODwTDohojsjSDIMGXMAkyKuqTXWHnTEew4+i9oDd0SdEZERGS/rA65kydPxqZNmyxqer0eb7zxBiZOnDhkjRHZE0EQMD5sFmbFXw2ZILcYq2svxbbs9ejStkrTHBERkR2yeguxhx56CNdddx0OHDgAvV6Pxx9/HCUlJejo6MDGjRuHo0ciuxEdkApnpRu+P+0uaK3ddfhf1jrMG3cLvF2DJOyQiIjIPlh9JTcmJgZffvklzjvvPEyfPh0ymQwXX3wxPv/8cyQmJg5Hj0R2JcQrFhdNuBNqhbtFvVvXjq3Zb6K2rUSizoiIiOyH1Vdyly9fjr/85S/405/+NBz9EDkEX7cQXJLyR+zIeQftmgZzXW/swTdH38ashGWI8kuWsEMiIqLRbUC7K5zcOoyIBs7d2QeXJP8fAtwjLeom0Ygf8jcht/oniTojIiIa/awOuYsWLcILL7yAwsJC6HS64eiJyGE4K1xx4fjbEOEz9rQREQdKvsKh0q0QuZcuERGR1axerrBr1y4cP34c27dv73M8Ly9v0E0RORInuQLnJV2P/cVf4ljtPouxo1W70a1rx/S4pZDLrP52JSIiclhW/6n5xz/+cTj6IHJoMkGGaTFXwFXlicPlln+BLGnIhEbXiTlJ10Pp5CxRh0RERKOL1SF30aJFw9EHkcMTBAHJ4XOgVrpjb+GnEPHbMoWatiJsO7Ie88bdDBelh4RdEhERjQ4D+vfPnTt3oqCgAEaj0VzT6XQ4cuQI3nnnnSFrjsgRxQVOglrpjh/y3ofB9Nu695auGvNeul4uARJ2SEREZPusDrkvvPAC3nrrLfj5+aGpqQmBgYFobGyE0WjEpZdeOhw9EjmcMO8EXDThDnyb+y569J3mepe2Fduy38QFY/+AAI/Is5yBiIjIsVm9u8JXX32Fhx9+GHv27EFAQAA++OAD7NmzBxMnTkR4ePhw9EjkkPzcw3BJ8h/h7uxrUdcaurH96D9R3pQjUWdERES2z+qQ29TUhPPPPx8AkJCQgOzsbHh5eeEvf/kLtm7dOuQNEjkyD7UvLkn+I/zcwizqRpMBP+RtRH7NvjM8k4iIyLFZHXI9PDzQ3d0NAIiIiEBRUREAICQkBHV1dUPbHRFBrXTD/Al3IMw7waIuQsS+4s9xuHw7RFGUqDsiIiLbZHXInTp1Kl544QXU1dUhJSUFX3/9NZqbm7F9+3b4+PgMR49EDk8hV+L8sTciLnBSr7Hsiu/xU+EnMJmMfTyTiIjIMVkdch988EHU19dj27ZtmD9/PpRKJaZPn47nn38ef/jDH4ajRyICIBPkODd2CVLCL+g1VlSfgZ1570Fv1ErQGRERke2xeneF4OBgfP7559BqtVAqlXj//ffx448/IigoCMnJycPRIxH9ShAEpEXOg4vKA/uKPoeI35YpVLUU4Osj/8TcsTdBrXSTsEsiIiLpWX0l9ySVSgUAUKvVuPDCCxlwiUZQQtBUzEm6AXKZwqLe1FmJLVmvo7I5X6LOiIiIbIPVV3ITExMhCMIZx/Py8gbVEBH1T4TvWMwffzt25r4LraHbXO/StuLb3HcR6TsOU6Ivg6vKS7omiYiIJGJ1yH322WctQq7BYEBZWRk+//xzPPjgg0PaHBGdXYBHBC5J/iN25PwLndoWi7HyphxUtRQiNWIuxoZMh0wml6hLIiKikWd1yF28eHGf9fHjx+Pjjz/GFVdcMeimiKj/PF38cUnKXdiV/z7q2sssxgwmHQ6VbUVx/WFMi12IQI8oSXokIiIaaQNek3u65ORkZGRkDNXpiMgKLkp3XDThDkyPWwqVk0uv8ZbuWmzLfhM/FX6CHn2XBB0SERGNLKuv5Palq6sLGzduhJ+f31CcjogGQBBkiAuchHCfJBwu246CugO9jimsO4TjTblIj7oIcYGTIAhD9vdcIiIimzJkHzwTBAFPPPHEkDRFRAPnrHDFuXGLERuYjp+LP0dLV43FuNbQjb1Fn6Kw7hDOiVkIH7cQiTolIiIaPoP+4BkAKBQKpKSkIDw8fMgaI6LBCfCIxGWpy5FX/TN+Of4NDEadxXhDx3F8lfk6kkLORVrEPCicVBJ1SkRENPSG7INnRGR7ZIIc40JnIMpvAg6WbkFZ4xGLcREm5FbvQVljNqZEL0Ck74SzbhFIREQ0Wlgdcl9//fV+H7t8+XJrT09Ew8BV5YnzEq9DVUsB9hV/gY6eJovxbl07fsj/ACFe8ZgWczk81FxfT0REo5vVIXf//v3Izs6GyWRCVFQUFAoFysrKoNFoEBwcbD5OEASGXCIbE+odjysm/hlHK3chu+IHmESDxXh1awE+P/wyksPPw/iw2XA67Y5qREREo4XVIXf69OkwGo146aWXEBgYCADo7OzEQw89hJiYGNx7771D3iQRDR0nmQKpEXMR7Z+KfcVfoLq10GLcJBqQefxbFNf/gnNiFiLEO06iTomIiAbO6v2D/vOf/+DRRx81B1wAcHNzw5///Gd89NFHQ9ocEQ0fD7Uf5o27BbMTroVa6d5rvKOnCd/kvI0f8j9At7Zdgg6JiIgGzuoruTqdDt3d3b3qDQ0NQ9IQEY0cQRAwxj8Zod7xyDy+A3nVeyFCtDimrDEbVS3HkBYxD4kh50Am8PbARERk+6y+kjt37lw88sgj2LdvH7q6utDZ2Yldu3bhsccew+WXXz4cPRLRMFM6OWNK9GVYkHoP/N0jeo3rjVocKN2CLZmvo779uAQdEhERWcfqK7mrVq3CPffcg5tuusm81ZAoirjkkkvwwAMPDHmDRDRyfN1CcEny/6Gw7hAOlW2DzqCxGG/uqsHW7DcQHzQZ6VEX9XkLYSIiIltgdch1c3PDO++8g+LiYhQWnvjAytixYxER0fvqDxGNPoIgQ3zQFET4jsWh0m0oqs847QgRBbUHUN1SiDlJ18PXLVSSPomIiM5mwDeuj4mJwZQpUyCTydDY2DiUPRGRDXBWuGFG/JW4eML/wcslsNd4p7YFW7PfQGHdIQm6IyIiOrt+h9y1a9di6tSpKC8vBwAcPnwYF154IVasWIFrr70WN998M3p6eoatUSKSRqBnFC5PXYFJUZfASaa0GDOaDPip8BPsLfoMRpPhDGcgIiIaef0KuR999BHefPNNXHXVVfD19QUAPPzww3B2dsaWLVuwa9cudHV1YcOGDcPaLBFJQyaTY3zYLCyceC8C3CN7jRfU7se27PXo0raOfHNERER96FfI/fjjj/HXv/4V9913H9zc3HDkyBGUlZXhhhtuQGxsLAIDA/HHP/4R//vf/4a7XyKSkJuzF+ZPuB1Jwef2GmvsrMCXv7yGmtYiCTojIiKy1K+QW1xcjOnTp5sf79u3D4IgYPbs2eZabGwsqqurB9SETqfDggULsH//fnOtoqICN910E1JTU3HJJZdgz549Fs/Zu3cvFixYgJSUFNx4442oqKgY0GsTkXXkMidMjbkcM+OXQX7abX+1hi58c/RtHKncBVEUz3AGIiKi4dfvNbkntwsDgEOHDsHT0xOJiYnmWldXF9RqtdUNaLVa3HvvveadGoATW5Ldfffd8PPzw+bNm3HFFVdg+fLl5hBdXV2Nu+++G4sXL8Ynn3wCHx8f3HXXXfxDlWgExQSk4dKUu+Du7GtRFyEio2wbfsjfCJ2B6/SJiEga/Qq58fHxOHz4MACgvb0d+/fvt7iyCwDbtm1DfHy8VS9eVFSEq666CsePW24uv2/fPlRUVODJJ59ETEwM7rzzTqSmpmLz5s0ATiyfGD9+PG655RbExcVh9erVqKqqwoEDB6x6fSIaHB/XYCxIXY5wn6ReY+VNOdiStRat3XUSdEZERI6uXyH3uuuuw5NPPolnn30Wt956K3Q6Hf7whz8AAOrq6vDWW2/h7bffxpVXXmnVix84cABTp07FRx99ZFHPysrC2LFj4eLy20bz6enpyMzMNI9PmjTJPKZWqzFu3DjzOBGNHJWTGucn3YC0yAsBCBZj7ZoGbMlci9KGbGmaIyIih9Wvm0Fcfvnl0Ol02LRpE2QyGV566SUkJycDANavX4///ve/uP3223HFFVdY9eLXXnttn/WGhgYEBARY1Hx9fVFbW9uv8f4SRRHd3d1WPYdGjkajsfiVbFuc7zS4K/ywr/Qz6Iy/zZnBpMOuYx+gpqUEyaFzIRP6t0qK8+/YOP+OjfPv2E6df1EULZbMWqPfdzxbunQpli5d2qt+55134p577oG3t/eAGuiLRqOBUmm5H6dSqYROp+vXeH/p9Xrk5eUNrlkadmVlZVK3QFYY4zQH5aa96BFbLeoF9ftQ1ViMcOU0KATnfp+P8+/YOP+OjfPv2E7O/+mZr7+svq3v6QIDe98JabBUKhVaW1stajqdDs7Ozubx0wOtTqeDh4eHVa+jUCgQGxs7qF5p+Gg0GpSVlSEqKmpAH2ok6Yw3peJwxVaUNmVa1LtMDSg3/oBzxiyFn1v4Wc/B+XdsnH/Hxvl3bKfOf1VV1YDPM+iQOxwCAwNRVGS512ZjY6N5iUJgYGCvWwk3NjYiKan3h1/ORhAEi3W/ZJvUajXnaRSanXQ1gmujsa/4C5hEo7mu0Xfgh8J/Y/KYBUgMnva7/wzF+XdsnH/Hxvl3bGq1esBLFQArthAbSSkpKcjJybG4TXBGRgZSUlLM4xkZGeYxjUaD3Nxc8zgR2Yb4oCm4JPn/4KrytKibRCP2l3yBHwv+C4PRumVGRERE/WGTIXfKlCkIDg7GypUrUVhYiA0bNiA7O9u8JnjJkiU4fPgwNmzYgMLCQqxcuRJhYWGYOnWqxJ0T0en83MNxWeo9CPbsvTSopOEX/C9rHdo1TRJ0RkRE9swmQ65cLse6devQ0NCAxYsX48svv8TatWsREhICAAgLC8Nrr72GzZs3Y+nSpWhtbcXatWsHdUmbiIaPs8IN88bfgglh5/Uaa+muxVeZr6GimR8CJSKioWMza3KPHTtm8TgyMhIbN2484/GzZ8+2uK0wEdk2mSBDetRF8HMLw57Cj6E3as1jemMPdua+h5Tw85ES0f9txoiIiM6Ef5IQ0YiK9BuPBanL4eUS0Gssq+I77Mx9F1o9968mIqLBYcglohHnqfbHpSl3I8ovuddYVUsBvsp8DS3dNRJ0RkRE9oIhl4gkoZCrMDvhGkweswDCaT+KOrUt+O7YO2g2lEIURYk6JCKi0Ywhl4gkIwgCxoXOwEUTboezws1izCgaUKU/hJ3H3kZl8zGGXSIisgpDLhFJLtBzDC5PXYEAj8heY83d1fg29x38L3sdqloKGHaJiKhfGHKJyCa4qDwwf/ztSAo+t8/xxo4K7Mj5F7Zlv4nq1kKGXSIiOiuGXCKyGXKZE6bGXI45idfDTeXT5zH1HeX45ujb2HZkPWpai0e4QyIiGi1sZp9cIqKTIv3Gw1cdhX1Ht6NFKEKXrqXXMfXtZdh+9J8I9BiDtMh5CPKMlqBTIiKyVQy5RGSTZIIM3k5RmJZ4IWo68pFV8R06tb3Dbl17Kb4+sgHBnjFIjZiHQM+okW+WiIhsDkMuEdk0mSBHXNBkxARMRFF9BrIqvkOXtrXXcTVtxag5UowQrzikRszt80NsRETkOBhyiWhUkMnkiA+aciLs1p0Iu926tl7HVbcWorq1ECFe8UiLnAt/9wgJuiUiIqkx5BLRqCKXOSEheCpiA9NRWHcQ2RXfo1vX3uu46tYCVLcWIMw7AakR8+DnHiZBt0REJBWGXCIaleQyJyQGn4PYwEkorD2A7MofoNF19DqusuUYKluOIdwnCakRc+HrFipBt0RENNIYcoloVHOSKZAUMh1xgVNQULsf2ZU/oEff2eu4iuY8VDTnIcJnLFIj5sLHLUSCbomIaKQw5BKRXXCSKzA2dAbig6bgWO1+HKn8AT36rl7HHW/OxfHmXET6jkNqxDx4uwZJ0C0REQ03hlwisitOciXGhc5EfNBUHKv5GUcqd0Nr6B12y5tyUN6Ugyi/CRgfOhu+bqEQBEGCjomIaDgw5BKRXVLIlRgfNhsJwdOQV/0zcqp2Q2vo7nVcWeMRlDUegbdLEOKDJiPaPw0qhYsEHRMR0VBiyCUiu6aQq5Acfh6Sgs9BXs1eHK3aDZ1B0+u4lu5a7C/5CgdLtyHSdxzigiYh2DMGgsC7nxMRjUYMuUTkEBROKiSHz0Fi8DnIq/4JOVU/Qmfs6XWcSTSgtDELpY1ZcFN5IzYwHXGBk+Cq8hr5pomIaMAYconIoSidnJEScQESQ85FfvVeFNQd7PMOagDQqW1B5vFvkXl8J0K94xAXOBnhPkmQy/ijk4jI1vEnNRE5JJWTGikRFyA5fA5qWotRUHcQx5tyYBKNfRwtoqqlAFUtBVA5uSImIA1xgZPh7Ro44n0TEVH/MOQSkUMTBBlCvOMQ4h2HHn0XShoyUVh7EC3dtX0erzV0Ibd6D3Kr98DfPQJxgZMwxi8FCifVCHdORERnw5BLRPQrZ4UrxoZMR1LwuWjqrERB3SGUNmRCb9T2eXxDx3E0dBzHgZItiPKbgLigyQhwj+RWZERENoAhl4joNIIgwM89HH7u4Zgy5lKUNR5BYd0h1LWX9nm8waRDUX0Giuoz4Kn2R1zgZMQETIRa6TbCnRMR0UkMuUREZ+EkVyI2MB2xgelo0zSgsO4QiusOQ6Pv6PP4Nk0DDpVtRUb51wj3SUJc4GSEesdBJshHuHMiIsfGkEtE1E+ean9MiroYEyMuRGXLMRTWHURl8zGIMPU6VhRNON6Ug+NNOXBReiA2cBLGhkyHs8JVgs6JiBwPQy4RkZVkMjkifMciwncsunXtKKo7jKK6Q2jvaezz+G5dO7IrvkNe9V6khJ+PpJBzuQ0ZEdEw409ZIqJBcFF6IDn8PEwIm4269lIU1h1CWeMRGE36XsfqjT04VLYV+TX7MGnMRYj0ncAPqRERDROGXCKiISAIAoI8oxHkGY2p0ZejtCELhXUH0dhZ2evYTm0zfsj/AAHukZg05lIEeERI0DERkX1jyCUiGmJKJ2ckBE9FQvBUNHfV4EjlDyhtyOp1XH1HObZmr0OUXzLSoy6Cu7OPBN0SEdknmdQNEBHZMx/XYMxOuAaXptyFAI/IPo8pa8zGZxn/wKHSrdAaNCPcIRGRfWLIJSIaAf7uEbh4wv/hvMTr4O7s22vcJBpxtGo3Pj20BnnVe2Ey9XV7YSIi6i8uVyAiGiGCICDKbwLCfZKQX/Mzso7vhM7YY3GM1tCN/SVfIq/mZ0yKuhjhPkn8cBoR0QDwSi4R0QiTy5wwLnQmFk96AEkh0yEIvX8Ut2sa8F3ev7H96D/R1FklQZdERKMbQy4RkUScFa6YGn0ZFk28FxG+4/o8pratBF9lvo4fC/6LLm3bCHdIRDR6cbkCEZHEPNR+OD/pBtS2leBg6VY09dp2TERx/WGUNR7B+NCZGB82Gwq5SpJeiYhGC17JJSKyEUGe0ViQchdmxi+Dq8qz17jRpEdWxXf49NALKKg9AJPY+3bCRER0AkMuEZENEQQZYgLSsGji/ZgYOb/PK7YafQf2Fn2Kr355FVUtBRJ0SURk+xhyiYhskJNcgeTwOVicfj8SgqZCQO8dFlq6a7Ej51/YkfMvtHTVSdAlEZHt4ppcIiIbpla645zYRUgMPheHyraiquVYr2OqWgpQ3VKIuKDJSI2YBxeluwSdEhHZFoZcIqJRwNs1EPPG3YzqlkIcLP0fWrprLcZFiCioPYCiugyE+SQiNmAiwrwTIZPJJeqYiEhaDLlERKNIiHccLvNagaK6DPxS/g00+g6LcZNoxPGmHBxvyoHKyRXRAamIDZgIH9cQ3lSCiBwKQy4R0SgjE2SID5qMMf7JOFq5G0erdsNo0vc6TmvoQl71T8ir/gneLkGIDUxHtH8q1FzOQEQOgCGXiGiUUshVSIuch/igKcg8vgMlDZkwmgx9HtvSXYuDpf/DodJtCPWOR2xgOsJ9kiCX8Y8BIrJP/OlGRDTKuao8MT1uKSaPWYCyxmwU1Wegvr28z2NFmFDZko/KlnwondQY45eC2MB0+LmFcTkDEdkVhlwiIjuhdHJGfNAUxAdNQbumEUX1h1Fcfxhd2tY+j9cZNDhWuw/HavfBU+2PmIB0xASk9XkjCiKi0YYhl4jIDnmo/TAx8kKkRcxFbVsJiuoPo7zxCAx9rN0FgDZNAw6Xf41fyrcj2CsWsQHpiPAdCye5coQ7JyIaGgy5RER2TBBkCPaKRbBXLKZFX4GypiMorj+M2raSPo8XIaK6tRDVrYVQyFWI8ktGbEA6AjwiuZyBiEYVhlwiIgehcFIhLnAS4gInoaOnGcW/Lmfo6Gnu83i9UYvCuoMorDsId2dfxAZMREzARLg5e49w50RE1rPp2/ru2LEDCQkJFl8rVqwAAOTm5uLKK69ESkoKlixZgqNHj0rcLRHR6OHu7IPUiLlYnP4ALp5wJ+ICJ0EhV53x+I6eJvxyfAc+OfQcvj6yAZUtxyCK4gh2TERkHZu+kltUVIQ5c+bgqaeeMtdUKhW6u7txxx134LLLLsPf//53bNq0CXfeeSd27NgBFxcXCTsmIhpdBEFAoOcYBHqOwdToy1HelIPi+sOobi0C0HeIrW0rQW1bCUK84jAp6mL4uIWMbNNERP1g0yG3uLgY8fHx8Pf3t6h/8sknUKlUePDBByEIAlatWoXdu3fj66+/xuLFiyXqlohodHOSKxETkIaYgDR0aVtRXP8LiuoPo13T0Ofx1a2F+DKzCLEBE5EWeSF3ZSAim2LTyxWKi4sRFRXVq56VlYX09HTzhyAEQcDEiRORmZk5sg0SEdkpV5UXksPnYNHEe3FJ8l1ICJoKpdy5jyNFFNVn4NOMF/BL+TfQG7Qj3isRUV9s9kquKIooLS3Fnj17sH79ehiNRlx00UVYsWIFGhoaEBsba3G8r68vCgsLrX6N7u7uoWybhpBGo7H4lRwL5992uDn5ISVkPsYHXYDy5iPIqfkBGn2HxTFGkx5ZFd/hWM1+jAs5D2N80yATBn4dhfPv2Dj/ju3U+RdFccA7u9hsyK2uroZGo4FSqcTLL7+MyspKPP300+jp6THXT6VUKqHT6ax6Db1ej7y8vKFsm4ZBWVmZ1C2QhDj/tsYZ0fK5aBQL0GDIhwlGi9EeQxcyjv8PRyt+RJAiGe6yoEFtPcb5d2ycf8d2cv5Pz3z9ZbMhNzQ0FPv374enpycEQUBSUhJMJhMeeOABTJkypVeg1el0cHbu65/SzkyhUPS6Iky2Q6PRoKysDFFRUVCr1VK3QyOM82/rJkCj70ROzS6UNh6GeNqH1LRiO8p1exDgPgYpofPg7RJk1dk5/46N8+/YTp3/qqqqAZ/HZkMuAHh5eVk8jomJgVarhb+/PxobGy3GGhsbERAQYNX5BUHgbgyjgFqt5jw5MM6/7XKBC2Z5Xonk7lk4VLoNlS35vY6p7yjFjvx/IiYgDRMj51v94TTOv2Pj/Ds2tVo9qH8JstkPnv3444+YOnWqxXqcvLw8eHl5IT09Hb/88ot5j0ZRFHH48GGkpKRI1S4RkcPycgnE3HE34cLxt8HHNbiPI0QU1x/Gpxkv4HD5dn44jYhGhM2G3LS0NKhUKjzyyCMoKSnBrl278Pzzz+O2227DRRddhPb2djzzzDMoKirCM888A41Gg4svvljqtomIHFaIVywuS70HM+KuhIvSo9e40aRHdsX32JyxBvk1+2ASjX2chYhoaNhsyHVzc8Pbb7+N5uZmLFmyBKtWrcKyZctw2223wc3NDevXr0dGRgYWL16MrKwsbNiwgf+kQUQkMUGQITYwHYvT78fEyPlwkvf+wEiPvhP7ij/HF4dfQUVzHu+cRkTDwqbX5MbFxeGdd97pcyw5ORmfffbZCHdERET94SRXIjl8DuICJyHz+E4U1B6ACJPFMW2aeuzMfQ/BnjGYNOYS+LqFStQtEdkjm72SS0REo59a6Y5zYhfiiol/RrhPUp/H1LQV46vM1/FjwX/RpW0d2QaJyG7Z9JVcIiKyD14uAbhg7B9Q01qMQ6Vb0dR1+rZAJz6cVtaYjXEhMxHjO0WSPonIfvBKLhERjZhgrxgsSL0bM+OX9bmdmNFkQHbl99ia8xoa9AVo72nkml0iGhBeySUiohElCDLEBKQh0nc8cqt/wpHK76E3Wm4rpjV0oxZZ+Do3C84KNwR5Rv/6NQae6oBB7Z1JRI6BIZeIiCThJFcgOfw8xAVOQlbFThyr2d/rw2nAid0YyhqzUdaYDQBwVrgi0ONE4A3yjIaXSwAEgf8wSUSWGHKJiEhSaqUbpsVcgaTgc3GobBsqmnPPenyPvgvlTUdQ3nQEAKByckHgr4E3yGMMvF2DGHqJiCGXiIhsg6eLPy4YeyNq20qQW7kX1S1FMKDnd5+nNXTjeFMOjjflAACUTmoEeowxX+n1dg2GjKGXyOEw5BIRkU0J8oyGhyIIuZpchEcHoU1Xjdq2UtS2laBb1/a7z9cZNKhozjVfEVbInRHoEWVe1+vjFgyZIB/ut0FEEmPIJSIimyQIAtydfRDoE4b4oCkQRRGd2mZz4K1tK+nXvrp6Yw8qW/JR2ZIPAFDIVQj0iELgr6HX1y2UV3qJ7BBDLhERjQonQq8v3J19ERc4CQDQ0dOMul9Db117KTp6mn/3PHqjFpUtx1DZcgwA4KbyRmLwNMQGToKzwnVY3wMRjRyGXCIiGrXcnX3g7uyD2MB0AECXttXiSm9HT9PvnqNT24JDZdvwy/EdiPZPRWLwufB1Cxnu1olomDHkEhGR3XBVeSEmIA0xAWkAgC5tG+raT4beUrRrGs74XKPJgMK6QyisO4QAj0gkBZ+LSN/xkMm4fpdoNGLIJSIiu+Wq8kS0fyqi/VMBAN269l+XN5Sipq34jKG3vr0c9e3lUCvdkRA0FfFBU+GidB/BzolosBhyiYjIYbgoPTDGPwVj/FMgiiIaOiqQX7MXZY1HYBKNvY7X6DqQefxbZFd8j0i/8UgKPhf+7hG84xrRKMCQS0REDkkQBAR4RCDAIwKTxlyKwtoDOFa7H9269l7HmkQjShuyUNqQBV/XUCSGnIMxfilwkisk6JyI+oMhl4iIHJ6L0h0pERdgQth5KG/KQX7NXtS1l/V5bFNXFX4q/ASHSrciLmgyEoOmwc3Ze2QbJqLfxZBLRET0K5lMjjH+yRjjn4ymzmrk1/yMkoZMGE36XsdqDd04WrkLOZW7Ee6ThKSQcxHkGcOlDEQ2giGXiIioD75uIZgetwSToi5GYd0h5Nf8jE5tS6/jRIg43pyL48258FQHICnkHMQETIRCrpKgayI6iSGXiIjoLFQKF4wPm4WxoTNQ1ZyPvJqfUd1a2OexbZp67Cv+AhllXyM2IB2JIefAU+0/wh0TEcCQS0RE1C8yQYZw37EI9x2L1u56HKvZh6L6DOiN2l7H6o1a5NXsRV7NXoR4xSMpeBpCvRO45y7RCGLIJSIispKXSwCmxlyOtMgLUVz/C/Jr9qLtDHvuVrcWoLq1AEq5M8J8khDpOw4h3vFQyJUj3DWRY2HIJSIiGiClkzOSQs5BYvA01LQVIa96Lyqa8wGIvY7VGXtQ0vALShp+gVzmhBCveET6jkO4TxJUCpeRb57IzjHkEhERDZIgCAjxikOIVxw6eppxrGYfCuoOQmfQ9Hm80WRARXMuKppzIUCGIM8xiPAdhwjfcXBVeY5w90T2iSGXiIhoCLk7+2DSmEuQGjEXpQ1ZOFZ3AI0dFWc8XoQJNW3FqGkrxv6SL+HnFo4I33GI9B0HTxd+aI1ooBhyiYiIhoGTXIm4oMmIC5qMLm0bjjfl4nhTDmrbSiDCdMbnNXZWoLGzAofLv4anOgCRv17h9XUL5R68RFZgyCUiIhpmripPJIWcg6SQc6DVd6OiOQ/lTTmobi2A0WQ44/PaNPXIrqxHduX3cFV5IsLnROAN9IyCTOBODURnw5BLREQ0glQKF8QGpiM2MB16ow7VLQUob8pBZXMedMaeMz6vS9tm3pZM5eSCcJ8kRPiOQ4hXHJzkihF8B0SjA0MuERGRRBRyJSL9xiPSbzxMJiNq20pQ3pSD48050Og6zvg8raEbRfUZKKrPgJNMiVDveET6jkeg5xi4KN0hCLIRfBdEtokhl4iIyAbIZHKEeMchxDsO08TL0dBRgeNNOShvykFHT9MZn2cw6VDedBTlTUdPnEdwgruzz4kvtS88nH3g7uwLd2dfuDl7Qy7jH/3kGPg7nYiIyMYIggwBHpEI8IhEetTFaO2uMwfe5q7qsz7XJBrQpqlHm6YeaOl1ZriqPOHxa+h1V58MwCd+VTo5D9t7IhppDLlEREQ2TBAEeLsGwds1CCkRF6Cjp/nXnRqOoq69HH3deOLMRHRpW9GlbUVNW3GvUZWTK9zVPr+G4F8DsPpEIFYr3Li7A40qDLlERESjiLuzD8aFzsC40BnQ6DpR0fzb1mQGk35Q59YauqDt6OpzX18nmRLuzj7wUPshyDMG4T6JcHP2HtTrEQ0nhlwiIqJRSq10Q3zQFMQHTYEoitDoOtDR04T2niZ09DSjo6cJHZoTv2oN3YN6LYNJh5buWrR016K86Sj2l3wBb5cghPskIcwnEX7u4ZDxA29kQxhyiYiI7IAgCHBRecBF5YFAzzG9xnWGnhOht6cJ7b8G35NfXdp2WLfs4YSToTe78ns4K1wR6p2AcJ8khHjFcX0vSY4hl4iIyAEonZzh6xYKX7fQXmNGk+HXK78nr/6eciW4pwUm8cw3rDipR9+F4vrDKK4/DJkgR6DnGIR7JyLcNwnuzr7D8ZaIzoohl4iIyMHJZU7wcgmAl0tArzFRNKFb1452zYmrvrVtpahqOXbW5Q8m0Yia1iLUtBbhQOkWeKoDEO6TiHCfJPh7RPBubTQiGHKJiIjojARBBleVF1xVXghGDOKDpsAkmtDQfhwVLXmobM5Ha3fdWc/RpqlHW1U9jlbthsrJBaHe8QjzSUKodxxUTi4j9E7I0TDkEhERkVVkggyBnlEI9IzCpKiL0dHThMrmfFQ056O2rQQm0XjG52oN3ShpyERJQyYEnDhPmPeJq7yeLv4j+C7I3jHkEhER0aC4O/siKWQ6kkKmQ2/Qorq1EBXNeahsyUePvuuMzxNhQm1bCWrbSnCobCs8nP0Q5pMIf9cxEEXTCL4DskcMuURERDRkFE4qRPqNR6TfeIiiCY2dlahozkNFcz5aumrO+tz2nkbkVu8BsAcCZKjM2wMft2B4uQT+umY4EG7OPtyqjPqFIZeIiIiGhSDI4O8eAX/3CEyMnI/OnlZUtuSjsjkP1a3FZ921QYQJrZo6tGos1/vKZU7wVAf8GnwD4e0SAC/XQLipvCEw/NIpGHKJiIhoRLg5eyExeBoSg6dBb9ShprXoxLKG5nxo9B39OofRZEBzVzWau6ot6k4yBTxdfgu/5iu/Ki+GXwfFkEtEREQjTiFXIsJ3LCJ8x0IUTWjqqkZF04l1vE2dVVafz2DSo6mzqtdznWTKX8NvALzNATgQriovCIIwVG+HbBBDLhEREUlKEGTwcwuDn1sY0iLnoaW9Edn5B+EV6IJufQtau+vQ2l03oFsTG0w6NHVWoqmz0qLuJFfCSx0ID7Uf3J194KH2hbvziS9nhSsDsB1gyCUiIiKbonJygZs8AHH+SXBxObGPriiK6NF3/hp4683Bt7W7fmDh16hDY2cFGjsreo05yZVwd/aFh7MP3J394K72+TUA+8BV5cUPvo0SDLlERERk8wRBgFrpDrXSHcFesea6KIrQmMPvKV9dddAZewb0WgajDi1dNX3uBiET5HBz9jaHXndnX/NVYDdnbzjJFAN+jzS0GHKJiIho1BIEAS5Kd7go3RFyevjVdaC1uw4tvwbftu56tHTXQT/A8AucuGVxu6YR7ZrGvrqBi9Kj1/IHd2dvqJUeUCvdeEvjEcSQS0RERHZHEAS4qDzgovJAiHecuS6KIrp17ebQ29HTjI6eJrT3NKOzp/msd2v7fSK6dW3o1rWhrr20r67grHCFi9IDLkp3qPv81QNqhRtkMobhwRrVIVer1eKJJ57AN998A2dnZ9xyyy245ZZbpG6LiIiIbJQgCHBVecJV5YlQ73iLMZNoQre2DR09TejoaUa7punX/z7xWG/UDvLVT6wr7tF3ovnMN4LDyTCsVrqfEojdfw3A7nBReUCtOHFlWC4b1VFuWI3q/zPPP/88jh49ivfeew/V1dV46KGHEBISgosuukjq1oiIiGiUkQkyuDl7w83ZG8GnjZ344FvXKQG40XwVuKOnGT36ziHs5Lcw/Ht3iVM5uZqvAiudnKGQKyGXKeAkV0IhO+W/5Uo4yZSQyxVQyJRw+vWxk1zx669KyAS5Xe0qMWpDbnd3Nz7++GP885//xLhx4zBu3DgUFhbi/fffZ8glIiKiIXXig29uUCvdEOAR2Wtcb9Ci/ZSrvh2/XgVu72lCt7YdIkzD0pfW0AWtoQst3bWDPpcAmUXodfo1IJ8ahtVKN8QETISvW+gQdD+8Rm3Izc/Ph8FgQFpamrmWnp6ON998EyaTCTIZt/cgIiKikaFwUsHXLQS+biG9xkTRhB59F7p1HdDoOtCta4dG1w6NvgPd2nZ06ztOPNZ1DnJN8OCIMEFv1J5YlqE/83EFtQdxxcQ/w93ZZ+SaG4BRG3IbGhrg7e0NpVJprvn5+UGr1aK1tRU+Pr//P14URXR3W7+3Ho0MjUZj8Ss5Fs6/Y+P8Ozb7nH851DIvqJ294OPc9xGiKEJn1ECj60CPoQMafSc0+g709PGrlGHYYNKhuqkE4d5neCODdOr8i6I44CUUozbkajQai4ALwPxYp9P16xx6vR55eXlD3hsNrbKyMqlbIAlx/h0b59+xcf5VEKCCGn5QnyzJAVEmwgg9DKIGerEHBlEDg9gDIwwwiQaIMML063+bzP9tWRNhgAhxQF3JoUBztQadtcOboU7O/+l5r79GbchVqVS9wuzJx87O/fubhUKhQGxs7O8fSJLQaDQoKytDVFQU1Gr17z+B7Arn37Fx/h0b539kmEQjDEY9jCY9DCYdDCY9jOZf9TD8+mU06WAwnjjGSa5EmFcSPJz9hq2vU+e/qqpqwOcZtSE3MDAQLS0tMBgMcHI68TYaGhrg7OwMDw+Pfp1DEATz7QLJdqnVas6TA+P8OzbOv2Pj/Ds2tVo9qN0eRu2ns5KSkuDk5ITMzExzLSMjAxMmTOCHzoiIiIgc3KhNg2q1GgsXLsTjjz+O7OxsfPvtt/jXv/6FG2+8UerWiIiIiEhio3a5AgCsXLkSjz/+OP7whz/Azc0N99xzDy688EKp2yIiIiIiiY3qkKtWq/Hcc8/hueeek7oVIiIiIrIho3a5AhERERHRmTDkEhEREZHdYcglIiIiIrvDkEtEREREdochl4iIiIjsDkMuEREREdkdhlwiIiIisjsMuURERERkdxhyiYiIiMjuMOQSERERkd1hyCUiIiIiuyOIoihK3YQUDh8+DFEUoVQqpW6FzkAURej1eigUCgiCIHU7NMI4/46N8+/YOP+O7dT51+v1EAQBEydOtPo8TsPQ26jAbxrbJwgC/xLiwDj/jo3z79g4/47t1PkXBGHAmc1hr+QSERERkf3imlwiIiIisjsMuURERERkdxhyiYiIiMjuMOQSERERkd1hyCUiIiIiu8OQS0RERER2hyGXiIiIiOwOQy4RERER2R2GXLI5O3bsQEJCgsXXihUrpG6LhplOp8OCBQuwf/9+c62iogI33XQTUlNTcckll2DPnj0SdkjDra/fA08//XSvnwcbN26UsEsaanV1dVixYgWmTJmCmTNnYvXq1dBqtQD4M8ARnG3+B/v977C39SXbVVRUhDlz5uCpp54y11QqlYQd0XDTarW47777UFhYaK6Jooi7774b8fHx2Lx5M7799lssX74cW7duRUhIiITd0nDo6/cAABQXF+O+++7DokWLzDU3N7eRbo+GiSiKWLFiBTw8PPD++++jra0NDz/8MGQyGR588EH+DLBzZ5v/hx56aNDf/wy5ZHOKi4sRHx8Pf39/qVuhEVBUVIT77rsPp99hfN++faioqMCHH34IFxcXxMTE4Oeff8bmzZtxzz33SNQtDYcz/R4ATvw8uPXWW/nzwE6VlJQgMzMTP/30E/z8/AAAK1aswHPPPYdZs2bxZ4CdO9v8nwy5g/n+53IFsjnFxcWIioqSug0aIQcOHMDUqVPx0UcfWdSzsrIwduxYuLi4mGvp6enIzMwc4Q5puJ3p90BnZyfq6ur488CO+fv746233jIHnJM6Ozv5M8ABnG3+h+L7n1dyyaaIoojS0lLs2bMH69evh9FoxEUXXYQVK1ZAqVRK3R4Ng2uvvbbPekNDAwICAixqvr6+qK2tHYm2aASd6fdAcXExBEHAm2++id27d8PLyws333yzxT9d0ujm4eGBmTNnmh+bTCZs3LgR06ZN488AB3C2+R+K73+GXLIp1dXV0Gg0UCqVePnll1FZWYmnn34aPT09eOSRR6Ruj0bQyd8Hp1IqldDpdBJ1RCOtpKQEgiAgOjoa119/PQ4ePIhHH30Ubm5umDdvntTt0TBYs2YNcnNz8cknn+Ddd9/lzwAHc+r85+TkDPr7nyGXbEpoaCj2798PT09PCIKApKQkmEwmPPDAA1i5ciXkcrnULdIIUalUaG1ttajpdDo4OztL0xCNuIULF2LOnDnw8vICACQmJqKsrAybNm1iyLVDa9aswXvvvYeXXnoJ8fHx/BngYE6f/7i4uEF//3NNLtkcLy8vCIJgfhwTEwOtVou2tjYJu6KRFhgYiMbGRotaY2Njr3++JPslCIL5D7iToqOjUVdXJ01DNGyeeuopvPPOO1izZg3mz58PgD8DHElf8z8U3/8MuWRTfvzxR0ydOhUajcZcy8vLg5eXF3x8fCTsjEZaSkoKcnJy0NPTY65lZGQgJSVFwq5oJL3yyiu46aabLGr5+fmIjo6WpiEaFq+//jo+/PBDvPjii7j00kvNdf4McAxnmv+h+P5nyCWbkpaWBpVKhUceeQQlJSXYtWsXnn/+edx2221St0YjbMqUKQgODsbKlStRWFiIDRs2IDs7G0uXLpW6NRohc+bMwcGDB/H222/j+PHj+OCDD/D555/jlltukbo1GiLFxcVYt24dbr/9dqSnp6OhocH8xZ8B9u9s8z8U3/+C2NfGhEQSKiwsxLPPPovMzEy4urri6quvxt13322xhIHsU0JCAv79739j6tSpAIDy8nKsWrUKWVlZiIyMxMMPP4xzzz1X4i5pOJ3+e+Dbb7/Fq6++irKyMoSGhuIvf/kLLrzwQom7pKGyYcMG/OMf/+hz7NixY/wZYOd+b/4H+/3PkEtEREREdofLFYiIiIjI7jDkEhEREZHdYcglIiIiIrvDkEtEREREdochl4iIiIjsDkMuEREREdkdhlwiIiIisjsMuURERERkdxhyiYgG6YYbbsDixYvPOP7II49g/vz5v3ue1157Deeff/5QtjYgmzdvxowZM5CcnIwdO3b0Gv/rX/+KG264oVd969atGDt2LB599FGYTKaRaJWI6IwYcomIBmnp0qXIyclBcXFxrzGtVouvv/4aS5culaCzgXnuuecwc+ZMbNu2DTNmzOjXc7Zu3YoHHngA11xzDZ588knIZPzjhYikxZ9CRESDNH/+fLi7u+Orr77qNfbtt99Co9Fg4cKFI9/YALW1tWHSpEkIDQ2FWq3+3eO//vprPPDAA7jhhhvw6KOPQhCEEeiSiOjsGHKJiAbJ2dkZl156KbZs2dJr7LPPPsPs2bPh7++PgoIC3HnnnZg8eTLGjx+PCy64AP/617/OeN6EhAR8+umnZ619//33WLx4MZKTkzFv3jy8/PLL0Ol0Zzyn0WjEu+++i/nz52PChAmYP38+Nm3aBACorKxEQkICAODhhx/u19KJ7du347777sOtt96Kv/71r797PBHRSGHIJSIaAkuWLEFFRQV++eUXc62hoQF79+7FlVdeCY1Gg1tuuQVeXl748MMPsWXLFlx00UV47rnnkJeXN6DX3L17N/785z/jqquuwpYtW/C3v/0N27ZtwwMPPHDG5/z973/HunXrsHz5cnz11Ve47rrr8Mwzz+Ddd99FcHAw9uzZA+BEyP3kk0/O+vrffPMN7r33XqSmpuLee+8d0HsgIhouDLlEREMgOTkZ8fHxFksWvvzyS/j6+mLWrFnQaDS48cYb8dhjjyEmJgZRUVFYsWIFAODYsWMDes0333wTV111Fa6++mpERERgxowZeOKJJ/D111+jsrKy1/GdnZ3YtGkTVqxYgcsuuwxRUVG48cYbce2112LDhg2QyWTw9/cHALi7u8PHx+eMr11YWIh7770XU6dOxaFDh/Dtt98O6D0QEQ0XJ6kbICKyF0uWLMH69evx8MMPw8nJCZ9//jkWLVoEuVwOHx8fXHvttdiyZQtyc3Nx/Phx5OfnA8CAdyLIzc1Fdna2xRVXURQBAMXFxQgLC7M4vqSkBHq9Hunp6Rb1KVOm4L333kNTUxP8/Pz69dotLS144IEHcNttt+H222/HqlWrMH78eAQFBQ3ovRARDTWGXCKiIXL55ZfjhRdewE8//QR/f38UFhbi9ddfB3Bi6cKyZcvg4+OD888/HzNmzMCECRMwe/bsfp/fYDBYPDaZTLjtttuwaNGiXseevCJ7qpMB+HQnQ7aTU///SJg4cSJuu+02AMCzzz6LBQsW4P7778d7770HuVze7/MQEQ0XLlcgIhoiJwPs1q1b8b///Q+TJ09GZGQkAGDLli1obW3Fpk2bcNddd2HevHloa2sDcObwqVAo0NnZaX5cXl5uMR4XF4fS0lJERkaav2pra/H888+jq6ur1/liYmKgUCiQkZFhUT906BD8/f3h6enZ7/d6aiD29/fHU089hYMHD2LdunX9PgcR0XBiyCUiGkJLly7F999/j+3bt1vsjRsUFASNRoOvv/4a1dXV2LNnj/nDWmfaDSE1NRUff/wx8vLykJubi8cffxxKpdI8fvvtt2P79u14/fXXUVpaip9//hkrV65ER0dHn1dy3dzcsGzZMrz66qvYsmULysvL8f777+ODDz7ALbfcMqitvy688EIsWrQIb7zxBg4ePDjg8xARDRUuVyAiGkIzZsyAi4sLWltbLe5ydtFFFyEnJwd///vf0dnZidDQUFx55ZXYuXMnjhw5gmuuuabXuR5//HE8/vjjuOqqqxAQEIA//elPqK2ttTjnSy+9hPXr1+PNN9+El5cXzj//fNx///1n7G/lypXw9vbGCy+8gMbGRkRFReGxxx7DVVddNej3/sgjj+DAgQO4//778cUXX8DLy2vQ5yQiGihBPNO/kxERERERjVJcrkBEREREdochl4iIiIjsDkMuEREREdkdhlwiIiIisjsMuURERERkdxhyiYiIiMjuMOQSERERkd1hyCUiIiIiu8OQS0RERER2hyGXiIiIiOwOQy4RERER2Z3/B33Zkhzj6wq/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clustering(swell_all_grouped, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d720db1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "silhouette(swell_all_grouped, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be855ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster\n",
       "8          6\n",
       "2          5\n",
       "0          3\n",
       "3          2\n",
       "4          2\n",
       "7          2\n",
       "1          1\n",
       "5          1\n",
       "6          1\n",
       "9          1\n",
       "10         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 11, max_iter = 500, random_state = 0)\n",
    "y = kmeans.fit_predict(swell_all_grouped)\n",
    "y = pd.DataFrame(y, columns=[\"Cluster\"])\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6652ed",
   "metadata": {},
   "source": [
    "####  Visualization with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ad9cfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x203af170190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "kmeans = KMeans(n_clusters = 8, max_iter = 500, random_state = 0)\n",
    "model = kmeans.fit(swell_all_grouped)\n",
    "\n",
    "# Choose a perplexity value\n",
    "perplexity_value = 20  # Adjust this value as needed\n",
    "\n",
    "tsne = TSNE(perplexity=perplexity_value).fit_transform(swell_all_grouped)\n",
    "plt.scatter(x = tsne[:, 0], y = tsne[:, 1], c=model.labels_, cmap='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4ffe04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PP6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PP7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PP8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PP9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PP10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PP11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PP12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PP13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PP14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PP15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PP16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PP17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PP18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PP19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PP20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PP21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PP22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PP23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PP24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PP25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Cluster\n",
       "0    PP1        8\n",
       "1    PP2        1\n",
       "2    PP3        8\n",
       "3    PP4        0\n",
       "4    PP5        2\n",
       "5    PP6        8\n",
       "6    PP7        8\n",
       "7    PP8        3\n",
       "8    PP9        9\n",
       "9   PP10        8\n",
       "10  PP11        3\n",
       "11  PP12        2\n",
       "12  PP13        2\n",
       "13  PP14        4\n",
       "14  PP15        7\n",
       "15  PP16       10\n",
       "16  PP17        5\n",
       "17  PP18        4\n",
       "18  PP19        2\n",
       "19  PP20        2\n",
       "20  PP21        6\n",
       "21  PP22        8\n",
       "22  PP23        7\n",
       "23  PP24        0\n",
       "24  PP25        0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.concat([ids, y], axis=1)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f30ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>SCL</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>stress</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>119.071484</td>\n",
       "      <td>PP4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>138.735573</td>\n",
       "      <td>PP19</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>120.251942</td>\n",
       "      <td>PP3</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>561.332213</td>\n",
       "      <td>PP21</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>158.138912</td>\n",
       "      <td>PP24</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>93.893556</td>\n",
       "      <td>PP4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP23</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>77</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>495.018099</td>\n",
       "      <td>PP12</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3140 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR       RMSSD         SCL    id dataset  stress  Cluster\n",
       "0      58    0.093757  119.071484   PP4   Train       0        0\n",
       "1     999  999.000000  138.735573  PP19   Train       0        2\n",
       "2     999  999.000000  999.000000  PP22   Train       1        8\n",
       "3     999  999.000000  120.251942   PP3   Train       1        8\n",
       "4      70    0.064568  561.332213  PP21   Train       0        6\n",
       "...   ...         ...         ...   ...     ...     ...      ...\n",
       "3135  999  999.000000  158.138912  PP24    Test       1        0\n",
       "3136  999  999.000000  999.000000  PP22    Test       1        8\n",
       "3137  999  999.000000   93.893556   PP4    Test       0        0\n",
       "3138  999  999.000000  999.000000  PP23    Test       0        7\n",
       "3139   77    0.025147  495.018099  PP12    Test       1        2\n",
       "\n",
       "[3140 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_grouped_all = swell.join(clusters.set_index('id'), on='id')\n",
    "swell_grouped_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f99439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_grouped_all.to_csv(\"Final_CSVs/swell_clusters_all11.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5ffdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_grouped_all = pd.read_csv('Final_CSVs/swell_clusters_all11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93374ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>SCL</th>\n",
       "      <th>id</th>\n",
       "      <th>stress</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>119.071484</td>\n",
       "      <td>PP4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>138.735573</td>\n",
       "      <td>PP19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>120.251942</td>\n",
       "      <td>PP3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>561.332213</td>\n",
       "      <td>PP21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>158.138912</td>\n",
       "      <td>PP24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>93.893556</td>\n",
       "      <td>PP4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP23</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>77</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>495.018099</td>\n",
       "      <td>PP12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3140 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR       RMSSD         SCL    id  stress  Cluster\n",
       "0      58    0.093757  119.071484   PP4       0        0\n",
       "1     999  999.000000  138.735573  PP19       0        2\n",
       "2     999  999.000000  999.000000  PP22       1        8\n",
       "3     999  999.000000  120.251942   PP3       1        8\n",
       "4      70    0.064568  561.332213  PP21       0        6\n",
       "...   ...         ...         ...   ...     ...      ...\n",
       "3135  999  999.000000  158.138912  PP24       1        0\n",
       "3136  999  999.000000  999.000000  PP22       1        8\n",
       "3137  999  999.000000   93.893556   PP4       0        0\n",
       "3138  999  999.000000  999.000000  PP23       0        7\n",
       "3139   77    0.025147  495.018099  PP12       1        2\n",
       "\n",
       "[3140 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'dataset' to run pycaret tests based on \"Cluster\".\n",
    "\n",
    "swell_grouped_all = swell_grouped_all.drop('dataset', axis = 1)\n",
    "swell_grouped_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ae0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_participants = swell_grouped_all[\"Cluster\"].unique()\n",
    "all_group = swell_grouped_all.groupby('Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc8d53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  8  6  7  3  1 10  9  4  5]\n"
     ]
    }
   ],
   "source": [
    "print(unique_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2bdbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant:  0\n",
      "Unique IDs: ['PP4' 'PP24' 'PP25']\n",
      "Participant:  2\n",
      "Unique IDs: ['PP19' 'PP12' 'PP5' 'PP20' 'PP13']\n",
      "Participant:  8\n",
      "Unique IDs: ['PP22' 'PP3' 'PP1' 'PP10' 'PP6' 'PP7']\n",
      "Participant:  6\n",
      "Unique IDs: ['PP21']\n",
      "Participant:  7\n",
      "Unique IDs: ['PP23' 'PP15']\n",
      "Participant:  3\n",
      "Unique IDs: ['PP8' 'PP11']\n",
      "Participant:  1\n",
      "Unique IDs: ['PP2']\n",
      "Participant:  10\n",
      "Unique IDs: ['PP16']\n",
      "Participant:  9\n",
      "Unique IDs: ['PP9']\n",
      "Participant:  4\n",
      "Unique IDs: ['PP14' 'PP18']\n",
      "Participant:  5\n",
      "Unique IDs: ['PP17']\n"
     ]
    }
   ],
   "source": [
    "for participant in unique_participants:\n",
    "    print(\"Participant: \",participant)    \n",
    "    part_df = all_group.get_group(participant)\n",
    "\n",
    "    unique_ids = part_df['id'].unique()\n",
    "    print(\"Unique IDs:\", unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf357db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  0\n",
      "ID Counts:\n",
      "  ID: PP24, Count: 130\n",
      "  ID: PP4, Count: 128\n",
      "  ID: PP25, Count: 128\n",
      "Group:  2\n",
      "ID Counts:\n",
      "  ID: PP19, Count: 130\n",
      "  ID: PP12, Count: 129\n",
      "  ID: PP20, Count: 129\n",
      "  ID: PP13, Count: 126\n",
      "  ID: PP5, Count: 125\n",
      "Group:  8\n",
      "ID Counts:\n",
      "  ID: PP7, Count: 130\n",
      "  ID: PP1, Count: 129\n",
      "  ID: PP3, Count: 128\n",
      "  ID: PP10, Count: 128\n",
      "  ID: PP22, Count: 126\n",
      "  ID: PP6, Count: 126\n",
      "Group:  6\n",
      "ID Counts:\n",
      "  ID: PP21, Count: 106\n",
      "Group:  7\n",
      "ID Counts:\n",
      "  ID: PP23, Count: 129\n",
      "  ID: PP15, Count: 121\n",
      "Group:  3\n",
      "ID Counts:\n",
      "  ID: PP11, Count: 127\n",
      "  ID: PP8, Count: 116\n",
      "Group:  1\n",
      "ID Counts:\n",
      "  ID: PP2, Count: 121\n",
      "Group:  10\n",
      "ID Counts:\n",
      "  ID: PP16, Count: 129\n",
      "Group:  9\n",
      "ID Counts:\n",
      "  ID: PP9, Count: 122\n",
      "Group:  4\n",
      "ID Counts:\n",
      "  ID: PP14, Count: 129\n",
      "  ID: PP18, Count: 119\n",
      "Group:  5\n",
      "ID Counts:\n",
      "  ID: PP17, Count: 129\n"
     ]
    }
   ],
   "source": [
    "for participant in unique_participants:\n",
    "  print(\"Group: \", participant)\n",
    "  part_df = all_group.get_group(participant)\n",
    "\n",
    "  # Count the number of rows for each ID using value_counts()\n",
    "  id_counts = part_df['id'].value_counts()\n",
    "\n",
    "  # Print the ID and its corresponding count\n",
    "  print(\"ID Counts:\")\n",
    "  for id, count in id_counts.items():\n",
    "    print(f\"  ID: {id}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb4dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_per_user(data, train_size=0.7):\n",
    "    users = list(set(data.id))\n",
    "    users = sorted(users, reverse=True)  # fix randomness\n",
    "    total_users = len(users)\n",
    "    slice = int(train_size * total_users)\n",
    "    users_train = users[:slice]\n",
    "    users_test = users[slice:]\n",
    "    return data[data.id.isin(users_train)], data[data.id.isin(users_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36eb83dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "knn                K Neighbors Classifier    0.8705  0.8761  0.9192  0.8615   \n",
      "ada                  Ada Boost Classifier    0.8588  0.8889  0.9192  0.8432   \n",
      "lightgbm  Light Gradient Boosting Machine    0.8394  0.9054  0.8835  0.8397   \n",
      "rf               Random Forest Classifier    0.8315  0.8690  0.8538  0.8463   \n",
      "et                 Extra Trees Classifier    0.8318  0.8439  0.8473  0.8499   \n",
      "gbc          Gradient Boosting Classifier    0.8278  0.8822  0.8467  0.8445   \n",
      "dt               Decision Tree Classifier    0.8118  0.7764  0.8242  0.8361   \n",
      "nb                            Naive Bayes    0.6243  0.9018  0.9709  0.5938   \n",
      "lr                    Logistic Regression    0.7348  0.9066  0.5764  0.8925   \n",
      "ridge                    Ridge Classifier    0.7348  0.0000  0.5764  0.8925   \n",
      "lda          Linear Discriminant Analysis    0.7348  0.9090  0.5764  0.8925   \n",
      "svm                   SVM - Linear Kernel    0.7108  0.0000  0.5868  0.7664   \n",
      "qda       Quadratic Discriminant Analysis    0.4649  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4649  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "knn       0.8851  0.7380  0.7489     0.021  \n",
      "ada       0.8752  0.7143  0.7268     0.061  \n",
      "lightgbm  0.8558  0.6756  0.6875     0.087  \n",
      "rf        0.8443  0.6611  0.6720     0.116  \n",
      "et        0.8425  0.6623  0.6740     0.093  \n",
      "gbc       0.8390  0.6540  0.6653     0.046  \n",
      "dt        0.8214  0.6225  0.6356     0.013  \n",
      "nb        0.7356  0.2070  0.2875     0.012  \n",
      "lr        0.6841  0.4821  0.5232     0.028  \n",
      "ridge     0.6841  0.4821  0.5232     0.012  \n",
      "lda       0.6841  0.4821  0.5232     0.013  \n",
      "svm       0.6399  0.4298  0.4687     0.014  \n",
      "qda       0.0000  0.0000  0.0000     0.015  \n",
      "dummy     0.0000  0.0000  0.0000     0.014  \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "                    Model  Accuracy     AUC  Recall  Prec.     F1   Kappa  \\\n",
      "0  K Neighbors Classifier    0.4692  0.5934  0.8551    0.5  0.631 -0.1176   \n",
      "\n",
      "      MCC  \n",
      "0 -0.1933  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_0.csv\n",
      "Group:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dt               Decision Tree Classifier    0.7392  0.7585  0.8388  0.7209   \n",
      "et                 Extra Trees Classifier    0.7420  0.8024  0.8198  0.7306   \n",
      "rf               Random Forest Classifier    0.7395  0.8063  0.8243  0.7239   \n",
      "knn                K Neighbors Classifier    0.7396  0.8089  0.8157  0.7317   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7373  0.8162  0.8193  0.7259   \n",
      "gbc          Gradient Boosting Classifier    0.7290  0.7973  0.7805  0.7310   \n",
      "ada                  Ada Boost Classifier    0.7033  0.7777  0.7138  0.7323   \n",
      "lr                    Logistic Regression    0.5705  0.5554  0.5855  0.5986   \n",
      "nb                            Naive Bayes    0.5652  0.5439  0.5560  0.6029   \n",
      "ridge                    Ridge Classifier    0.5574  0.0000  0.5564  0.5899   \n",
      "lda          Linear Discriminant Analysis    0.5600  0.5434  0.5517  0.5940   \n",
      "svm                   SVM - Linear Kernel    0.5180  0.0000  0.5429  0.4307   \n",
      "qda       Quadratic Discriminant Analysis    0.4662  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4662  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dt        0.7742  0.4694  0.4802     0.013  \n",
      "et        0.7708  0.4771  0.4854     0.099  \n",
      "rf        0.7696  0.4717  0.4809     0.116  \n",
      "knn       0.7691  0.4723  0.4809     0.022  \n",
      "lightgbm  0.7672  0.4670  0.4787     0.090  \n",
      "gbc       0.7526  0.4535  0.4589     0.058  \n",
      "ada       0.7140  0.4064  0.4166     0.052  \n",
      "lr        0.5904  0.1391  0.1398     0.016  \n",
      "nb        0.5734  0.1316  0.1348     0.016  \n",
      "ridge     0.5705  0.1154  0.1162     0.012  \n",
      "lda       0.5695  0.1217  0.1228     0.016  \n",
      "svm       0.4156  0.0246  0.0401     0.012  \n",
      "qda       0.0000  0.0000  0.0000     0.020  \n",
      "dummy     0.0000  0.0000  0.0000     0.013  \n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       random_state=7690, splitter='best')\n",
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Decision Tree Classifier       0.4  0.4081  0.2593  0.3977  0.3139 -0.1785   \n",
      "\n",
      "      MCC  \n",
      "0 -0.1915  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_2.csv\n",
      "Group:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "knn                K Neighbors Classifier    0.6882  0.7348  0.7390  0.6951   \n",
      "lightgbm  Light Gradient Boosting Machine    0.6725  0.7360  0.7242  0.6830   \n",
      "gbc          Gradient Boosting Classifier    0.6647  0.7284  0.7097  0.6785   \n",
      "rf               Random Forest Classifier    0.6647  0.7051  0.7130  0.6711   \n",
      "dt               Decision Tree Classifier    0.6569  0.6646  0.7168  0.6642   \n",
      "ada                  Ada Boost Classifier    0.6451  0.6748  0.7249  0.6526   \n",
      "et                 Extra Trees Classifier    0.6471  0.6594  0.7054  0.6535   \n",
      "nb                            Naive Bayes    0.5431  0.5567  0.6144  0.5521   \n",
      "svm                   SVM - Linear Kernel    0.5176  0.0000  0.6630  0.4317   \n",
      "ridge                    Ridge Classifier    0.5216  0.0000  0.4504  0.5683   \n",
      "lda          Linear Discriminant Analysis    0.5118  0.5054  0.4282  0.5591   \n",
      "lr                    Logistic Regression    0.5039  0.4989  0.4143  0.5492   \n",
      "qda       Quadratic Discriminant Analysis    0.4647  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4647  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "knn       0.7142  0.3708  0.3738     0.022  \n",
      "lightgbm  0.7015  0.3393  0.3425     0.086  \n",
      "gbc       0.6922  0.3240  0.3260     0.049  \n",
      "rf        0.6895  0.3240  0.3273     0.123  \n",
      "dt        0.6881  0.3068  0.3111     0.016  \n",
      "ada       0.6841  0.2809  0.2860     0.060  \n",
      "et        0.6759  0.2871  0.2939     0.098  \n",
      "nb        0.5716  0.0764  0.0745     0.024  \n",
      "svm       0.5126  0.0133  0.0240     0.017  \n",
      "ridge     0.4984  0.0535  0.0556     0.012  \n",
      "lda       0.4776  0.0353  0.0376     0.016  \n",
      "lr        0.4678  0.0222  0.0230     0.016  \n",
      "qda       0.0000  0.0000  0.0000     0.016  \n",
      "dummy     0.0000  0.0000  0.0000     0.011  \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "                    Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  K Neighbors Classifier    0.6459  0.6624  0.4779  0.7647  0.5882  0.3055   \n",
      "\n",
      "      MCC  \n",
      "0  0.3317  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_8.csv\n",
      "Group:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "knn                K Neighbors Classifier    0.6357  0.6685  0.6417  0.6255   \n",
      "rf               Random Forest Classifier    0.6321  0.6792  0.6000  0.5671   \n",
      "ada                  Ada Boost Classifier    0.5696  0.6342  0.5333  0.5183   \n",
      "dt               Decision Tree Classifier    0.5536  0.5525  0.5500  0.5002   \n",
      "et                 Extra Trees Classifier    0.5839  0.6808  0.5000  0.5571   \n",
      "lightgbm  Light Gradient Boosting Machine    0.5607  0.6083  0.5250  0.5467   \n",
      "svm                   SVM - Linear Kernel    0.5839  0.0000  0.5500  0.6446   \n",
      "gbc          Gradient Boosting Classifier    0.5429  0.6133  0.4750  0.4988   \n",
      "lda          Linear Discriminant Analysis    0.6339  0.6446  0.4167  0.6300   \n",
      "lr                    Logistic Regression    0.6464  0.6133  0.3917  0.6633   \n",
      "ridge                    Ridge Classifier    0.5839  0.0000  0.3667  0.5467   \n",
      "nb                            Naive Bayes    0.6339  0.6056  0.2750  0.6800   \n",
      "qda       Quadratic Discriminant Analysis    0.5446  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.5446  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "knn       0.6144  0.2653  0.2913     0.033  \n",
      "rf        0.5705  0.2451  0.2586     0.135  \n",
      "ada       0.5055  0.1236  0.1233     0.060  \n",
      "dt        0.5029  0.1146  0.0874     0.021  \n",
      "et        0.4968  0.1578  0.1743     0.068  \n",
      "lightgbm  0.4956  0.1245  0.1361     0.067  \n",
      "svm       0.4806  0.1641  0.2242     0.017  \n",
      "gbc       0.4732  0.0762  0.0834     0.046  \n",
      "lda       0.4694  0.2287  0.2489     0.012  \n",
      "lr        0.4522  0.2518  0.2902     0.028  \n",
      "ridge     0.4041  0.1295  0.1435     0.015  \n",
      "nb        0.3589  0.2133  0.2778     0.019  \n",
      "qda       0.0000  0.0000  0.0000     0.020  \n",
      "dummy     0.0000  0.0000  0.0000     0.010  \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "                    Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  K Neighbors Classifier    0.5185  0.4853     0.5  0.3846  0.4348  0.0277   \n",
      "\n",
      "      MCC  \n",
      "0  0.0284  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_6.csv\n",
      "Group:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "nb                            Naive Bayes    0.5808  0.7601  1.0000  0.5632   \n",
      "ridge                    Ridge Classifier    0.7449  0.0000  0.6405  0.8744   \n",
      "lda          Linear Discriminant Analysis    0.7449  0.7891  0.6405  0.8744   \n",
      "lr                    Logistic Regression    0.7372  0.8081  0.6405  0.8544   \n",
      "knn                K Neighbors Classifier    0.7372  0.7512  0.6262  0.8628   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7449  0.7653  0.5976  0.9161   \n",
      "rf               Random Forest Classifier    0.7064  0.7653  0.5690  0.8600   \n",
      "svm                   SVM - Linear Kernel    0.6269  0.0000  0.6571  0.7510   \n",
      "et                 Extra Trees Classifier    0.6910  0.7569  0.5548  0.8314   \n",
      "gbc          Gradient Boosting Classifier    0.6833  0.7165  0.5405  0.8164   \n",
      "ada                  Ada Boost Classifier    0.6833  0.7093  0.5405  0.8000   \n",
      "dt               Decision Tree Classifier    0.6756  0.6762  0.5262  0.8211   \n",
      "qda       Quadratic Discriminant Analysis    0.4654  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4654  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "nb        0.7196  0.1054  0.1545     0.014  \n",
      "ridge     0.7105  0.4998  0.5414     0.015  \n",
      "lda       0.7105  0.4998  0.5414     0.014  \n",
      "lr        0.7044  0.4841  0.5212     0.019  \n",
      "knn       0.6974  0.4859  0.5256     0.028  \n",
      "lightgbm  0.6892  0.5046  0.5618     0.095  \n",
      "rf        0.6539  0.4275  0.4738     0.093  \n",
      "svm       0.6402  0.2492  0.2825     0.014  \n",
      "et        0.6398  0.3970  0.4358     0.127  \n",
      "gbc       0.6265  0.3831  0.4186     0.036  \n",
      "ada       0.6152  0.3847  0.4159     0.054  \n",
      "dt        0.5957  0.3714  0.4168     0.013  \n",
      "qda       0.0000  0.0000  0.0000     0.013  \n",
      "dummy     0.0000  0.0000  0.0000     0.016  \n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "         Model  Accuracy     AUC  Recall  Prec.      F1   Kappa     MCC\n",
      "0  Naive Bayes     0.562  0.5726  0.1452    1.0  0.2535  0.1421  0.2765\n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_7.csv\n",
      "Group:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lr                    Logistic Regression    0.5826  0.5950  0.5733  0.6171   \n",
      "nb                            Naive Bayes    0.5826  0.5950  0.5733  0.6171   \n",
      "ridge                    Ridge Classifier    0.5826  0.0000  0.5733  0.6171   \n",
      "lda          Linear Discriminant Analysis    0.5826  0.5950  0.5733  0.6171   \n",
      "lightgbm  Light Gradient Boosting Machine    0.5311  0.5256  0.4567  0.5900   \n",
      "knn                K Neighbors Classifier    0.5212  0.5231  0.3700  0.6236   \n",
      "svm                   SVM - Linear Kernel    0.5250  0.0000  0.5833  0.3260   \n",
      "et                 Extra Trees Classifier    0.5402  0.4647  0.3233  0.6733   \n",
      "rf               Random Forest Classifier    0.5152  0.4583  0.3233  0.5967   \n",
      "dt               Decision Tree Classifier    0.5068  0.4458  0.3233  0.5900   \n",
      "gbc          Gradient Boosting Classifier    0.5068  0.4464  0.3233  0.5900   \n",
      "ada                  Ada Boost Classifier    0.5068  0.4669  0.3233  0.6400   \n",
      "qda       Quadratic Discriminant Analysis    0.4909  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4909  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lr        0.5892  0.1632  0.1690     0.021  \n",
      "nb        0.5892  0.1632  0.1690     0.020  \n",
      "ridge     0.5892  0.1632  0.1690     0.014  \n",
      "lda       0.5892  0.1632  0.1690     0.014  \n",
      "lightgbm  0.4944  0.0644  0.0786     0.040  \n",
      "knn       0.4399  0.0472  0.0738     0.030  \n",
      "svm       0.4139  0.0500  0.0507     0.022  \n",
      "et        0.4094  0.0871  0.1253     0.079  \n",
      "rf        0.3977  0.0371  0.0590     0.110  \n",
      "dt        0.3947  0.0205  0.0426     0.013  \n",
      "gbc       0.3947  0.0205  0.0426     0.039  \n",
      "ada       0.3899  0.0169  0.0566     0.041  \n",
      "qda       0.0000  0.0000  0.0000     0.014  \n",
      "dummy     0.0000  0.0000  0.0000     0.019  \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=5480, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "                 Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Logistic Regression    0.2205  0.2034  0.0882  0.1395  0.1081 -0.5242   \n",
      "\n",
      "      MCC  \n",
      "0 -0.5679  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_3.csv\n",
      "Group:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lightgbm  Light Gradient Boosting Machine    0.9444  0.9850   0.955  0.9383   \n",
      "rf               Random Forest Classifier    0.9333  0.9900   0.955  0.9264   \n",
      "ada                  Ada Boost Classifier    0.9333  0.9700   0.930  0.9333   \n",
      "lda          Linear Discriminant Analysis    0.9222  0.9200   0.975  0.8898   \n",
      "et                 Extra Trees Classifier    0.9222  0.9650   0.930  0.9264   \n",
      "lr                    Logistic Regression    0.9222  0.9350   0.930  0.9183   \n",
      "ridge                    Ridge Classifier    0.9111  0.0000   0.975  0.8731   \n",
      "gbc          Gradient Boosting Classifier    0.9000  0.9525   0.930  0.8814   \n",
      "knn                K Neighbors Classifier    0.8889  0.9475   0.950  0.8598   \n",
      "dt               Decision Tree Classifier    0.8889  0.8900   0.910  0.8683   \n",
      "nb                            Naive Bayes    0.7778  0.9300   0.950  0.7201   \n",
      "svm                   SVM - Linear Kernel    0.7222  0.0000   0.755  0.6248   \n",
      "qda       Quadratic Discriminant Analysis    0.5222  0.0000   0.000  0.0000   \n",
      "dummy                    Dummy Classifier    0.5222  0.5000   0.000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lightgbm  0.9437  0.8880  0.8941     0.052  \n",
      "rf        0.9361  0.8637  0.8748     0.111  \n",
      "ada       0.9298  0.8650  0.8691     0.053  \n",
      "lda       0.9270  0.8407  0.8538     0.021  \n",
      "et        0.9218  0.8407  0.8538     0.104  \n",
      "lr        0.9183  0.8430  0.8531     0.026  \n",
      "ridge     0.9179  0.8176  0.8329     0.039  \n",
      "gbc       0.9000  0.7968  0.8098     0.079  \n",
      "knn       0.8981  0.7769  0.7896     0.032  \n",
      "dt        0.8854  0.7772  0.7841     0.020  \n",
      "nb        0.8128  0.5606  0.5812     0.022  \n",
      "svm       0.6708  0.4336  0.4669     0.020  \n",
      "qda       0.0000  0.0000  0.0000     0.013  \n",
      "dummy     0.0000  0.0000  0.0000     0.014  \n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "               random_state=533, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n",
      "                             Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "0  Light Gradient Boosting Machine     0.871  0.9625  0.8125  0.9286  0.8667   \n",
      "\n",
      "    Kappa    MCC  \n",
      "0  0.7427  0.749  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_1.csv\n",
      "Group:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "et                 Extra Trees Classifier    0.9289  0.9825  0.9467  0.9405   \n",
      "rf               Random Forest Classifier    0.9289  0.9842  0.9467  0.9429   \n",
      "lr                    Logistic Regression    0.9289  0.9958  0.9300  0.9571   \n",
      "knn                K Neighbors Classifier    0.9278  0.9379  0.9267  0.9548   \n",
      "lightgbm  Light Gradient Boosting Machine    0.9167  0.9683  0.9067  0.9571   \n",
      "dt               Decision Tree Classifier    0.8978  0.8925  0.9100  0.9298   \n",
      "gbc          Gradient Boosting Classifier    0.8967  0.9625  0.9067  0.9321   \n",
      "ada                  Ada Boost Classifier    0.8767  0.9617  0.9100  0.9014   \n",
      "lda          Linear Discriminant Analysis    0.8778  0.9242  0.9300  0.8755   \n",
      "ridge                    Ridge Classifier    0.8667  0.0000  0.9100  0.8755   \n",
      "nb                            Naive Bayes    0.6856  0.9367  1.0000  0.6567   \n",
      "svm                   SVM - Linear Kernel    0.8322  0.0000  0.7800  0.8405   \n",
      "qda       Quadratic Discriminant Analysis    0.4178  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4178  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "et        0.9401  0.8512  0.8605     0.097  \n",
      "rf        0.9399  0.8511  0.8640     0.204  \n",
      "lr        0.9385  0.8528  0.8655     0.017  \n",
      "knn       0.9366  0.8510  0.8603     0.022  \n",
      "lightgbm  0.9254  0.8289  0.8438     0.047  \n",
      "dt        0.9133  0.7855  0.8032     0.023  \n",
      "gbc       0.9111  0.7835  0.8051     0.054  \n",
      "ada       0.8991  0.7369  0.7564     0.072  \n",
      "lda       0.8987  0.7427  0.7559     0.028  \n",
      "ridge     0.8876  0.7207  0.7359     0.017  \n",
      "nb        0.7903  0.2719  0.3238     0.014  \n",
      "svm       0.7889  0.6841  0.7106     0.020  \n",
      "qda       0.0000  0.0000  0.0000     0.016  \n",
      "dummy     0.0000  0.0000  0.0000     0.013  \n",
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                     n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                     random_state=4091, verbose=0, warm_start=False)\n",
      "                    Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Extra Trees Classifier    0.7879  0.9096  0.9231  0.6667  0.7742  0.5838   \n",
      "\n",
      "      MCC  \n",
      "0  0.6114  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_10.csv\n",
      "Group:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "et                 Extra Trees Classifier    0.7133  0.7130   0.760  0.7174   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7022  0.7255   0.750  0.7326   \n",
      "ridge                    Ridge Classifier    0.7356  0.0000   0.710  0.7533   \n",
      "gbc          Gradient Boosting Classifier    0.7122  0.7915   0.740  0.7279   \n",
      "lda          Linear Discriminant Analysis    0.7256  0.7520   0.690  0.7483   \n",
      "dt               Decision Tree Classifier    0.6900  0.6700   0.740  0.6989   \n",
      "rf               Random Forest Classifier    0.7022  0.7135   0.715  0.7145   \n",
      "lr                    Logistic Regression    0.7033  0.7560   0.690  0.7167   \n",
      "ada                  Ada Boost Classifier    0.6689  0.7105   0.740  0.6710   \n",
      "knn                K Neighbors Classifier    0.6044  0.7140   0.670  0.6183   \n",
      "nb                            Naive Bayes    0.5289  0.6350   0.610  0.5488   \n",
      "svm                   SVM - Linear Kernel    0.5056  0.0000   0.475  0.2706   \n",
      "qda       Quadratic Discriminant Analysis    0.4833  0.0000   0.000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4833  0.5000   0.000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "et        0.7232  0.4280  0.4457     0.084  \n",
      "lightgbm  0.7223  0.4136  0.4303     0.045  \n",
      "ridge     0.7211  0.4789  0.4831     0.014  \n",
      "gbc       0.7207  0.4262  0.4362     0.039  \n",
      "lda       0.7078  0.4589  0.4639     0.027  \n",
      "dt        0.7028  0.3721  0.4016     0.015  \n",
      "rf        0.6992  0.4020  0.4250     0.097  \n",
      "lr        0.6889  0.4148  0.4213     0.025  \n",
      "ada       0.6888  0.3316  0.3607     0.044  \n",
      "knn       0.6154  0.2175  0.2271     0.034  \n",
      "nb        0.5543  0.0575  0.0715     0.020  \n",
      "svm       0.3400  0.0723  0.0731     0.013  \n",
      "qda       0.0000  0.0000  0.0000     0.014  \n",
      "dummy     0.0000  0.0000  0.0000     0.013  \n",
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                     n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                     random_state=7122, verbose=0, warm_start=False)\n",
      "                    Model  Accuracy    AUC  Recall  Prec.      F1   Kappa  \\\n",
      "0  Extra Trees Classifier    0.6774  0.693  0.6316    0.8  0.7059  0.3595   \n",
      "\n",
      "      MCC  \n",
      "0  0.3719  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_9.csv\n",
      "Group:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "ridge                    Ridge Classifier    0.7068  0.0000  0.7119  0.7681   \n",
      "lda          Linear Discriminant Analysis    0.6985  0.7638  0.6810  0.7863   \n",
      "et                 Extra Trees Classifier    0.6795  0.6867  0.7381  0.7232   \n",
      "nb                            Naive Bayes    0.6212  0.6157  0.8286  0.6429   \n",
      "lr                    Logistic Regression    0.6818  0.7610  0.6690  0.7563   \n",
      "rf               Random Forest Classifier    0.6553  0.7457  0.7119  0.7044   \n",
      "gbc          Gradient Boosting Classifier    0.6295  0.6995  0.6810  0.6971   \n",
      "dt               Decision Tree Classifier    0.6220  0.6145  0.6690  0.6824   \n",
      "lightgbm  Light Gradient Boosting Machine    0.6220  0.7195  0.6381  0.7060   \n",
      "svm                   SVM - Linear Kernel    0.5788  0.0000  0.8000  0.5409   \n",
      "ada                  Ada Boost Classifier    0.5977  0.6460  0.6238  0.6643   \n",
      "knn                K Neighbors Classifier    0.5879  0.6805  0.6238  0.6593   \n",
      "qda       Quadratic Discriminant Analysis    0.4205  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4205  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "ridge     0.7368  0.4066  0.4102     0.012  \n",
      "lda       0.7256  0.3910  0.4017     0.014  \n",
      "et        0.7211  0.3387  0.3505     0.085  \n",
      "nb        0.7145  0.1753  0.2070     0.012  \n",
      "lr        0.7059  0.3619  0.3679     0.018  \n",
      "rf        0.7012  0.2924  0.3021     0.091  \n",
      "gbc       0.6829  0.2348  0.2388     0.057  \n",
      "dt        0.6657  0.2254  0.2235     0.012  \n",
      "lightgbm  0.6557  0.2316  0.2454     0.047  \n",
      "svm       0.6360  0.0650  0.0802     0.013  \n",
      "ada       0.6331  0.1849  0.1938     0.045  \n",
      "knn       0.6323  0.1606  0.1660     0.020  \n",
      "qda       0.0000  0.0000  0.0000     0.013  \n",
      "dummy     0.0000  0.0000  0.0000     0.013  \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, positive=False, random_state=3700, solver='auto',\n",
      "                tol=0.0001)\n",
      "              Model  Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "0  Ridge Classifier    0.4574  0.4428  0.6522  0.4945  0.5625 -0.1173 -0.1253\n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_4.csv\n",
      "Group:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "rf               Random Forest Classifier    0.9044  0.9395   0.960  0.8800   \n",
      "gbc          Gradient Boosting Classifier    0.8933  0.9350   0.940  0.8767   \n",
      "et                 Extra Trees Classifier    0.8844  0.9540   0.940  0.8719   \n",
      "ada                  Ada Boost Classifier    0.8944  0.9655   0.895  0.9148   \n",
      "dt               Decision Tree Classifier    0.8800  0.8800   0.895  0.8717   \n",
      "lightgbm  Light Gradient Boosting Machine    0.8733  0.9340   0.895  0.8717   \n",
      "ridge                    Ridge Classifier    0.8422  0.0000   0.910  0.8129   \n",
      "lda          Linear Discriminant Analysis    0.8422  0.8310   0.910  0.8129   \n",
      "knn                K Neighbors Classifier    0.8311  0.8830   0.920  0.7931   \n",
      "lr                    Logistic Regression    0.8411  0.9080   0.840  0.8648   \n",
      "nb                            Naive Bayes    0.6756  0.9320   1.000  0.6137   \n",
      "svm                   SVM - Linear Kernel    0.8011  0.0000   0.775  0.7483   \n",
      "qda       Quadratic Discriminant Analysis    0.5000  0.0000   0.000  0.0000   \n",
      "dummy                    Dummy Classifier    0.5000  0.5000   0.000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "rf        0.9145  0.8079  0.8182     0.091  \n",
      "gbc       0.9010  0.7838  0.7973     0.039  \n",
      "et        0.8987  0.7633  0.7747     0.081  \n",
      "ada       0.8977  0.7869  0.7995     0.045  \n",
      "dt        0.8790  0.7602  0.7674     0.012  \n",
      "lightgbm  0.8756  0.7427  0.7555     0.042  \n",
      "ridge     0.8518  0.6806  0.7016     0.011  \n",
      "lda       0.8518  0.6806  0.7016     0.014  \n",
      "knn       0.8480  0.6553  0.6730     0.019  \n",
      "lr        0.8404  0.6809  0.7002     0.018  \n",
      "nb        0.7584  0.3424  0.4320     0.012  \n",
      "svm       0.7542  0.6010  0.6138     0.012  \n",
      "qda       0.0000  0.0000  0.0000     0.014  \n",
      "dummy     0.0000  0.0000  0.0000     0.014  \n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                       random_state=3959, verbose=0, warm_start=False)\n",
      "                      Model  Accuracy     AUC  Recall  Prec.    F1   Kappa  \\\n",
      "0  Random Forest Classifier    0.9394  0.9603  0.9048    1.0  0.95  0.8736   \n",
      "\n",
      "      MCC  \n",
      "0  0.8806  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files\\predictions_5.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os  # Import os module for folder creation\n",
    "\n",
    "# Specify folder name\n",
    "folder_name = \"SWELL_Multi_Attribute_Splitting_Output_Files\"\n",
    "\n",
    "# Load the CSV data into a pandas dataframe\n",
    "df_user_info = pd.read_csv(\"Scored_Surveys/swell_person.csv\", sep=\";\")\n",
    "\n",
    "accuracies_swell = []\n",
    "precision_swell = []\n",
    "recall_swell = []\n",
    "f1scores_swell = []\n",
    "\n",
    "for participant in unique_participants:\n",
    "    print(\"Group: \",participant)    \n",
    "    part_df = all_group.get_group(participant)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    # if the group has only one id don't split per user\n",
    "    if participant in [1,5,6,9,10]:\n",
    "        train_data, test_data = train_test_split(part_df)\n",
    "    else:\n",
    "        train_data, test_data = train_test_split_per_user(part_df)\n",
    "    \n",
    "    fold_groups = train_data.id\n",
    "\n",
    "    # Save the 'id' column from the test set\n",
    "    test_ids = test_data['id']\n",
    "\n",
    "    train_data = train_data.drop(columns=['id'])\n",
    "    test_data = test_data.drop(columns=['id'])\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    grid = setup(data=train_data, target='stress', fix_imbalance = True, html=False, verbose=False, test_data=test_data) #fix_imbalance = True,\n",
    "    best = compare_models(sort='F1')\n",
    "    accuracies_swell.append(pull()['Accuracy'][0])\n",
    "    precision_swell.append(pull()['Prec.'][0])\n",
    "    recall_swell.append(pull()['Recall'][0])\n",
    "    f1scores_swell.append(pull()['F1'][0])\n",
    "    print(best)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    # Make predictions using the best model\n",
    "    predictions = predict_model(best, data=test_data)\n",
    "\n",
    "    # Add 'id' column back to predictions DataFrame\n",
    "    predictions['PP'] = test_ids  # Use the 'id' column from the test data\n",
    "\n",
    "    # Merge the dataframes based on the 'PP' column\n",
    "    predictions_with_info = predictions.merge(df_user_info, on=\"PP\", how=\"left\")\n",
    "\n",
    "    # Extract true labels (y_true), rename the column\n",
    "    y_true = predictions_with_info[['stress_x']].rename(columns={'stress_x': 'y_true'})\n",
    "\n",
    "    # Extract predicted labels (y_pred), rename the column\n",
    "    y_pred = predictions_with_info[['prediction_label']].rename(columns={'prediction_label': 'y_pred'})\n",
    "\n",
    "    # Identify protected attribute columns (assuming you know the column names)\n",
    "    protected_attributes = predictions_with_info[['Age', 'Gender', 'Occupation']]\n",
    "\n",
    "    # Concatenate DataFrames containing predictions and protected attributes\n",
    "    all_data = pd.concat([test_ids.reset_index(drop=True), y_true, y_pred, protected_attributes], axis=1)\n",
    "\n",
    "    # Create filename\n",
    "    filename = f\"predictions_{participant}.csv\"\n",
    "\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)  # Create folder using makedirs()\n",
    "\n",
    "    # Create full path with folder name\n",
    "    filepath = os.path.join(folder_name, filename)\n",
    "\n",
    "    # Save predictions\n",
    "    all_data.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Predictions saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06bda6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = statistics.mean(accuracies_swell)\n",
    "mean_prec = statistics.mean(precision_swell)\n",
    "mean_rec = statistics.mean(recall_swell)\n",
    "mean_f1 = statistics.mean(f1scores_swell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e768234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy SWELL- Cluster All Features:  0.7540727272727272\n",
      "Mean Precision SWELL- Cluster All Features:  0.7777272727272727\n",
      "Mean Recall SWELL- Cluster All Features:  0.8223272727272727\n",
      "Mean F1-score SWELL- Cluster All Features:  0.7570545454545454\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy SWELL- Cluster All Features: \",mean_acc)\n",
    "print(\"Mean Precision SWELL- Cluster All Features: \",mean_f1)\n",
    "print(\"Mean Recall SWELL- Cluster All Features: \",mean_rec)\n",
    "print(\"Mean F1-score SWELL- Cluster All Features: \",mean_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd31b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"SWELL_Multi_Attribute_Splitting_Output_Files\"\n",
    "\n",
    "# List all CSV files in the folder:\n",
    "csv_files = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_files.append(os.path.join(folder_path, filename))\n",
    "\n",
    "# Concatenate files\n",
    "combined_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b2cd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions saved to: Output_Files\\SWELL_Multi_Attribute_Splitting.csv\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"Output_Files\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)  # Create folder using makedirs()\n",
    "\n",
    "# Create the full path with the output folder name\n",
    "output_filepath = os.path.join(output_folder, \"SWELL_Multi_Attribute_Splitting.csv\")\n",
    "\n",
    "# Save the concatenated DataFrame to the new CSV file\n",
    "combined_df.to_csv(output_filepath, index=False)\n",
    "\n",
    "print(f\"All predictions saved to: {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e4008",
   "metadata": {},
   "source": [
    "### Multi Attribute Splitting model trained with protected attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3fa4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_grouped_all = pd.read_csv('Final_CSVs/swell_clusters_all11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1371b3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PP', 'Age', 'Gender', 'Occupation', 'Dominant hand', 'Glasses',\n",
       "       'smoke', 'coffee', 'alcohol', 'physical', 'heart disease', 'medicine',\n",
       "       'Internal control index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV data into a pandas dataframe\n",
    "df_user_info = pd.read_csv(\"Scored_Surveys/swell_person.csv\", sep=\";\")\n",
    "df_user_info.drop(columns=['stress'], inplace=True)\n",
    "df_user_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ea7cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HR', 'RMSSD', 'SCL', 'id', 'dataset', 'stress_x', 'Cluster', 'Age',\n",
      "       'Gender', 'Occupation', 'Dominant hand', 'Glasses', 'smoke', 'coffee',\n",
      "       'alcohol', 'physical', 'stress_y', 'heart disease', 'medicine',\n",
      "       'Internal control index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV data into a pandas dataframe\n",
    "df_user_info = pd.read_csv(\"Scored_Surveys/swell_person.csv\", sep=\";\")\n",
    "\n",
    "# Rename the 'PP' column to 'id'\n",
    "df_user_info.rename(columns={'PP': 'id'}, inplace=True)\n",
    "\n",
    "# Merge the dataframes based on the 'PP' column\n",
    "swell_grouped_all = swell_grouped_all.merge(df_user_info, on=\"id\", how=\"left\")\n",
    "\n",
    "# Print the result\n",
    "print(swell_grouped_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da3f2132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>SCL</th>\n",
       "      <th>id</th>\n",
       "      <th>stress_x</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Dominant hand</th>\n",
       "      <th>Glasses</th>\n",
       "      <th>smoke</th>\n",
       "      <th>coffee</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>physical</th>\n",
       "      <th>stress_y</th>\n",
       "      <th>heart disease</th>\n",
       "      <th>medicine</th>\n",
       "      <th>Internal control index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>119.071484</td>\n",
       "      <td>PP4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>138.735573</td>\n",
       "      <td>PP19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>f</td>\n",
       "      <td>Icelandic</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>m</td>\n",
       "      <td>Physics</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>120.251942</td>\n",
       "      <td>PP3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>561.332213</td>\n",
       "      <td>PP21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>f</td>\n",
       "      <td>Photography</td>\n",
       "      <td>right</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>158.138912</td>\n",
       "      <td>PP24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>m</td>\n",
       "      <td>MSc Electrical Engineering</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP22</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>m</td>\n",
       "      <td>Physics</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>93.893556</td>\n",
       "      <td>PP4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>999</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>PP23</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>f</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>77</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>495.018099</td>\n",
       "      <td>PP12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>f</td>\n",
       "      <td>student</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3,89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3140 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR       RMSSD         SCL    id  stress_x  Cluster  Age Gender  \\\n",
       "0      58    0.093757  119.071484   PP4         0        0   24      m   \n",
       "1     999  999.000000  138.735573  PP19         0        2   23      f   \n",
       "2     999  999.000000  999.000000  PP22         1        8   26      m   \n",
       "3     999  999.000000  120.251942   PP3         1        8   24      m   \n",
       "4      70    0.064568  561.332213  PP21         0        6   22      f   \n",
       "...   ...         ...         ...   ...       ...      ...  ...    ...   \n",
       "3135  999  999.000000  158.138912  PP24         1        0   22      m   \n",
       "3136  999  999.000000  999.000000  PP22         1        8   26      m   \n",
       "3137  999  999.000000   93.893556   PP4         0        0   24      m   \n",
       "3138  999  999.000000  999.000000  PP23         0        7   25      f   \n",
       "3139   77    0.025147  495.018099  PP12         1        2   24      f   \n",
       "\n",
       "                      Occupation Dominant hand Glasses  smoke  coffee  \\\n",
       "0                        student         right      no      6       6   \n",
       "1                      Icelandic         right     yes      6       6   \n",
       "2                        Physics         right      no      6       6   \n",
       "3                        student         right      no      6       6   \n",
       "4                    Photography         right     yes      4       5   \n",
       "...                          ...           ...     ...    ...     ...   \n",
       "3135  MSc Electrical Engineering         right      no      6       6   \n",
       "3136                     Physics         right      no      6       6   \n",
       "3137                     student         right      no      6       6   \n",
       "3138        Computer Engineering         right      no      6       6   \n",
       "3139                     student         right      no      6       6   \n",
       "\n",
       "      alcohol  physical  stress_y heart disease medicine  \\\n",
       "0           6         2         6            no       no   \n",
       "1           6         6         6            no       no   \n",
       "2           6         6         6            no       no   \n",
       "3           6         6         6            no       no   \n",
       "4           5         5         4            no       no   \n",
       "...       ...       ...       ...           ...      ...   \n",
       "3135        6         2         2            no       no   \n",
       "3136        6         6         6            no       no   \n",
       "3137        6         2         6            no       no   \n",
       "3138        6         2         4            no       no   \n",
       "3139        6         6         6            no       no   \n",
       "\n",
       "     Internal control index  \n",
       "0                      3,61  \n",
       "1                      3,61  \n",
       "2                      3,61  \n",
       "3                      3,61  \n",
       "4                      3,39  \n",
       "...                     ...  \n",
       "3135                   3,82  \n",
       "3136                   3,61  \n",
       "3137                   3,61  \n",
       "3138                   3,89  \n",
       "3139                   3,89  \n",
       "\n",
       "[3140 rows x 19 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'dataset' to run pycaret tests based on \"Cluster\".\n",
    "\n",
    "swell_grouped_all = swell_grouped_all.drop('dataset', axis = 1)\n",
    "swell_grouped_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b3368a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_participants = swell_grouped_all[\"Cluster\"].unique()\n",
    "all_group = swell_grouped_all.groupby('Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f09c6368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  0\n",
      "ID Counts:\n",
      "  ID: PP24, Count: 130\n",
      "  ID: PP4, Count: 128\n",
      "  ID: PP25, Count: 128\n",
      "Group:  2\n",
      "ID Counts:\n",
      "  ID: PP19, Count: 130\n",
      "  ID: PP12, Count: 129\n",
      "  ID: PP20, Count: 129\n",
      "  ID: PP13, Count: 126\n",
      "  ID: PP5, Count: 125\n",
      "Group:  8\n",
      "ID Counts:\n",
      "  ID: PP7, Count: 130\n",
      "  ID: PP1, Count: 129\n",
      "  ID: PP3, Count: 128\n",
      "  ID: PP10, Count: 128\n",
      "  ID: PP22, Count: 126\n",
      "  ID: PP6, Count: 126\n",
      "Group:  6\n",
      "ID Counts:\n",
      "  ID: PP21, Count: 106\n",
      "Group:  7\n",
      "ID Counts:\n",
      "  ID: PP23, Count: 129\n",
      "  ID: PP15, Count: 121\n",
      "Group:  3\n",
      "ID Counts:\n",
      "  ID: PP11, Count: 127\n",
      "  ID: PP8, Count: 116\n",
      "Group:  1\n",
      "ID Counts:\n",
      "  ID: PP2, Count: 121\n",
      "Group:  10\n",
      "ID Counts:\n",
      "  ID: PP16, Count: 129\n",
      "Group:  9\n",
      "ID Counts:\n",
      "  ID: PP9, Count: 122\n",
      "Group:  4\n",
      "ID Counts:\n",
      "  ID: PP14, Count: 129\n",
      "  ID: PP18, Count: 119\n",
      "Group:  5\n",
      "ID Counts:\n",
      "  ID: PP17, Count: 129\n"
     ]
    }
   ],
   "source": [
    "for participant in unique_participants:\n",
    "  print(\"Group: \", participant)\n",
    "  part_df = all_group.get_group(participant)\n",
    "\n",
    "  # Count the number of rows for each ID using value_counts()\n",
    "  id_counts = part_df['id'].value_counts()\n",
    "\n",
    "  # Print the ID and its corresponding count\n",
    "  print(\"ID Counts:\")\n",
    "  for id, count in id_counts.items():\n",
    "    print(f\"  ID: {id}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66d7dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "knn                K Neighbors Classifier    0.8745  0.8836  0.9192  0.8672   \n",
      "ada                  Ada Boost Classifier    0.8663  0.9019  0.9335  0.8440   \n",
      "lightgbm  Light Gradient Boosting Machine    0.8511  0.9185  0.8901  0.8518   \n",
      "gbc          Gradient Boosting Classifier    0.8472  0.9006  0.8753  0.8523   \n",
      "rf               Random Forest Classifier    0.8434  0.8996  0.8610  0.8589   \n",
      "et                 Extra Trees Classifier    0.8435  0.8699  0.8544  0.8650   \n",
      "dt               Decision Tree Classifier    0.8392  0.8073  0.8527  0.8573   \n",
      "nb                            Naive Bayes    0.6243  0.8564  0.9709  0.5938   \n",
      "lr                    Logistic Regression    0.7348  0.8615  0.5764  0.8925   \n",
      "ridge                    Ridge Classifier    0.7348  0.0000  0.5764  0.8925   \n",
      "lda          Linear Discriminant Analysis    0.7348  0.8645  0.5764  0.8925   \n",
      "svm                   SVM - Linear Kernel    0.6906  0.0000  0.7104  0.6909   \n",
      "qda       Quadratic Discriminant Analysis    0.4649  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4649  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "knn       0.8883  0.7461  0.7563     0.087  \n",
      "ada       0.8837  0.7290  0.7400     0.104  \n",
      "lightgbm  0.8655  0.6989  0.7116     0.134  \n",
      "gbc       0.8603  0.6920  0.6997     0.090  \n",
      "rf        0.8556  0.6843  0.6941     0.128  \n",
      "et        0.8555  0.6851  0.6925     0.125  \n",
      "dt        0.8499  0.6764  0.6872     0.085  \n",
      "nb        0.7356  0.2070  0.2875     0.088  \n",
      "lr        0.6841  0.4821  0.5232     0.149  \n",
      "ridge     0.6841  0.4821  0.5232     0.096  \n",
      "lda       0.6841  0.4821  0.5232     0.060  \n",
      "svm       0.6654  0.3755  0.4301     0.082  \n",
      "qda       0.0000  0.0000  0.0000     0.056  \n",
      "dummy     0.0000  0.0000  0.0000     0.060  \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "                    Model  Accuracy     AUC  Recall  Prec.     F1   Kappa  \\\n",
      "0  K Neighbors Classifier    0.4692  0.5936  0.8551    0.5  0.631 -0.1176   \n",
      "\n",
      "      MCC  \n",
      "0 -0.1933  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_0.csv\n",
      "Group:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "rf               Random Forest Classifier    0.7707  0.8533  0.8140  0.7728   \n",
      "knn                K Neighbors Classifier    0.7601  0.8273  0.8293  0.7514   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7605  0.8540  0.8052  0.7657   \n",
      "et                 Extra Trees Classifier    0.7576  0.8423  0.7850  0.7728   \n",
      "gbc          Gradient Boosting Classifier    0.7371  0.8377  0.7614  0.7562   \n",
      "dt               Decision Tree Classifier    0.7345  0.7686  0.7619  0.7500   \n",
      "ada                  Ada Boost Classifier    0.7004  0.7920  0.6393  0.7677   \n",
      "svm                   SVM - Linear Kernel    0.5235  0.0000  0.8324  0.5421   \n",
      "lr                    Logistic Regression    0.5522  0.5064  0.5417  0.5860   \n",
      "lda          Linear Discriminant Analysis    0.5520  0.5164  0.5364  0.5869   \n",
      "ridge                    Ridge Classifier    0.5520  0.0000  0.5269  0.5878   \n",
      "nb                            Naive Bayes    0.5420  0.5297  0.4971  0.5920   \n",
      "qda       Quadratic Discriminant Analysis    0.5026  0.5100  0.4207  0.3406   \n",
      "dummy                    Dummy Classifier    0.4662  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "rf        0.7889  0.5373  0.5460     0.156  \n",
      "knn       0.7871  0.5136  0.5199     0.066  \n",
      "lightgbm  0.7815  0.5166  0.5240     0.157  \n",
      "et        0.7749  0.5114  0.5180     0.190  \n",
      "gbc       0.7550  0.4712  0.4770     0.186  \n",
      "dt        0.7509  0.4662  0.4744     0.068  \n",
      "ada       0.6882  0.4066  0.4202     0.155  \n",
      "svm       0.6218  0.0041  0.0054     0.069  \n",
      "lr        0.5609  0.1061  0.1070     0.067  \n",
      "lda       0.5584  0.1064  0.1074     0.094  \n",
      "ridge     0.5521  0.1079  0.1091     0.062  \n",
      "nb        0.5312  0.0887  0.0952     0.088  \n",
      "qda       0.3459  0.0193  0.0248     0.070  \n",
      "dummy     0.0000  0.0000  0.0000     0.072  \n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                       random_state=2860, verbose=0, warm_start=False)\n",
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Random Forest Classifier    0.6588  0.6932  0.7185  0.6644  0.6904  0.3118   \n",
      "\n",
      "     MCC  \n",
      "0  0.313  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_2.csv\n",
      "Group:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.7686  0.8584  0.7577  0.8046   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7627  0.8613  0.7505  0.7951   \n",
      "rf               Random Forest Classifier    0.7549  0.8416  0.7537  0.7815   \n",
      "et                 Extra Trees Classifier    0.7529  0.8009  0.7426  0.7864   \n",
      "knn                K Neighbors Classifier    0.7294  0.8125  0.7427  0.7517   \n",
      "dt               Decision Tree Classifier    0.7196  0.7202  0.7283  0.7436   \n",
      "svm                   SVM - Linear Kernel    0.5471  0.0000  0.9714  0.5457   \n",
      "ada                  Ada Boost Classifier    0.6588  0.7434  0.6950  0.6758   \n",
      "nb                            Naive Bayes    0.4882  0.4874  0.5230  0.5079   \n",
      "qda       Quadratic Discriminant Analysis    0.5196  0.5130  0.5845  0.4401   \n",
      "ridge                    Ridge Classifier    0.4882  0.0000  0.4419  0.5233   \n",
      "lr                    Logistic Regression    0.4784  0.4903  0.4201  0.5091   \n",
      "lda          Linear Discriminant Analysis    0.4863  0.4796  0.3878  0.5352   \n",
      "dummy                    Dummy Classifier    0.4647  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.7770  0.5365  0.5424     0.197  \n",
      "lightgbm  0.7695  0.5254  0.5290     0.286  \n",
      "rf        0.7647  0.5084  0.5125     0.424  \n",
      "et        0.7598  0.5051  0.5112     0.268  \n",
      "knn       0.7429  0.4566  0.4609     0.097  \n",
      "dt        0.7319  0.4372  0.4422     0.162  \n",
      "svm       0.6957  0.0340  0.0477     0.181  \n",
      "ada       0.6832  0.3130  0.3143     0.260  \n",
      "nb        0.5114 -0.0267 -0.0286     0.137  \n",
      "qda       0.4940  0.0265  0.0336     0.173  \n",
      "ridge     0.4745 -0.0175 -0.0192     0.178  \n",
      "lr        0.4576 -0.0346 -0.0371     0.097  \n",
      "lda       0.4451 -0.0125 -0.0095     0.124  \n",
      "dummy     0.0000  0.0000  0.0000     0.118  \n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=100, n_iter_no_change=None,\n",
      "                           random_state=2548, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "0  Gradient Boosting Classifier    0.5331  0.5957  0.4632  0.5727  0.5122   \n",
      "\n",
      "    Kappa     MCC  \n",
      "0  0.0739  0.0755  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_8.csv\n",
      "Group:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dt               Decision Tree Classifier    0.6214  0.6125  0.6250  0.5917   \n",
      "et                 Extra Trees Classifier    0.6089  0.6712  0.5583  0.5671   \n",
      "svm                   SVM - Linear Kernel    0.5179  0.0000  0.7583  0.5179   \n",
      "ada                  Ada Boost Classifier    0.5554  0.6696  0.5583  0.5029   \n",
      "rf               Random Forest Classifier    0.6000  0.6035  0.5250  0.5000   \n",
      "gbc          Gradient Boosting Classifier    0.5446  0.6200  0.4750  0.4817   \n",
      "lightgbm  Light Gradient Boosting Machine    0.5607  0.5490  0.4500  0.5150   \n",
      "knn                K Neighbors Classifier    0.5286  0.5162  0.4333  0.4583   \n",
      "ridge                    Ridge Classifier    0.5839  0.0000  0.3750  0.6100   \n",
      "lda          Linear Discriminant Analysis    0.5714  0.5538  0.3500  0.5100   \n",
      "lr                    Logistic Regression    0.5464  0.6067  0.3500  0.4267   \n",
      "nb                            Naive Bayes    0.6339  0.5925  0.2250  0.5167   \n",
      "qda       Quadratic Discriminant Analysis    0.5571  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.5571  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dt        0.5816  0.2214  0.2390     0.092  \n",
      "et        0.5401  0.1904  0.2227     0.230  \n",
      "svm       0.5258  0.0635  0.0866     0.080  \n",
      "ada       0.5164  0.0872  0.0846     0.165  \n",
      "rf        0.5057  0.1491  0.1435     0.211  \n",
      "gbc       0.4713  0.0636  0.0665     0.126  \n",
      "lightgbm  0.4429  0.0855  0.1069     0.139  \n",
      "knn       0.4310  0.0140  0.0142     0.113  \n",
      "ridge     0.4121  0.1393  0.1888     0.085  \n",
      "lda       0.3721  0.1143  0.1510     0.112  \n",
      "lr        0.3560  0.0643  0.0813     0.105  \n",
      "nb        0.3038  0.1891  0.2322     0.084  \n",
      "qda       0.0000  0.0000  0.0000     0.093  \n",
      "dummy     0.0000  0.0000  0.0000     0.170  \n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       random_state=8016, splitter='best')\n",
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Decision Tree Classifier    0.7037  0.7074  0.7273  0.6154  0.6667  0.4033   \n",
      "\n",
      "      MCC  \n",
      "0  0.4079  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_6.csv\n",
      "Group:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "nb                            Naive Bayes    0.5808  0.7601  1.0000  0.5632   \n",
      "ridge                    Ridge Classifier    0.7372  0.0000  0.6262  0.8678   \n",
      "lda          Linear Discriminant Analysis    0.7372  0.7772  0.6262  0.8678   \n",
      "knn                K Neighbors Classifier    0.7295  0.7494  0.6262  0.8494   \n",
      "lr                    Logistic Regression    0.7295  0.7891  0.6119  0.8628   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7372  0.7748  0.5833  0.9161   \n",
      "rf               Random Forest Classifier    0.6987  0.7641  0.5690  0.8350   \n",
      "et                 Extra Trees Classifier    0.6910  0.7248  0.5548  0.8314   \n",
      "gbc          Gradient Boosting Classifier    0.6833  0.7284  0.5262  0.8450   \n",
      "ada                  Ada Boost Classifier    0.6756  0.6998  0.5262  0.7964   \n",
      "dt               Decision Tree Classifier    0.6673  0.6609  0.5095  0.8178   \n",
      "svm                   SVM - Linear Kernel    0.6064  0.0000  0.5690  0.5960   \n",
      "qda       Quadratic Discriminant Analysis    0.4654  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4654  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "nb        0.7196  0.1054  0.1545     0.109  \n",
      "ridge     0.6989  0.4855  0.5273     0.162  \n",
      "lda       0.6989  0.4855  0.5273     0.112  \n",
      "knn       0.6923  0.4699  0.5080     0.096  \n",
      "lr        0.6868  0.4713  0.5142     0.097  \n",
      "lightgbm  0.6737  0.4907  0.5505     0.250  \n",
      "rf        0.6484  0.4119  0.4514     0.237  \n",
      "et        0.6398  0.3970  0.4358     0.278  \n",
      "gbc       0.6210  0.3841  0.4297     0.146  \n",
      "ada       0.6066  0.3698  0.4003     0.159  \n",
      "dt        0.5851  0.3548  0.4008     0.114  \n",
      "svm       0.5297  0.2153  0.2533     0.101  \n",
      "qda       0.0000  0.0000  0.0000     0.118  \n",
      "dummy     0.0000  0.0000  0.0000     0.118  \n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "         Model  Accuracy     AUC  Recall  Prec.      F1   Kappa     MCC\n",
      "0  Naive Bayes     0.562  0.5726  0.1452    1.0  0.2535  0.1421  0.2765\n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_7.csv\n",
      "Group:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "svm                   SVM - Linear Kernel    0.5091  0.0000  0.9000  0.4591   \n",
      "lr                    Logistic Regression    0.5826  0.5967  0.5733  0.6171   \n",
      "nb                            Naive Bayes    0.5826  0.5950  0.5733  0.6171   \n",
      "ridge                    Ridge Classifier    0.5826  0.0000  0.5733  0.6171   \n",
      "lda          Linear Discriminant Analysis    0.5826  0.5950  0.5733  0.6171   \n",
      "lightgbm  Light Gradient Boosting Machine    0.5477  0.5228  0.4733  0.6174   \n",
      "knn                K Neighbors Classifier    0.5212  0.5244  0.3700  0.6236   \n",
      "dt               Decision Tree Classifier    0.5152  0.4569  0.3233  0.6233   \n",
      "rf               Random Forest Classifier    0.5152  0.4519  0.3233  0.6233   \n",
      "ada                  Ada Boost Classifier    0.5144  0.4711  0.3233  0.6467   \n",
      "gbc          Gradient Boosting Classifier    0.5068  0.4497  0.3233  0.5900   \n",
      "et                 Extra Trees Classifier    0.5068  0.4333  0.3233  0.5800   \n",
      "qda       Quadratic Discriminant Analysis    0.4909  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4909  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "svm       0.6076  0.0000  0.0000     0.109  \n",
      "lr        0.5892  0.1632  0.1690     0.104  \n",
      "nb        0.5892  0.1632  0.1690     0.115  \n",
      "ridge     0.5892  0.1632  0.1690     0.107  \n",
      "lda       0.5892  0.1632  0.1690     0.106  \n",
      "lightgbm  0.5145  0.0978  0.1146     0.119  \n",
      "knn       0.4399  0.0472  0.0738     0.150  \n",
      "dt        0.4002  0.0371  0.0681     0.105  \n",
      "rf        0.4002  0.0371  0.0681     0.222  \n",
      "ada       0.3974  0.0340  0.0722     0.176  \n",
      "gbc       0.3947  0.0205  0.0426     0.145  \n",
      "et        0.3933  0.0205  0.0398     0.292  \n",
      "qda       0.0000  0.0000  0.0000     0.100  \n",
      "dummy     0.0000  0.0000  0.0000     0.114  \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "              power_t=0.5, random_state=1156, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "                 Model  Accuracy  AUC  Recall   Prec.      F1  Kappa  MCC\n",
      "0  SVM - Linear Kernel    0.5354  0.5     1.0  0.5354  0.6974    0.0  0.0\n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_3.csv\n",
      "Group:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "rf               Random Forest Classifier    0.9222  0.9700   0.935  0.9233   \n",
      "dt               Decision Tree Classifier    0.9222  0.9250   0.895  0.9633   \n",
      "knn                K Neighbors Classifier    0.9111  0.9775   0.975  0.8731   \n",
      "lr                    Logistic Regression    0.9111  0.9250   0.935  0.9067   \n",
      "lightgbm  Light Gradient Boosting Machine    0.9111  0.9650   0.915  0.9233   \n",
      "et                 Extra Trees Classifier    0.9111  0.9850   0.935  0.9017   \n",
      "gbc          Gradient Boosting Classifier    0.9111  0.9650   0.895  0.9433   \n",
      "ada                  Ada Boost Classifier    0.8889  0.9100   0.895  0.9148   \n",
      "ridge                    Ridge Classifier    0.8667  0.0000   0.910  0.8450   \n",
      "lda          Linear Discriminant Analysis    0.8667  0.9050   0.910  0.8450   \n",
      "svm                   SVM - Linear Kernel    0.7222  0.0000   0.835  0.7473   \n",
      "nb                            Naive Bayes    0.5667  0.8950   0.980  0.5448   \n",
      "qda       Quadratic Discriminant Analysis    0.4889  0.0000   0.000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4889  0.5000   0.000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "rf        0.9233  0.8430  0.8531     0.210  \n",
      "dt        0.9211  0.8441  0.8581     0.088  \n",
      "knn       0.9179  0.8176  0.8329     0.095  \n",
      "lr        0.9142  0.8199  0.8322     0.167  \n",
      "lightgbm  0.9122  0.8210  0.8331     0.272  \n",
      "et        0.9120  0.8210  0.8322     0.280  \n",
      "gbc       0.9072  0.8232  0.8414     0.162  \n",
      "ada       0.8905  0.7758  0.8011     0.150  \n",
      "ridge     0.8742  0.7299  0.7357     0.071  \n",
      "lda       0.8742  0.7299  0.7357     0.164  \n",
      "svm       0.7285  0.4364  0.5193     0.077  \n",
      "nb        0.6973  0.1147  0.1645     0.092  \n",
      "qda       0.0000  0.0000  0.0000     0.110  \n",
      "dummy     0.0000  0.0000  0.0000     0.152  \n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                       random_state=6838, verbose=0, warm_start=False)\n",
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Random Forest Classifier    0.9032  0.9829  0.9231  0.8571  0.8889  0.8034   \n",
      "\n",
      "      MCC  \n",
      "0  0.8051  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_1.csv\n",
      "Group:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "rf               Random Forest Classifier    0.9189  0.9509  0.9100  0.9490   \n",
      "lightgbm  Light Gradient Boosting Machine    0.9089  0.9507  0.9067  0.9371   \n",
      "gbc          Gradient Boosting Classifier    0.8978  0.9368  0.9233  0.8988   \n",
      "knn                K Neighbors Classifier    0.8967  0.9253  0.8833  0.9274   \n",
      "ada                  Ada Boost Classifier    0.8867  0.9551  0.8867  0.9181   \n",
      "et                 Extra Trees Classifier    0.8767  0.9438  0.8900  0.8990   \n",
      "lr                    Logistic Regression    0.8667  0.9583  0.8867  0.8874   \n",
      "dt               Decision Tree Classifier    0.8544  0.8550  0.8300  0.9040   \n",
      "svm                   SVM - Linear Kernel    0.7833  0.0000  0.8400  0.8478   \n",
      "lda          Linear Discriminant Analysis    0.7411  0.8858  0.8033  0.7692   \n",
      "ridge                    Ridge Classifier    0.7311  0.0000  0.8033  0.7622   \n",
      "nb                            Naive Bayes    0.6456  0.8658  1.0000  0.6164   \n",
      "qda       Quadratic Discriminant Analysis    0.4378  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4378  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "rf        0.9230  0.8367  0.8492     0.188  \n",
      "lightgbm  0.9179  0.8111  0.8191     0.272  \n",
      "gbc       0.9066  0.7869  0.7964     0.141  \n",
      "knn       0.8999  0.7896  0.8000     0.092  \n",
      "ada       0.8979  0.7662  0.7753     0.168  \n",
      "et        0.8834  0.7489  0.7678     0.272  \n",
      "lr        0.8810  0.7242  0.7405     0.077  \n",
      "dt        0.8573  0.7073  0.7206     0.101  \n",
      "svm       0.8030  0.5673  0.6330     0.089  \n",
      "lda       0.7717  0.4769  0.5052     0.084  \n",
      "ridge     0.7662  0.4569  0.4886     0.092  \n",
      "nb        0.7615  0.1968  0.2643     0.104  \n",
      "qda       0.0000  0.0000  0.0000     0.101  \n",
      "dummy     0.0000  0.0000  0.0000     0.154  \n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                       random_state=1238, verbose=0, warm_start=False)\n",
      "                      Model  Accuracy     AUC  Recall  Prec.      F1   Kappa  \\\n",
      "0  Random Forest Classifier    0.9697  0.9463  0.9333    1.0  0.9655  0.9385   \n",
      "\n",
      "      MCC  \n",
      "0  0.9403  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_10.csv\n",
      "Group:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.8022  0.8645   0.825  0.7917   \n",
      "dt               Decision Tree Classifier    0.7800  0.7825   0.850  0.7710   \n",
      "ada                  Ada Boost Classifier    0.7800  0.8345   0.830  0.7738   \n",
      "et                 Extra Trees Classifier    0.7800  0.7845   0.825  0.7617   \n",
      "rf               Random Forest Classifier    0.7467  0.8320   0.800  0.7371   \n",
      "nb                            Naive Bayes    0.7478  0.7650   0.805  0.7233   \n",
      "knn                K Neighbors Classifier    0.7244  0.7670   0.755  0.7325   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7144  0.7840   0.730  0.7131   \n",
      "lr                    Logistic Regression    0.7244  0.7870   0.670  0.7550   \n",
      "ridge                    Ridge Classifier    0.7244  0.0000   0.670  0.7550   \n",
      "lda          Linear Discriminant Analysis    0.7244  0.7920   0.670  0.7550   \n",
      "svm                   SVM - Linear Kernel    0.5256  0.0000   0.665  0.4185   \n",
      "qda       Quadratic Discriminant Analysis    0.4944  0.0000   0.000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4944  0.5000   0.000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.8044  0.5999  0.6066     0.125  \n",
      "dt        0.7977  0.5554  0.5754     0.088  \n",
      "ada       0.7882  0.5612  0.5827     0.155  \n",
      "et        0.7880  0.5526  0.5623     0.183  \n",
      "rf        0.7610  0.4820  0.4925     0.255  \n",
      "nb        0.7533  0.4896  0.5071     0.088  \n",
      "knn       0.7295  0.4368  0.4599     0.093  \n",
      "lightgbm  0.7113  0.4226  0.4387     0.155  \n",
      "lr        0.6926  0.4448  0.4670     0.083  \n",
      "ridge     0.6926  0.4448  0.4670     0.092  \n",
      "lda       0.6926  0.4448  0.4670     0.093  \n",
      "svm       0.5080  0.0410  0.0502     0.088  \n",
      "qda       0.0000  0.0000  0.0000     0.097  \n",
      "dummy     0.0000  0.0000  0.0000     0.114  \n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=100, n_iter_no_change=None,\n",
      "                           random_state=1559, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "0  Gradient Boosting Classifier    0.5161  0.6045     0.5  0.6667  0.5714   \n",
      "\n",
      "    Kappa     MCC  \n",
      "0  0.0412  0.0435  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_9.csv\n",
      "Group:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lda          Linear Discriminant Analysis    0.6985  0.7552  0.7095  0.7748   \n",
      "rf               Random Forest Classifier    0.6803  0.7395  0.7262  0.7424   \n",
      "ridge                    Ridge Classifier    0.6985  0.0000  0.6667  0.7919   \n",
      "ada                  Ada Boost Classifier    0.6826  0.7140  0.6976  0.7538   \n",
      "nb                            Naive Bayes    0.6311  0.6167  0.8119  0.6490   \n",
      "lr                    Logistic Regression    0.6735  0.7719  0.7000  0.7288   \n",
      "et                 Extra Trees Classifier    0.6545  0.6967  0.7381  0.6872   \n",
      "lightgbm  Light Gradient Boosting Machine    0.6561  0.6938  0.6524  0.7538   \n",
      "gbc          Gradient Boosting Classifier    0.6379  0.6910  0.6667  0.7310   \n",
      "dt               Decision Tree Classifier    0.6045  0.5962  0.6524  0.6444   \n",
      "knn                K Neighbors Classifier    0.5364  0.6462  0.5500  0.6125   \n",
      "svm                   SVM - Linear Kernel    0.5212  0.0000  0.5857  0.5004   \n",
      "qda       Quadratic Discriminant Analysis    0.4205  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4205  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lda       0.7342  0.3819  0.3906     0.119  \n",
      "rf        0.7204  0.3438  0.3680     0.177  \n",
      "ridge     0.7201  0.3958  0.4076     0.089  \n",
      "ada       0.7164  0.3529  0.3625     0.150  \n",
      "nb        0.7152  0.2009  0.2259     0.096  \n",
      "lr        0.7076  0.3383  0.3490     0.111  \n",
      "et        0.7018  0.2846  0.3031     0.414  \n",
      "lightgbm  0.6826  0.3044  0.3244     0.414  \n",
      "gbc       0.6796  0.2560  0.2674     0.138  \n",
      "dt        0.6377  0.1891  0.1821     0.085  \n",
      "knn       0.5730  0.0684  0.0689     0.143  \n",
      "svm       0.4988  0.0245  0.0497     0.099  \n",
      "qda       0.0000  0.0000  0.0000     0.073  \n",
      "dummy     0.0000  0.0000  0.0000     0.152  \n",
      "LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,\n",
      "                           priors=None, shrinkage=None, solver='svd',\n",
      "                           store_covariance=False, tol=0.0001)\n",
      "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "0  Linear Discriminant Analysis    0.4264  0.4601  0.6377  0.4731  0.5432   \n",
      "\n",
      "    Kappa    MCC  \n",
      "0 -0.1838 -0.199  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_4.csv\n",
      "Group:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.9267  0.9580  0.9800  0.9095   \n",
      "ada                  Ada Boost Classifier    0.9144  0.9580  0.9200  0.9381   \n",
      "et                 Extra Trees Classifier    0.8978  0.9840  0.9800  0.8711   \n",
      "rf               Random Forest Classifier    0.8967  0.9410  0.9400  0.8943   \n",
      "lda          Linear Discriminant Analysis    0.8556  0.9163  0.8600  0.8805   \n",
      "lr                    Logistic Regression    0.8456  0.9273  0.8600  0.8671   \n",
      "dt               Decision Tree Classifier    0.8444  0.8442  0.8433  0.8875   \n",
      "lightgbm  Light Gradient Boosting Machine    0.8333  0.8987  0.8833  0.8410   \n",
      "knn                K Neighbors Classifier    0.8244  0.9178  0.9033  0.8196   \n",
      "ridge                    Ridge Classifier    0.8344  0.0000  0.8600  0.8505   \n",
      "nb                            Naive Bayes    0.7022  0.9570  1.0000  0.6647   \n",
      "svm                   SVM - Linear Kernel    0.7700  0.0000  0.8000  0.7352   \n",
      "qda       Quadratic Discriminant Analysis    0.4678  0.0000  0.0000  0.0000   \n",
      "dummy                    Dummy Classifier    0.4678  0.5000  0.0000  0.0000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.9374  0.8496  0.8676     0.102  \n",
      "ada       0.9179  0.8290  0.8485     0.116  \n",
      "et        0.9159  0.7909  0.8154     0.146  \n",
      "rf        0.9078  0.7907  0.8123     0.164  \n",
      "lda       0.8593  0.7094  0.7278     0.069  \n",
      "lr        0.8521  0.6894  0.7086     0.113  \n",
      "dt        0.8509  0.6857  0.7103     0.070  \n",
      "lightgbm  0.8509  0.6621  0.6873     0.115  \n",
      "knn       0.8502  0.6441  0.6658     0.114  \n",
      "ridge     0.8430  0.6663  0.6876     0.073  \n",
      "nb        0.7890  0.3906  0.4559     0.096  \n",
      "svm       0.7479  0.5433  0.5840     0.073  \n",
      "qda       0.0000  0.0000  0.0000     0.089  \n",
      "dummy     0.0000  0.0000  0.0000     0.073  \n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=100, n_iter_no_change=None,\n",
      "                           random_state=7499, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "                          Model  Accuracy     AUC  Recall   Prec.     F1  \\\n",
      "0  Gradient Boosting Classifier    0.9697  0.9889     1.0  0.9474  0.973   \n",
      "\n",
      "    Kappa     MCC  \n",
      "0  0.9385  0.9403  \n",
      "Predictions saved to: SWELL_Multi_Attribute_Splitting_Output_Files_Bias\\predictions_5.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os  # Import os module for folder creation\n",
    "\n",
    "# Specify folder name\n",
    "folder_name = \"SWELL_Multi_Attribute_Splitting_Output_Files_Bias\"\n",
    "\n",
    "# Load the CSV data into a pandas dataframe\n",
    "df_user_info = pd.read_csv(\"Scored_Surveys/swell_person.csv\", sep=\";\")\n",
    "\n",
    "accuracies_swell = []\n",
    "precision_swell = []\n",
    "recall_swell = []\n",
    "f1scores_swell = []\n",
    "\n",
    "for participant in unique_participants:\n",
    "    print(\"Group: \",participant)    \n",
    "    part_df = all_group.get_group(participant)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    # if the group has only one id don't split per user\n",
    "    if participant in [1,5,6,9,10]:\n",
    "        train_data, test_data = train_test_split(part_df)\n",
    "    else:\n",
    "        train_data, test_data = train_test_split_per_user(part_df)\n",
    "\n",
    "    # train_data, test_data = train_test_split(part_df)\n",
    "\n",
    "    fold_groups = train_data.id\n",
    "\n",
    "    # Save the 'id' column from the test set\n",
    "    test_ids = test_data['id']\n",
    "\n",
    "    train_data = train_data.drop(columns=['id'])\n",
    "    test_data = test_data.drop(columns=['id'])\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    grid = setup(data=train_data, target='stress_x', fix_imbalance = True, html=False, verbose=False, test_data=test_data) #fix_imbalance = True,\n",
    "    best = compare_models(sort='F1')\n",
    "    accuracies_swell.append(pull()['Accuracy'][0])\n",
    "    precision_swell.append(pull()['Prec.'][0])\n",
    "    recall_swell.append(pull()['Recall'][0])\n",
    "    f1scores_swell.append(pull()['F1'][0])\n",
    "    print(best)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    # Make predictions using the best model\n",
    "    predictions = predict_model(best, data=test_data)\n",
    "\n",
    "    # Add 'id' column back to predictions DataFrame\n",
    "    predictions['PP'] = test_ids  # Use the 'id' column from the test data\n",
    "\n",
    "    # Extract true labels (y_true), rename the column\n",
    "    y_true = predictions[['stress_x']].rename(columns={'stress_x': 'y_true'})\n",
    "\n",
    "    # Extract predicted labels (y_pred), rename the column\n",
    "    y_pred = predictions[['prediction_label']].rename(columns={'prediction_label': 'y_pred'})\n",
    "\n",
    "    # Identify protected attribute columns (assuming you know the column names)\n",
    "    protected_attributes = predictions[['Age', 'Gender', 'Occupation']]\n",
    "\n",
    "    # Concatenate DataFrames containing predictions and protected attributes\n",
    "    all_data = pd.concat([test_ids, y_true, y_pred, protected_attributes], axis=1)\n",
    "\n",
    "    # Create filename\n",
    "    filename = f\"predictions_{participant}.csv\"\n",
    "\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)  # Create folder using makedirs()\n",
    "\n",
    "    # Create full path with folder name\n",
    "    filepath = os.path.join(folder_name, filename)\n",
    "\n",
    "    # Save predictions\n",
    "    all_data.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Predictions saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1238ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = statistics.mean(accuracies_swell)\n",
    "mean_prec = statistics.mean(precision_swell)\n",
    "mean_rec = statistics.mean(recall_swell)\n",
    "mean_f1 = statistics.mean(f1scores_swell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "376f3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy SWELL- Cluster All Features:  0.7630545454545454\n",
      "Mean Precision SWELL- Cluster All Features:  0.7895727272727273\n",
      "Mean Recall SWELL- Cluster All Features:  0.8523090909090909\n",
      "Mean F1-score SWELL- Cluster All Features:  0.7642636363636364\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy SWELL- Cluster All Features: \",mean_acc)\n",
    "print(\"Mean Precision SWELL- Cluster All Features: \",mean_f1)\n",
    "print(\"Mean Recall SWELL- Cluster All Features: \",mean_rec)\n",
    "print(\"Mean F1-score SWELL- Cluster All Features: \",mean_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "597f59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"SWELL_Multi_Attribute_Splitting_Output_Files_Bias\"\n",
    "\n",
    "# List all CSV files in the folder:\n",
    "csv_files = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_files.append(os.path.join(folder_path, filename))\n",
    "\n",
    "# Concatenate files\n",
    "combined_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b734542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions saved to: Output_Files\\SWELL_Multi_Attribute_Splitting_Bias.csv\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"Output_Files\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)  # Create folder using makedirs()\n",
    "\n",
    "# Create the full path with the output folder name\n",
    "output_filepath = os.path.join(output_folder, \"SWELL_Multi_Attribute_Splitting_Bias.csv\")\n",
    "\n",
    "# Save the concatenated DataFrame to the new CSV file\n",
    "combined_df.to_csv(output_filepath, index=False)\n",
    "\n",
    "print(f\"All predictions saved to: {output_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
